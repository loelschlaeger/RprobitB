<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Model definition • RprobitB</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Model definition">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">RprobitB</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.4</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/RprobitB.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/v01_model_definition.html">Model definition</a></li>
    <li><a class="dropdown-item" href="../articles/v02_choice_data.html">Choice data</a></li>
    <li><a class="dropdown-item" href="../articles/v03_model_fitting.html">Model fitting</a></li>
    <li><a class="dropdown-item" href="../articles/v04_modeling_heterogeneity.html">Modeling heterogeneity</a></li>
    <li><a class="dropdown-item" href="../articles/v05_choice_prediction.html">Choice prediction</a></li>
    <li><a class="dropdown-item" href="../articles/v06_model_selection.html">Model selection</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/loelschlaeger/RprobitB/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Model definition</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/loelschlaeger/RprobitB/blob/main/vignettes/v01_model_definition.Rmd" class="external-link"><code>vignettes/v01_model_definition.Rmd</code></a></small>
      <div class="d-none name"><code>v01_model_definition.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="the-probit-model">The probit model<a class="anchor" aria-label="anchor" href="#the-probit-model"></a>
</h2>
<p>The probit model<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;The name &lt;em&gt;probit&lt;/em&gt; is a portmanteau of
&lt;em&gt;prob&lt;/em&gt;ability and un&lt;em&gt;it&lt;/em&gt;. &lt;span class="citation"&gt;(&lt;a href="#ref-Bliss1934"&gt;Bliss 1934&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>1</sup></a> is a regression-type model where the
dependent variable only takes a finite number of values and the error
term is normally distributed <span class="citation">(<a href="#ref-Agresti2015">Agresti 2015</a>)</span>. Its purpose is to
estimate the probability that the dependent variable takes a certain,
discrete value. The most common application are discrete choice
scenarios. The dependent variable here is one of finitely many and
mutually exclusive alternatives, and explanatory variables typically are
characteristics of the deciders or the alternatives.</p>
<p>To be concrete, assume that we possess data of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
decision makers which choose between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>≥</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">J \geq 2</annotation></semantics></math>
alternatives<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;To be precise, the model name gets the prefix
&lt;em&gt;multinomial&lt;/em&gt; in the case
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;J&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;J &amp;gt; 2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;.&lt;/p&gt;'><sup>2</sup></a> at each of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math>
choice occasions<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;For notational simplicity, the number of choice
occasions
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;annotation encoding="application/x-tex"&gt;T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;
is assumed to be the same for each decision maker here. However, we are
not restricted to this case: &lt;a href="https://loelschlaeger.de/RprobitB/"&gt;RprobitB&lt;/a&gt; allows for
unbalanced panels, i.e. varying
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;annotation encoding="application/x-tex"&gt;T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;.
Of course, the cross-sectional case
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;T = 1&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;
is possible.&lt;/p&gt;'><sup>3</sup></a>. Specific to each decision maker,
alternative and choice occasion, we furthermore observe
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>P</mi><annotation encoding="application/x-tex">P</annotation></semantics></math>
choice attributes that we use to explain the choices. The continuous
choice attributes cannot be linked directly to the discrete choices but
must take a detour over a latent variable. In the discrete choice
setting, this variable can be interpreted as the decider’s utility of a
certain alternative. Decider
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>’s
utility
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">U_{ntj}</annotation></semantics></math>
for alternative
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
at choice occasion
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
is modeled as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mi>′</mi><mi>β</mi><mo>+</mo><msub><mi>ϵ</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\begin{equation}
  U_{ntj} = X_{ntj}'\beta + \epsilon_{ntj}
\end{equation}</annotation></semantics></math></p>
<p>for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">n=1,\dots,N</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">t=1,\dots,T</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>J</mi></mrow><annotation encoding="application/x-tex">j=1,\dots,J</annotation></semantics></math>,
where</p>
<ul>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">X_{ntj}</annotation></semantics></math>
is a (column) vector of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>P</mi><annotation encoding="application/x-tex">P</annotation></semantics></math>
characteristics of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
as faced by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>∈</mo><msup><mi>ℝ</mi><mi>P</mi></msup></mrow><annotation encoding="application/x-tex">\beta \in {\mathbb R}^{P}</annotation></semantics></math>
is a vector of coefficients,</p></li>
<li><p>and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ϵ</mi><mrow><mi>n</mi><mi>t</mi><mo>:</mo></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ϵ</mi><mrow><mi>n</mi><mi>t</mi><mn>1</mn></mrow></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>ϵ</mi><mrow><mi>n</mi><mi>t</mi><mi>J</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>′</mi><mo>∼</mo><msub><mtext mathvariant="normal">MVN</mtext><mi>J</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mi>Σ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(\epsilon_{nt:}) = (\epsilon_{nt1},\dots,\epsilon_{ntJ})' \sim \text{MVN}_{J} (0,\Sigma)</annotation></semantics></math>
is the model’s error term vector for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>,
which in the probit model is assumed to be multivariate normally
distributed with zero mean and covariance matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Σ</mi><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math>.</p></li>
</ul>
<p>Now let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">y_{nt}=j</annotation></semantics></math>
denote the event that decision maker
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
chooses alternative
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
at choice occasion
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>.
Assuming utility maximizing behavior of the decision makers<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;This in fact is a critical assumption because many
studies show that humans do not decide in this rational sense in
general, see for example &lt;span class="citation"&gt;Hewig et al. (&lt;a href="#ref-Hewig2011"&gt;2011&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>4</sup></a>, the
decisions are linked to the utilities via</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><msub><mrow><mo>arg</mo><mo>max</mo></mrow><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>J</mi></mrow></msub><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mi>.</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
y_{nt} = {\arg \max}_{j = 1,\dots,J} U_{ntj}.
\end{equation}</annotation></semantics></math></p>
<p>In the ordered probit case, the concept of decider’s having separate
utilities for each alternative is no longer natural <span class="citation">(<a href="#ref-Train2009">Train 2009</a>)</span>.
Instead, we model only a single utility value
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mi>′</mi><msub><mi>β</mi><mi>n</mi></msub><mo>+</mo><msub><mi>ϵ</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align*}
  U_{nt} = X_{nt}'\beta_n + \epsilon_{nt}
\end{align*}</annotation></semantics></math> per decider
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
and choice occasion
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>,
which we interpret as the “level of association” that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
has with the choice question. The utility value falls into discrete
categories, which in turn are linked to the ordered alternatives
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>J</mi></mrow><annotation encoding="application/x-tex">j=1,\dots,J</annotation></semantics></math>.
Formally,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>y</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>J</mi></mrow></munder><mi>j</mi><mo>⋅</mo><mi>I</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>γ</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>&lt;</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mo>≤</mo><msub><mi>γ</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align*}
   y_{nt} = \sum_{j = 1,\dots,J} j \cdot I(\gamma_{j-1} &lt; U_{nt} \leq \gamma_{j}),
\end{align*}</annotation></semantics></math> with end points
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mn>0</mn></msub><mo>=</mo><mo>−</mo><mi>∞</mi></mrow><annotation encoding="application/x-tex">\gamma_0 = -\infty</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mi>J</mi></msub><mo>=</mo><mo>+</mo><mi>∞</mi></mrow><annotation encoding="application/x-tex">\gamma_J = +\infty</annotation></semantics></math>,
and thresholds
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>γ</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>J</mi><mo>−</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">(\gamma_j)_{j=1,\dots,J-1}</annotation></semantics></math>.
To ensure monotonicity of the thresholds, we rather estimate logarithmic
threshold increments
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>d</mi><mi>j</mi></msub><annotation encoding="application/x-tex">d_j</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mi>j</mi></msub><mo>=</mo><msub><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>exp</mo><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\gamma_j = \sum_{i=1,\dots,j} \exp{d_i}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>J</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">j=1,\dots,J-1</annotation></semantics></math>.</p>
</div>
<div class="section level2">
<h2 id="choice-behavior-heterogeneity">Choice behavior heterogeneity<a class="anchor" aria-label="anchor" href="#choice-behavior-heterogeneity"></a>
</h2>
<p>Note that the coefficient vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
is constant across decision makers. This assumption is too restrictive
for many applications.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;For example, consider the case of modeling the choice of
a means of transportation to work: It is easily imaginable that business
people and pensioners do not share the same sensitivities towards cost
and time.&lt;/p&gt;"><sup>5</sup></a> Heterogeneity in choice behavior can be
modeled by imposing a distribution on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
such that each decider can have their own preferences.</p>
<p>Formally, we define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>α</mi><mo>,</mo><msub><mi>β</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta = (\alpha, \beta_n)</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>P</mi><mi>f</mi></msub><annotation encoding="application/x-tex">P_f</annotation></semantics></math>
coefficients that are constant across deciders and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>n</mi></msub><annotation encoding="application/x-tex">\beta_n</annotation></semantics></math>
are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>P</mi><mi>r</mi></msub><annotation encoding="application/x-tex">P_r</annotation></semantics></math>
decider-specific coefficients. Consequently,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>=</mo><msub><mi>P</mi><mi>f</mi></msub><mo>+</mo><msub><mi>P</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">P = P_f + P_r</annotation></semantics></math>.
Now if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>r</mi></msub><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">P_r&gt;0</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>n</mi></msub><annotation encoding="application/x-tex">\beta_n</annotation></semantics></math>
is distributed according to some
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>P</mi><mi>r</mi></msub><annotation encoding="application/x-tex">P_r</annotation></semantics></math>-variate
distribution, the so-called mixing distribution.</p>
<p>Choosing an appropriate mixing distribution is a notoriously
difficult task of the model specification. In many applications,
different types of standard parametric distributions (including the
normal, log-normal, uniform and tent distribution) are tried in
conjunction with a likelihood value-based model selection, cf., <span class="citation">Train (<a href="#ref-Train2009">2009</a>)</span>,
Chapter 6. Instead, <a href="https://loelschlaeger.de/RprobitB/">RprobitB</a> implements the approach of
<span class="citation">(<a href="#ref-Oelschlaeger2020">Oelschläger and
Bauer 2020</a>)</span> to approximate any underlying mixing distribution
by a mixture of (multivariate) Gaussian densities. More precisely, the
underlying mixing distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>g</mi><msub><mi>P</mi><mi>r</mi></msub></msub><annotation encoding="application/x-tex">g_{P_r}</annotation></semantics></math>
for the random coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>β</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>n</mi></msub><annotation encoding="application/x-tex">(\beta_n)_{n}</annotation></semantics></math>
is approximated by a mixture of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>P</mi><mi>r</mi></msub><annotation encoding="application/x-tex">P_r</annotation></semantics></math>-variate
normal densities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ϕ</mi><msub><mi>P</mi><mi>r</mi></msub></msub><annotation encoding="application/x-tex">\phi_{P_r}</annotation></semantics></math>
with mean vectors
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>=</mo><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>b</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">b=(b_c)_{c}</annotation></semantics></math>
and covariance matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Ω</mi><mo>=</mo><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Ω</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">\Omega=(\Omega_c)_{c}</annotation></semantics></math>
using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
components, i.e.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>n</mi></msub><mo>∣</mo><mi>b</mi><mo>,</mo><mi>Ω</mi><mo>∼</mo><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><msub><mi>s</mi><mi>c</mi></msub><msub><mi>ϕ</mi><msub><mi>P</mi><mi>r</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo>∣</mo><msub><mi>b</mi><mi>c</mi></msub><mo>,</mo><msub><mi>Ω</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
\beta_n\mid b,\Omega \sim \sum_{c=1}^{C} s_c \phi_{P_r} (\cdot \mid b_c,\Omega_c).
\end{equation}</annotation></semantics></math></p>
<p>Here,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>s</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>c</mi></msub><annotation encoding="application/x-tex">(s_c)_{c}</annotation></semantics></math>
are weights satisfying
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><msub><mi>s</mi><mi>c</mi></msub><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 &lt; s_c\leq 1</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">c=1,\dots,C</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>c</mi></msub><msub><mi>s</mi><mi>c</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\sum_c s_c=1</annotation></semantics></math>.
One interpretation of the latent class model is obtained by introducing
variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">z=(z_n)_n</annotation></semantics></math>,
allocating each decision maker
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
to class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>
with probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mi>c</mi></msub><annotation encoding="application/x-tex">s_c</annotation></semantics></math>,
i.e.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">Prob</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>s</mi><mi>c</mi></msub><mo>∧</mo><msub><mi>β</mi><mi>n</mi></msub><mo>∣</mo><mi>z</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>Ω</mi><mo>∼</mo><msub><mi>ϕ</mi><msub><mi>P</mi><mi>r</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo>∣</mo><msub><mi>b</mi><msub><mi>z</mi><mi>n</mi></msub></msub><mo>,</mo><msub><mi>Ω</mi><msub><mi>z</mi><mi>n</mi></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
\text{Prob}(z_n=c)=s_c \land \beta_n \mid z,b,\Omega \sim \phi_{P_r}(\cdot \mid b_{z_n},\Omega_{z_n}).
\end{equation}</annotation></semantics></math></p>
<p>We call the resulting model the <em>latent class mixed multinomial
probit model</em>. Note that the model collapses to the <em>(normally)
mixed multinomial probit model</em> if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>r</mi></msub><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">P_r&gt;0</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">C=1</annotation></semantics></math>,
to the <em>multinomial probit model</em> if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>r</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">P_r=0</annotation></semantics></math>
and to the <em>binary probit model</em> if additionally
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">J=2</annotation></semantics></math>.</p>
</div>
<div class="section level2">
<h2 id="model-normalization">Model normalization<a class="anchor" aria-label="anchor" href="#model-normalization"></a>
</h2>
<p>As is well known, any utility model needs to be normalized with
respect to level and scale in order to be identified <span class="citation">(<a href="#ref-Train2009">Train 2009</a>)</span>.
Therefore, we consider the transformed model</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>U</mi><mo accent="true">̃</mo></mover><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mover><mi>X</mi><mo accent="true">̃</mo></mover><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mi>′</mi><mi>β</mi><mo>+</mo><msub><mover><mi>ϵ</mi><mo accent="true">̃</mo></mover><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
\tilde{U}_{ntj} = \tilde{X}_{ntj}' \beta + \tilde{\epsilon}_{ntj},
\end{equation}</annotation></semantics></math></p>
<p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">n=1,\dots,N</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">t=1,\dots,T</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>J</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">j=1,\dots,J-1</annotation></semantics></math>,
where (choosing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math>
as the reference alternative)
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>U</mi><mo accent="true">̃</mo></mover><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>J</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\tilde{U}_{ntj} = U_{ntj} - U_{ntJ}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>X</mi><mo accent="true">̃</mo></mover><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi><mi>J</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\tilde{X}_{ntj} = X_{ntj} - X_{ntJ}</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>ϵ</mi><mo accent="true">̃</mo></mover><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>ϵ</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>ϵ</mi><mrow><mi>n</mi><mi>t</mi><mi>J</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\tilde{\epsilon}_{ntj} = \epsilon_{ntj} - \epsilon_{ntJ}</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>ϵ</mi><mo accent="true">̃</mo></mover><mrow><mi>n</mi><mi>t</mi><mo>:</mo></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>ϵ</mi><mo accent="true">̃</mo></mover><mrow><mi>n</mi><mi>t</mi><mn>1</mn></mrow></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mover><mi>ϵ</mi><mo accent="true">̃</mo></mover><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>J</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>′</mi><mo>∼</mo><msub><mtext mathvariant="normal">MVN</mtext><mrow><mi>J</mi><mo>−</mo><mn>1</mn></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mover><mi>Σ</mi><mo accent="true">̃</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(\tilde{\epsilon}_{nt:}) = (\tilde{\epsilon}_{nt1},...,\tilde{\epsilon}_{nt(J-1)})'  \sim \text{MVN}_{J-1} (0,\tilde{\Sigma})</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Σ</mi><mo accent="true">̃</mo></mover><annotation encoding="application/x-tex">\tilde{\Sigma}</annotation></semantics></math>
denotes a covariance matrix with the top-left element restricted to
one.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;&lt;a href="https://loelschlaeger.de/RprobitB/"&gt;RprobitB&lt;/a&gt; provides an alternative to
fixing an error term variance in order to normalize with respect to
scale by fixing an element of
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;annotation encoding="application/x-tex"&gt;\alpha&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;.&lt;/p&gt;'><sup>6</sup></a></p>
</div>
<div class="section level2">
<h2 id="parameter-labels">Parameter labels<a class="anchor" aria-label="anchor" href="#parameter-labels"></a>
</h2>
<p>In <a href="https://loelschlaeger.de/RprobitB/">RprobitB</a>, the probit model parameters are saved as
an <code>RprobitB_parameter</code> object. Their labels are consistent
with their definition in this vignette. For example:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">RprobitB</span><span class="fu">:::</span><span class="fu"><a href="../reference/RprobitB_parameter.html">RprobitB_parameter</a></span><span class="op">(</span></span>
<span>  P_f <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  P_r <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  J <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  N <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  C <span class="op">=</span> <span class="fl">2</span>, <span class="co"># the number of latent classes</span></span>
<span>  alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, <span class="co"># the fixed coefficient vector of length 'P_f'</span></span>
<span>  s <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.4</span><span class="op">)</span>, <span class="co"># the vector of class weights of length 'C'</span></span>
<span>  b <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>  <span class="co"># the matrix of class means as columns of dimension 'P_r' x 'C'</span></span>
<span>  Omega <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">0.1</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">4</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>  <span class="co"># the matrix of class covariance matrices as columns of dimension 'P_r^2' x 'C'</span></span>
<span>  Sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>, <span class="co"># the differenced error term covariance matrix of dimension '(J-1)' x '(J-1)'</span></span>
<span>  <span class="co"># the undifferenced error term covariance matrix is labeled 'Sigma_full'</span></span>
<span>  z <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="fl">5</span><span class="op">)</span> <span class="co"># the vector of the allocation variables of length 'N'</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; alpha : 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; C : 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; s : double vector of length 2 </span></span>
<span><span class="co">#&gt; 0.6 0.4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; b : 2 x 2 matrix of doubles </span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]   -1    1</span></span>
<span><span class="co">#&gt; [2,]    1    2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Omega : 4 x 2 matrix of doubles </span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]    1  0.1</span></span>
<span><span class="co">#&gt; [2,]    0    0</span></span>
<span><span class="co">#&gt; [3,]    0    0</span></span>
<span><span class="co">#&gt; [4,]    1  0.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sigma : 2 x 2 matrix of doubles </span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]    1    0</span></span>
<span><span class="co">#&gt; [2,]    0    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sigma_full : 3 x 3 matrix of doubles </span></span>
<span><span class="co">#&gt;      [,1] [,2] [,3]</span></span>
<span><span class="co">#&gt; [1,]    2    1    1</span></span>
<span><span class="co">#&gt; [2,]    1    2    1</span></span>
<span><span class="co">#&gt; [3,]    1    1    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; beta : 2 x 10 matrix of doubles </span></span>
<span><span class="co">#&gt;       [,1] [,2]  [,3] ... [,10]</span></span>
<span><span class="co">#&gt; [1,] -0.03 0.97 -0.25 ...  1.52</span></span>
<span><span class="co">#&gt; [2,] -0.01 1.82  0.07 ...  1.75</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; z : double vector of length 10 </span></span>
<span><span class="co">#&gt; 1 2 1 ... 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; d : NA</span></span></code></pre></div>
<p>Mind that the matrix <code>Sigma_full</code> is not unique and can be
any matrix that results into <code>Sigma</code> after the differencing,
see the non-exported function
<code>RprobitB:::undiff_Sigma()</code>.</p>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Agresti2015" class="csl-entry">
Agresti, A. 2015. <em>Foundations of Linear and Generalized Linear
Models</em>. Wiley.
</div>
<div id="ref-Bliss1934" class="csl-entry">
Bliss, C. I. 1934. <span>“The Method of Probits.”</span>
<em>Science</em> 79 (2037). <a href="https://doi.org/10.1126/science.79.2037.38" class="external-link">https://doi.org/10.1126/science.79.2037.38</a>.
</div>
<div id="ref-Hewig2011" class="csl-entry">
Hewig, Johannes, Nora Kretschmer, Ralf H. Trippe, Holger Hecht, Michael
G. H. Coles, Clay B. Holroyd, and Wolfgang H. R. Miltner. 2011.
<span>“Why Humans Deviate from Rational Choice.”</span>
<em>Psychophysiology</em> 48 (4): 507–14. https://doi.org/<a href="https://doi.org/10.1111/j.1469-8986.2010.01081.x" class="external-link">https://doi.org/10.1111/j.1469-8986.2010.01081.x</a>.
</div>
<div id="ref-Oelschlaeger2020" class="csl-entry">
Oelschläger, L., and D. Bauer. 2020. <span>“Bayes Estimation of Latent
Class Mixed Multinomial Probit Models.”</span> <em>TRB Annual Meeting
2021</em>.
</div>
<div id="ref-Train2009" class="csl-entry">
Train, Kenneth E. 2009. <em>Discrete Choice Methods with
Simulation</em>. 2nd ed. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511805271" class="external-link">https://doi.org/10.1017/CBO9780511805271</a>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://loelschlaeger.de" class="external-link">Lennart Oelschläger</a>, <a href="https://de.wikipedia.org/wiki/Dietmar_Bauer" class="external-link">Dietmar Bauer</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
