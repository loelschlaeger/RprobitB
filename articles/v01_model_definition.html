<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="RprobitB">
<title>Model definition • RprobitB</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.3/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.3/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Model definition">
<meta property="og:description" content="RprobitB">
<meta property="og:image" content="https://loelschlaeger.de/RprobitB/logo.svg">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">RprobitB</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.2</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/RprobitB.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/v01_model_definition.html">Model definition</a>
    <a class="dropdown-item" href="../articles/v02_choice_data.html">Choice data</a>
    <a class="dropdown-item" href="../articles/v03_model_fitting.html">Model fitting</a>
    <a class="dropdown-item" href="../articles/v04_modeling_heterogeneity.html">Modeling heterogeneity</a>
    <a class="dropdown-item" href="../articles/v05_choice_prediction.html">Choice prediction</a>
    <a class="dropdown-item" href="../articles/v06_model_selection.html">Model selection</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/loelschlaeger/RprobitB/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">



<script src="v01_model_definition_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Model definition</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/loelschlaeger/RprobitB/blob/HEAD/vignettes/v01_model_definition.Rmd" class="external-link"><code>vignettes/v01_model_definition.Rmd</code></a></small>
      <div class="d-none name"><code>v01_model_definition.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="the-probit-model">The probit model<a class="anchor" aria-label="anchor" href="#the-probit-model"></a>
</h2>
<p>The probit model<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;The name &lt;em&gt;probit&lt;/em&gt; is a portmanteau of &lt;em&gt;prob&lt;/em&gt;ability and un&lt;em&gt;it&lt;/em&gt;. &lt;span class="citation"&gt;(Bliss &lt;a href="#ref-Bliss:1934" role="doc-biblioref"&gt;1934&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>1</sup></a> is a regression-type model where the dependent variable only takes a finite number of values and the error term is normally distributed <span class="citation">(Agresti <a href="#ref-Agresti:2015" role="doc-biblioref">2015</a>)</span>. Its purpose is to estimate the probability that the dependent variable takes a certain, discrete value. The most common application are discrete choice scenarios. The dependent variable here is one of finitely many and mutually exclusive alternatives, and explanatory variables typically are characteristics of the deciders or the alternatives.</p>
<p>To be concrete, assume that we possess data of <span class="math inline">\(N\)</span> decision makers which choose between <span class="math inline">\(J \geq 2\)</span> alternatives<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;To be precise, the model name gets the prefix &lt;em&gt;multinomial&lt;/em&gt; in the case &lt;span class="math inline"&gt;\(J &amp;gt; 2\)&lt;/span&gt;.&lt;/p&gt;'><sup>2</sup></a> at each of <span class="math inline">\(T\)</span> choice occasions<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;For notational simplicity, the number of choice occasions &lt;span class="math inline"&gt;\(T\)&lt;/span&gt; is assumed to be the same for each decision maker here. However, we are not restricted to this case: {RprobitB} allows for unbalanced panels, i.e. varying &lt;span class="math inline"&gt;\(T\)&lt;/span&gt;. Of course, the cross-sectional case &lt;span class="math inline"&gt;\(T = 1\)&lt;/span&gt; is possible.&lt;/p&gt;'><sup>3</sup></a>. Specific to each decision maker, alternative and choice occasion, we furthermore observe <span class="math inline">\(P\)</span> choice attributes that we use to explain the choices. The continuous choice attributes cannot be linked directly to the discrete choices but must take a detour over a latent variable. In the discrete choice setting, this variable can be interpreted as the decider’s utility of a certain alternative. Decider <span class="math inline">\(n\)</span>’s utility <span class="math inline">\(U_{ntj}\)</span> for alternative <span class="math inline">\(j\)</span> at choice occasion <span class="math inline">\(t\)</span> is modeled as</p>
<p><span class="math display">\[\begin{equation}
  U_{ntj} = X_{ntj}'\beta + \epsilon_{ntj}
\end{equation}\]</span></p>
<p>for <span class="math inline">\(n=1,\dots,N\)</span>, <span class="math inline">\(t=1,\dots,T\)</span> and <span class="math inline">\(j=1,\dots,J\)</span>, where</p>
<ul>
<li><p><span class="math inline">\(X_{ntj}\)</span> is a (column) vector of <span class="math inline">\(P\)</span> characteristics of <span class="math inline">\(j\)</span> as faced by <span class="math inline">\(n\)</span> at <span class="math inline">\(t\)</span>,</p></li>
<li><p><span class="math inline">\(\beta \in {\mathbb R}^{P}\)</span> is a vector of coefficients,</p></li>
<li><p>and <span class="math inline">\((\epsilon_{nt:}) = (\epsilon_{nt1},\dots,\epsilon_{ntJ})' \sim \text{MVN}_{J} (0,\Sigma)\)</span> is the model’s error term vector for <span class="math inline">\(n\)</span> at <span class="math inline">\(t\)</span>, which in the probit model is assumed to be multivariate normally distributed with zero mean and covariance matrix <span class="math inline">\(\Sigma\)</span>.</p></li>
</ul>
<p>Now let <span class="math inline">\(y_{nt}=j\)</span> denote the event that decision maker <span class="math inline">\(n\)</span> chooses alternative <span class="math inline">\(j\)</span> at choice occasion <span class="math inline">\(t\)</span>. Assuming utility maximizing behavior of the decision makers<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;This in fact is a critical assumption because many studies show that humans do not decide in this rational sense in general, see for example &lt;span class="citation"&gt;Hewig et al. (&lt;a href="#ref-Hewig:2011" role="doc-biblioref"&gt;2011&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>4</sup></a>, the decisions are linked to the utilities via</p>
<p><span class="math display">\[\begin{equation}
y_{nt} = {\arg \max}_{j = 1,\dots,J} U_{ntj}.
\end{equation}\]</span></p>
<p>In the ordered probit case, the concept of decider’s having separate utilities for each alternative is no longer natural <span class="citation">(Train <a href="#ref-Train:2009" role="doc-biblioref">2009</a>)</span>. Instead, we model only a single utility value <span class="math display">\[\begin{align*}
  U_{nt} = X_{nt}'\beta_n + \epsilon_{nt}
\end{align*}\]</span> per decider <span class="math inline">\(n\)</span> and choice occasion <span class="math inline">\(t\)</span>, which we interpret as the “level of association” that <span class="math inline">\(n\)</span> has with the choice question. The utility value falls into discrete categories, which in turn are linked to the ordered alternatives <span class="math inline">\(j=1,\dots,J\)</span>. Formally, <span class="math display">\[\begin{align*}
   y_{nt} = \sum_{j = 1,\dots,J} j \cdot I(\gamma_{j-1} &lt; U_{nt} \leq \gamma_{j}),
\end{align*}\]</span> with end points <span class="math inline">\(\gamma_0 = -\infty\)</span> and <span class="math inline">\(\gamma_J = +\infty\)</span>, and thresholds <span class="math inline">\((\gamma_j)_{j=1,\dots,J-1}\)</span>. To ensure monotonicity of the thresholds, we rather estimate logarithmic threshold increments <span class="math inline">\(d_j\)</span> with <span class="math inline">\(\gamma_j = \sum_{i=1,\dots,j} \exp{d_i}\)</span>, <span class="math inline">\(j=1,\dots,J-1\)</span>.</p>
</div>
<div class="section level2">
<h2 id="choice-behavior-heterogeneity">Choice behavior heterogeneity<a class="anchor" aria-label="anchor" href="#choice-behavior-heterogeneity"></a>
</h2>
<p>Note that the coefficient vector <span class="math inline">\(\beta\)</span> is constant across decision makers. This assumption is too restrictive for many applications.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;For example, consider the case of modeling the choice of a means of transportation to work: It is easily imaginable that business people and pensioners do not share the same sensitivities towards cost and time.&lt;/p&gt;"><sup>5</sup></a> Heterogeneity in choice behavior can be modeled by imposing a distribution on <span class="math inline">\(\beta\)</span> such that each decider can have their own preferences.</p>
<p>Formally, we define <span class="math inline">\(\beta = (\alpha, \beta_n)\)</span>, where <span class="math inline">\(\alpha\)</span> are <span class="math inline">\(P_f\)</span> coefficients that are constant across deciders and <span class="math inline">\(\beta_n\)</span> are <span class="math inline">\(P_r\)</span> decider-specific coefficients. Consequently, <span class="math inline">\(P = P_f + P_r\)</span>. Now if <span class="math inline">\(P_r&gt;0\)</span>, <span class="math inline">\(\beta_n\)</span> is distributed according to some <span class="math inline">\(P_r\)</span>-variate distribution, the so-called mixing distribution.</p>
<p>Choosing an appropriate mixing distribution is a notoriously difficult task of the model specification. In many applications, different types of standard parametric distributions (including the normal, log-normal, uniform and tent distribution) are tried in conjunction with a likelihood value-based model selection, cf., <span class="citation">Train (<a href="#ref-Train:2009" role="doc-biblioref">2009</a>)</span>, Chapter 6. Instead, {RprobitB} implements the approach of <span class="citation">(Oelschläger and Bauer <a href="#ref-Oelschlaeger:2020" role="doc-biblioref">2020</a>)</span> to approximate any underlying mixing distribution by a mixture of (multivariate) Gaussian densities. More precisely, the underlying mixing distribution <span class="math inline">\(g_{P_r}\)</span> for the random coefficients <span class="math inline">\((\beta_n)_{n}\)</span> is approximated by a mixture of <span class="math inline">\(P_r\)</span>-variate normal densities <span class="math inline">\(\phi_{P_r}\)</span> with mean vectors <span class="math inline">\(b=(b_c)_{c}\)</span> and covariance matrices <span class="math inline">\(\Omega=(\Omega_c)_{c}\)</span> using <span class="math inline">\(C\)</span> components, i.e.</p>
<p><span class="math display">\[\begin{equation}
\beta_n\mid b,\Omega \sim \sum_{c=1}^{C} s_c \phi_{P_r} (\cdot \mid b_c,\Omega_c).
\end{equation}\]</span></p>
<p>Here, <span class="math inline">\((s_c)_{c}\)</span> are weights satisfying <span class="math inline">\(0 &lt; s_c\leq 1\)</span> for <span class="math inline">\(c=1,\dots,C\)</span> and <span class="math inline">\(\sum_c s_c=1\)</span>. One interpretation of the latent class model is obtained by introducing variables <span class="math inline">\(z=(z_n)_n\)</span>, allocating each decision maker <span class="math inline">\(n\)</span> to class <span class="math inline">\(c\)</span> with probability <span class="math inline">\(s_c\)</span>, i.e.</p>
<p><span class="math display">\[\begin{equation}
\text{Prob}(z_n=c)=s_c \land \beta_n \mid z,b,\Omega \sim \phi_{P_r}(\cdot \mid b_{z_n},\Omega_{z_n}).
\end{equation}\]</span></p>
<p>We call the resulting model the <em>latent class mixed multinomial probit model</em>. Note that the model collapses to the <em>(normally) mixed multinomial probit model</em> if <span class="math inline">\(P_r&gt;0\)</span> and <span class="math inline">\(C=1\)</span>, to the <em>multinomial probit model</em> if <span class="math inline">\(P_r=0\)</span> and to the <em>binary probit model</em> if additionally <span class="math inline">\(J=2\)</span>.</p>
</div>
<div class="section level2">
<h2 id="model-normalization">Model normalization<a class="anchor" aria-label="anchor" href="#model-normalization"></a>
</h2>
<p>As is well known, any utility model needs to be normalized with respect to level and scale in order to be identified <span class="citation">(Train <a href="#ref-Train:2009" role="doc-biblioref">2009</a>)</span>. Therefore, we consider the transformed model</p>
<p><span class="math display">\[\begin{equation}
\tilde{U}_{ntj} = \tilde{X}_{ntj}' \beta + \tilde{\epsilon}_{ntj},
\end{equation}\]</span></p>
<p><span class="math inline">\(n=1,\dots,N\)</span>, <span class="math inline">\(t=1,\dots,T\)</span> and <span class="math inline">\(j=1,\dots,J-1\)</span>, where (choosing <span class="math inline">\(J\)</span> as the reference alternative) <span class="math inline">\(\tilde{U}_{ntj} = U_{ntj} - U_{ntJ}\)</span>, <span class="math inline">\(\tilde{X}_{ntj} = X_{ntj} - X_{ntJ}\)</span>, and <span class="math inline">\(\tilde{\epsilon}_{ntj} = \epsilon_{ntj} - \epsilon_{ntJ}\)</span>, where <span class="math inline">\((\tilde{\epsilon}_{nt:}) = (\tilde{\epsilon}_{nt1},...,\tilde{\epsilon}_{nt(J-1)})' \sim \text{MVN}_{J-1} (0,\tilde{\Sigma})\)</span> and <span class="math inline">\(\tilde{\Sigma}\)</span> denotes a covariance matrix with the top-left element restricted to one.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;{RprobitB} provides an alternative to fixing an error term variance in order to normalize with respect to scale by fixing an element of &lt;span class="math inline"&gt;\(\alpha\)&lt;/span&gt;.&lt;/p&gt;'><sup>6</sup></a></p>
</div>
<div class="section level2">
<h2 id="parameter-labels-in-rprobitb">Parameter labels in {RprobitB}<a class="anchor" aria-label="anchor" href="#parameter-labels-in-rprobitb"></a>
</h2>
<p>In {RprobitB}, the probit model parameters are saved as an <code>RprobitB_parameter</code> object. Their labels are consistent with their definition in this vignette. For example:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">RprobitB</span><span class="fu">:::</span><span class="fu"><a href="../reference/RprobitB_parameter.html">RprobitB_parameter</a></span><span class="op">(</span></span>
<span>  P_f   <span class="op">=</span> <span class="fl">1</span>,           </span>
<span>  P_r   <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  J     <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  N     <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  C     <span class="op">=</span> <span class="fl">2</span>,          <span class="co"># the number of latent classes</span></span>
<span>  alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>,       <span class="co"># the fixed coefficient vector of length 'P_f'</span></span>
<span>  s     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.6</span>,<span class="fl">0.4</span><span class="op">)</span>, <span class="co"># the vector of class weights of length 'C'</span></span>
<span>  b     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,           </span>
<span>                      <span class="co"># the matrix of class means as columns of dimension 'P_r' x 'C'</span></span>
<span>  Omega <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>,<span class="fl">0.1</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">4</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,       </span>
<span>                      <span class="co"># the matrix of class covariance matrices as columns of dimension 'P_r^2' x 'C'</span></span>
<span>  Sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>,    <span class="co"># the differenced error term covariance matrix of dimension '(J-1)' x '(J-1)'</span></span>
<span>                      <span class="co"># the undifferenced error term covariance matrix is labeled 'Sigma_full'</span></span>
<span>  z     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,<span class="fl">5</span><span class="op">)</span>  <span class="co"># the vector of the allocation variables of length 'N'</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; alpha : 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; C : 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; s : double vector of length 2 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 0.6 0.4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; b : 2 x 2 matrix of doubles </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]   -1    1</span></span>
<span><span class="co">#&gt; [2,]    1    2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Omega : 4 x 2 matrix of doubles </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]    1  0.1</span></span>
<span><span class="co">#&gt; [2,]    0  0.0</span></span>
<span><span class="co">#&gt; [3,]    0  0.0</span></span>
<span><span class="co">#&gt; [4,]    1  0.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sigma : 2 x 2 matrix of doubles </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]    1    0</span></span>
<span><span class="co">#&gt; [2,]    0    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sigma_full : 3 x 3 matrix of doubles </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      [,1] [,2] [,3]</span></span>
<span><span class="co">#&gt; [1,]    2    1    1</span></span>
<span><span class="co">#&gt; [2,]    1    2    1</span></span>
<span><span class="co">#&gt; [3,]    1    1    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; beta : 2 x 10 matrix of doubles </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;         [,1]   [,2]    [,3] ...  [,10]</span></span>
<span><span class="co">#&gt; [1,] -1.3216 1.2176 -0.1633 ... 0.6693</span></span>
<span><span class="co">#&gt; [2,] -0.4707 1.7118  0.2542 ... 2.2730</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; z : integer vector of length 10 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1 2 1 ... 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; d : NA</span></span></code></pre></div>
<p>Mind that the matrix <code>Sigma_full</code> is not unique and can be any matrix that results into <code>Sigma</code> after the differencing, see the non-exported function <code>RprobitB:::undiff_Sigma()</code>.</p>
</div>
<div class="section level2 unnumbered">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references">
<div id="ref-Agresti:2015">
<p>Agresti, A. 2015. <em>Foundations of Linear and Generalized Linear Models.</em> Wiley.</p>
</div>
<div id="ref-Bliss:1934">
<p>Bliss, C. I. 1934. “The Method of Probits.” <em>Science</em> 79 (2037): 38–39. <a href="https://doi.org/10.1126/science.79.2037.38" class="external-link">https://doi.org/10.1126/science.79.2037.38</a>.</p>
</div>
<div id="ref-Hewig:2011">
<p>Hewig, J., N. Kretschmer, R. H. Trippe, H. Hecht, M. G. H. Coles, C. B. Holroyd, and W. H. R. Miltner. 2011. “Why Humans Deviate from Rational Choice.” <em>Psychophysiology</em> 48 (4). <a href="https://doi.org/10.1111/j.1469-8986.2010.01081.x" class="external-link">https://doi.org/10.1111/j.1469-8986.2010.01081.x</a>.</p>
</div>
<div id="ref-Oelschlaeger:2020">
<p>Oelschläger, L., and D. Bauer. 2020. “Bayes Estimation of Latent Class Mixed Multinomial Probit Models.” <em>TRB Annual Meeting 2021</em>.</p>
</div>
<div id="ref-Train:2009">
<p>Train, K. 2009. <em>Discrete Choice Methods with Simulation</em>. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511805271" class="external-link">https://doi.org/10.1017/CBO9780511805271</a>.</p>
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by <a href="https://loelschlaeger.de" class="external-link">Lennart Oelschläger</a>, <a href="https://de.wikipedia.org/wiki/Dietmar_Bauer" class="external-link">Dietmar Bauer</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
