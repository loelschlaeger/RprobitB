<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to RprobitB • RprobitB</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to RprobitB">
<meta property="og:description" content="RprobitB">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">RprobitB</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/data_management.html">1. Data management</a>
    </li>
    <li>
      <a href="../articles/introduction_to_RprobitB.html">Introduction to RprobitB</a>
    </li>
    <li>
      <a href="../articles/model_comparison.html">4. Model comparison</a>
    </li>
    <li>
      <a href="../articles/model_fitting.html">2. Model fitting</a>
    </li>
    <li>
      <a href="../articles/model_results.html">3. Model results</a>
    </li>
    <li>
      <a href="../articles/prediction.html">5. Prediction</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="introduction_to_RprobitB_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Introduction to RprobitB</h1>
                        <h4 class="author">Lennart Oelschläger</h4>
            
            <h4 class="date">2021-08-03</h4>
      
      
      <div class="hidden name"><code>introduction_to_RprobitB.Rmd</code></div>

    </div>

    
    
<p><strong>RprobitB</strong> is an R package that can be used to fit <a href="#lcmmnp-model">latent class mixed multinomial probit (LCMMNP) models</a> to simulated or empirical data. <strong>RprobitB</strong> is licensed under the GNU General Public License v3.0.</p>
<p>Do you found a bug or request a feature? Please <a href="https://github.com/loelschlaeger/RprobitB/issues">tell us</a>!</p>
<p>The package name <strong>RprobitB</strong> is a portmanteau, combining <em>R</em> (the programming language), <em>probit</em> (the model name) and <em>B</em> (for Bayes, the estimation method).</p>
<p><strong>RprobitB</strong> is able to</p>
<ul>
<li>estimate probit models on discrete choice panel data,</li>
<li>approximate any underlying mixing distributions through a mixture of normal distributions,</li>
<li>
<a href="#latent-class-updating-scheme">update the number of latent classes</a> within the algorithm on a weight-based strategy,</li>
<li>perform estimation in a Bayesian framework via Gibbs sampling, thereby avoiding numerical maximization or approximation of the model’s likelihood.</li>
</ul>
<p>At this point, you may ask yourself:</p>
<ol style="list-style-type: decimal">
<li><a href="#installing-rprobitb">How to install RprobitB?</a></li>
<li><a href="#using-rprobitb">How to use RprobitB?</a></li>
<li><a href="#lcmmnp-model">How is the LCMMNP model defined?</a></li>
<li><a href="#latent-class-updating-scheme">How does the latent class updating scheme work?</a></li>
<li><a href="#specifying-a-lcmmnp-model-in-rprobitb">How to specify a LCMMNP model in RprobitB?</a></li>
</ol>
<div id="installing-rprobitb" class="section level2">
<h2 class="hasAnchor">
<a href="#installing-rprobitb" class="anchor"></a>Installing RprobitB</h2>
<p>To install the latest version of <strong>RprobitB</strong>, run <code><a href="https://rdrr.io/r/utils/install.packages.html">install.packages("RprobitB")</a></code> in your R console.</p>
</div>
<div id="using-rprobitb" class="section level2">
<h2 class="hasAnchor">
<a href="#using-rprobitb" class="anchor"></a>Using RprobitB</h2>
<p>To use <strong>RprobitB</strong>, follow these steps:</p>
<ol style="list-style-type: decimal">
<li>Specify the model, see <a href="#specifying-a-lcmmnp-model-in-rprobitb">below</a> for details.</li>
<li>Run <code>RprobitB::fit_mnp(&lt;list of model specifications&gt;)</code>.</li>
<li>You get <a href="#on-screen-information">on-screen information</a> and <a href="#model-results">model results</a> in an output folder.</li>
</ol>
</div>
<div id="lcmmnp-model" class="section level2">
<h2 class="hasAnchor">
<a href="#lcmmnp-model" class="anchor"></a>LCMMNP model</h2>
<p>Assume that we observe the choices of <span class="math inline">\(N\)</span> decision makers which decide between <span class="math inline">\(J\)</span> alternatives at each of <span class="math inline">\(T\)</span> choice occasions.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Specific to each decision maker, alternative and choice occasion, we furthermore observe <span class="math inline">\(P_f+P_r\)</span> choice attributes that we use to explain the choices. The first <span class="math inline">\(P_f\)</span> attributes are connected to fixed coefficients, the other <span class="math inline">\(P_r\)</span> attributes to random coefficients following a joint distribution mixed across decision makers. Person <span class="math inline">\(n\)</span>’s utility <span class="math inline">\(\tilde{U}_{ntj}\)</span> for alternative <span class="math inline">\(j\)</span> at choice occasion <span class="math inline">\(t\)</span> is modelled as <span class="math display">\[\begin{equation}
\tilde{U}_{ntj} = \tilde{W}_{ntj}'\alpha + \tilde{X}_{ntj}'\beta_n + \tilde{\epsilon}_{ntj}
\end{equation}\]</span> for <span class="math inline">\(n=1,\dots,N\)</span>, <span class="math inline">\(t=1,\dots,T\)</span> and <span class="math inline">\(j=1,\dots,J\)</span>, where</p>
<ul>
<li>
<span class="math inline">\(\tilde{W}_{ntj}\)</span> is a vector of <span class="math inline">\(P_f\)</span> characteristics of <span class="math inline">\(j\)</span> as faced by <span class="math inline">\(n\)</span> at <span class="math inline">\(t\)</span> corresponding to the fixed coefficient vector <span class="math inline">\(\alpha \in {\mathbb R}^{P_f}\)</span>,</li>
<li>
<span class="math inline">\(\tilde{X}_{ntj}\)</span> is a vector of <span class="math inline">\(P_r\)</span> characteristics of <span class="math inline">\(j\)</span> as faced by <span class="math inline">\(n\)</span> at <span class="math inline">\(t\)</span> corresponding to the random, decision maker-specific coefficient vector <span class="math inline">\(\beta_n \in {\mathbb R}^{P_r}\)</span>, where <span class="math inline">\(\beta_n\)</span> is distributed according to some <span class="math inline">\(P_r\)</span>-variate distribution <span class="math inline">\(g_{P_r}\)</span>,</li>
<li>and <span class="math inline">\((\tilde{\epsilon}_{nt:}) = (\tilde{\epsilon}_{nt1},\dots,\tilde{\epsilon}_{ntJ})' \sim \text{MVN}_{J} (0,\tilde{\Sigma})\)</span> is the models’ error term vector for <span class="math inline">\(n\)</span> at <span class="math inline">\(t\)</span>, which in the probit model is assumed to be multivariate normally distributed with zero mean and covariance matrix <span class="math inline">\(\tilde{\Sigma}\)</span>.</li>
</ul>
<p>As is well known, any utility model needs to be normalized with respect to level and scale in order to be identified. Therefore, we consider the transformed model <span class="math display">\[\begin{equation}
U_{ntj} = W_{ntj}'\alpha + X_{ntj}'\beta_n + \epsilon_{ntj},
\end{equation}\]</span> <span class="math inline">\(n=1,\dots,N\)</span>, <span class="math inline">\(t=1,\dots,T\)</span> and <span class="math inline">\(j=1,\dots,J-1\)</span>, where (choosing <span class="math inline">\(J\)</span> as the reference alternative) <span class="math inline">\(U_{ntj}=\tilde{U}_{ntj} - \tilde{U}_{ntJ}\)</span>, <span class="math inline">\(W_{ntj}=\tilde{W}_{ntj}-\tilde{W}_{ntJ}\)</span>, <span class="math inline">\(X_{ntj}=\tilde{X}_{ntj}-\tilde{X}_{ntJ}\)</span> and <span class="math inline">\(\epsilon_{ntj}=\tilde{\epsilon}_{ntj}-\tilde{\epsilon}_{ntJ}\)</span>, where <span class="math inline">\((\epsilon_{nt:}) = (\epsilon_{nt1},...,\epsilon_{nt(J-1)})' \sim \text{MVN}_{J-1} (0,\Sigma)\)</span> and <span class="math inline">\(\Sigma\)</span> denotes a covariance matrix with the top-left element restricted to one. While taking utility differences in order to normalize the model with respect to level is a standard procedure, alternatives to fixing an error term variance in order to normalize with respect to scale exist, for example fixing an element of <span class="math inline">\(\alpha\)</span>.</p>
<p>Let <span class="math inline">\(y_{nt}=j\)</span> denote the event that decision maker <span class="math inline">\(n\)</span> chooses alternative <span class="math inline">\(j\)</span> at choice occasion <span class="math inline">\(t\)</span>. Assuming utility maximizing behaviour of the decision makers, the decisions are linked to the utilities via <span class="math display">\[\begin{equation}
y_{nt} = \sum_{j=1}^{J-1} j\cdot 1 \left (U_{ntj}=\max_i U_{nti}&gt;0 \right) + J \cdot 1\left (U_{ntj}&lt;0 ~\text{for all}~j\right), 
\end{equation}\]</span> where <span class="math inline">\(1(A)\)</span> equals <span class="math inline">\(1\)</span> if condition <span class="math inline">\(A\)</span> is true and <span class="math inline">\(0\)</span> else.</p>
<p>We approximate the mixing distribution <span class="math inline">\(g_{P_r}\)</span> for the random coefficients <span class="math inline">\(\beta=(\beta_n)_{n}\)</span> by a mixture of <span class="math inline">\(P_r\)</span>-variate normal densities <span class="math inline">\(\phi_{P_r}\)</span> with mean vectors <span class="math inline">\(b=(b_c)_{c}\)</span> and covariance matrices <span class="math inline">\(\Omega=(\Omega_c)_{c}\)</span> using <span class="math inline">\(C\)</span> components, i.e. <span class="math display">\[\begin{equation}
\beta_n\mid b,\Omega \sim \sum_{c=1}^{C} s_c \phi_{P_r} (\cdot \mid b_c,\Omega_c),
\end{equation}\]</span> where <span class="math inline">\((s_c)_{c}\)</span> are weights satisfying <span class="math inline">\(0 &lt; s_c\leq 1\)</span> for <span class="math inline">\(c=1,\dots,C\)</span> and <span class="math inline">\(\sum_c s_c=1\)</span>. One interpretation of the latent class model is obtained by introducing variables <span class="math inline">\(z=(z_n)_n\)</span> allocating each decision maker <span class="math inline">\(n\)</span> to class <span class="math inline">\(c\)</span> with probability <span class="math inline">\(s_c\)</span>, i.e. <span class="math display">\[\begin{equation}
\text{Prob}(z_n=c)=s_c \quad \text{and} \quad \beta_n \mid z,b,\Omega \sim \phi_{P_r}(\cdot \mid b_{z_n},\Omega_{z_n}).
\end{equation}\]</span> We call this model the <em>latent class mixed multinomial probit</em> (LCMMNP) model.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
</div>
<div id="latent-class-updating-scheme" class="section level2">
<h2 class="hasAnchor">
<a href="#latent-class-updating-scheme" class="anchor"></a>Latent class updating scheme</h2>
<p>Updating the number <span class="math inline">\(C\)</span> of latent classes is done within the algorithm by executing the following weight-based updating scheme.</p>
<ul>
<li>Class <span class="math inline">\(c\)</span> is removed, if <span class="math inline">\(s_c&lt;\epsilon_{\text{min}}\)</span>, i.e. if the class weight <span class="math inline">\(s_c\)</span> drops below some threshold <span class="math inline">\(\epsilon_{\text{min}}\)</span>. This case indicates that class <span class="math inline">\(c\)</span> has a negligible impact on the mixing distribution.</li>
<li>Class <span class="math inline">\(c\)</span> is splitted into two classes <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span>, if <span class="math inline">\(s_c&gt;\epsilon_\text{max}\)</span>. This case indicates that class <span class="math inline">\(c\)</span> has a high influence on the mixing distribution whose approximation can potentially be improved by increasing the resolution in directions of high variance. Therefore, the class means <span class="math inline">\(b_{c_1}\)</span> and <span class="math inline">\(b_{c_2}\)</span> of the new classes <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> are shifted in opposite directions from the class mean <span class="math inline">\(b_c\)</span> of the old class <span class="math inline">\(c\)</span> in the direction of the highest variance.</li>
<li>Two classes <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> are joined to one class <span class="math inline">\(c\)</span>, if <span class="math inline">\(\lVert b_{c_1} - b_{c_2} \rVert&lt;\epsilon_{\text{distmin}}\)</span>, i.e. if the euclidean distance between the class means <span class="math inline">\(b_{c_1}\)</span> and <span class="math inline">\(b_{c_2}\)</span> drops below some threshold <span class="math inline">\(\epsilon_{\text{distmin}}\)</span>. This case indicates location redundancy which should be repealed. The parameters of <span class="math inline">\(c\)</span> are assigned by adding the values of <span class="math inline">\(s\)</span> from <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> and averaging the values for <span class="math inline">\(b\)</span> and <span class="math inline">\(\Omega\)</span>.</li>
</ul>
</div>
<div id="specifying-a-lcmmnp-model-in-rprobitb" class="section level2">
<h2 class="hasAnchor">
<a href="#specifying-a-lcmmnp-model-in-rprobitb" class="anchor"></a>Specifying a LCMMNP model in RprobitB</h2>
<p><strong>RprobitB</strong> specifications are grouped in the named lists</p>
<ul>
<li>
<code>model</code> (model information),</li>
<li>
<code>data</code> (empirical data),</li>
<li>
<code>parm</code> (true parameter values),</li>
<li>
<code>lcus</code> (latent class updating scheme parameters),</li>
<li>
<code>init</code> (initial values for the Gibbs sampler),</li>
<li>
<code>prior</code> (prior parameters),</li>
<li>
<code>mcmc</code> (Markov chain Monte Carlo parameters),</li>
<li>
<code>norm</code> (normalization information),</li>
<li>
<code>out</code> (output settings).</li>
</ul>
<p>You can either specify none, all, or selected parameters. Unspecified parameters are set to <a href="#default-specifications-of-rprobitb">default values</a>.</p>
<div id="model" class="section level3">
<h3 class="hasAnchor">
<a href="#model" class="anchor"></a><code>model</code>
</h3>
<ul>
<li>
<code>N</code>, the number (greater or equal one) of decision makers</li>
<li>
<code>T</code>, the number (greater or equal one) or vector (of length <code>N</code>) of choice occasions for each decision maker</li>
<li>
<code>J</code>, the number (greater or equal two) of choice alternatives (fixed across decision makers and choice occasions)</li>
<li>
<code>P_f</code>, the number of attributes that are connected to fixed coefficients (can be zero)</li>
<li>
<code>P_r</code>, the number of attributes that are connected to random, decision maker specific coefficients (can be zero)</li>
<li>
<code>C</code>, the number of latent classes (ignored if <code>P_r = 0</code>)</li>
</ul>
</div>
<div id="data" class="section level3">
<h3 class="hasAnchor">
<a href="#data" class="anchor"></a><code>data</code>
</h3>
<p>If <code>data = NULL</code>, data is simulated from the model defined by <code>model</code> and <code>parm</code>.</p>
<p>To model empirical data, prepare your data using the <strong>RprobitB</strong> function <code>prepare_data()</code>. See the vignette <em>“How to work with empirical choice data?”</em> for details.</p>
</div>
<div id="parm" class="section level3">
<h3 class="hasAnchor">
<a href="#parm" class="anchor"></a><code>parm</code>
</h3>
<ul>
<li>
<code>alpha</code>, the fixed coefficient vector (of length <code>model[["P_f"]]</code>)</li>
<li>
<code>s</code>, the vector of class weights (of length <code>model[["C"]]</code>)</li>
<li>
<code>b</code>, the matrix of class means as columns (of dimension <code>model[["P_r"]]</code> x <code>model[["C"]]</code>)</li>
<li>
<code>Omega</code>, the matrix of class covariance matrices as columns (of dimension <code>model[["P_r"]]*model[["P_r"]]</code> x <code>model[["C"]]</code>)</li>
<li>
<code>Sigma</code>, the error term covariance matrix (of dimension <code>model[["J"]]-1</code> x <code>model[["J"]]-1</code>)</li>
</ul>
</div>
<div id="lcus" class="section level3">
<h3 class="hasAnchor">
<a href="#lcus" class="anchor"></a><code>lcus</code>
</h3>
<ul>
<li>
<code>do_lcus</code>, a boolean determining whether to update the number of latent classes</li>
<li>
<code>C0</code>, the initial number of latent classes</li>
<li>
<code>Cmax</code>, the maximum number of latent classes (greater or equal <code>lcus[["C0"]]</code>)</li>
<li>
<code>buffer</code>, the buffer for the updating (number of iterations to wait before the next update)</li>
<li>
<code>epsmin</code>, the threshold weight for removing latent classes (between 0 and 1)</li>
<li>
<code>epsmax</code>, the threshold weight for splitting latent classes (between 0 and 1)</li>
<li>
<code>distmin</code>, the threshold for joining latent classes (greater 0)</li>
</ul>
</div>
<div id="init" class="section level3">
<h3 class="hasAnchor">
<a href="#init" class="anchor"></a><code>init</code>
</h3>
<ul>
<li>
<code>at_true</code>, a boolean determining whether to initialize at the true parameter values (only for simulated data)</li>
<li>
<code>alpha0</code>, the initial fixed coefficient vector (of length <code>model[["P_f"]]</code>)</li>
<li>
<code>b0</code>, the initial matrix of the class means as columns (of dimension <code>model[["P_r"]]</code> x <code>model[["C"]]</code>)</li>
<li>
<code>Omega0</code>, the inital matrix of the class covariance matrices as columns (of dimension <code>model[["P_r"]]*model[["P_r"]]</code> x <code>model[["C"]]</code>)</li>
<li>
<code>Sigma0</code>, the initial error term covariance matrix (of dimension <code>model[["J"]]-1</code> x <code>model[["J"]]-1</code>)</li>
<li>
<code>U0</code>, the initial matrix of utilities (of dimension <code>model[["J"]]-1</code> x <code>model[["N"]]*max(model[["T"]])</code>)</li>
<li>
<code>beta0</code>, the initial matrix of random coefficients (of dimension <code>model[["P_r"]]</code> x <code>model[["N"]]</code>)</li>
<li>
<code>m0</code>, the initial vector of class sizes (of length <code>model[["C"]]</code>)</li>
</ul>
</div>
<div id="prior" class="section level3">
<h3 class="hasAnchor">
<a href="#prior" class="anchor"></a><code>prior</code>
</h3>
<p>A priori, <code>parm[["alpha"]]</code> ~ Normal(<code>eta</code>,<code>Psi</code>) with</p>
<ul>
<li>
<code>eta</code>, the expectation vector (of length <code>model[["P_f"]]</code>)</li>
<li>
<code>Psi</code>, the covariance matrix (of dimension <code>model[["P_f"]]</code> x <code>model[["P_f"]]</code>)</li>
</ul>
<p>A priori, <code>parm[["s"]]</code> ~ Dirichlet(<code>delta</code>) with</p>
<ul>
<li>
<code>delta</code>, the concentration parameter (of length 1)</li>
</ul>
<p>A priori, <code>parm[["b"]][,c]</code> ~ Normal(<code>xi</code>,<code>D</code>) with</p>
<ul>
<li>
<code>xi</code>, the expectation vector (of length <code>model[["P_r"]]</code>)</li>
<li>
<code>D</code>, the covariance matrix (of dimension <code>model[["P_r"]]</code> x <code>model[["P_r"]]</code>)</li>
</ul>
<p>A priori, <code><a href="https://rdrr.io/r/base/matrix.html">matrix(parm[["Omega"]][,c],nrow=model[["P_r"]],ncol=model[["P_r"]])</a></code> ~ Inverse_Wishart(<code>nu</code>,<code>Theta</code>) with</p>
<ul>
<li>
<code>nu</code>, the degrees of freedom (greater than <code>model[["P_r"]]</code>)</li>
<li>
<code>Theta</code>, the scale matrix (of dimension <code>model[["P_r"]]</code> x <code>model[["P_r"]]</code>)</li>
</ul>
<p>A priori, <code>parm[["Sigma"]]</code> ~ Inverse_Wishart(<code>kappa</code>,<code>E</code>) with</p>
<ul>
<li>
<code>kappa</code>, the degrees of freedom (greater than <code>model[["J"]]-1</code>)</li>
<li>
<code>E</code>, the scale matrix (of dimension <code>model[["J"]]-1</code> x <code>model[["J"]]-1</code>)</li>
</ul>
</div>
<div id="mcmc" class="section level3">
<h3 class="hasAnchor">
<a href="#mcmc" class="anchor"></a><code>mcmc</code>
</h3>
<ul>
<li>
<code>R</code>: the number of iterations</li>
<li>
<code>B</code>: the length of the burn-in period</li>
<li>
<code>Q</code>: the thinning parameter</li>
<li>
<code>nprint</code>: the step number for printing the sampling progress</li>
</ul>
</div>
<div id="norm" class="section level3">
<h3 class="hasAnchor">
<a href="#norm" class="anchor"></a><code>norm</code>
</h3>
<p><strong>RprobitB</strong> automatically normalizes with respect to level by computing utility differences, where <code>model[["J"]]</code> is the base alternative. The normalization with respect to scale can be specified:</p>
<ul>
<li>
<code>parameter</code>: the normalized parameter (either <code>"a"</code> for a fixed non-random linear coefficient or <code>"s"</code> for an error-term variance)</li>
<li>
<code>index</code>: the index of the parameter (between 1 and <code>model[["P_f"]]</code> or 1 and <code>model[["J"]]-1</code>, respectively)</li>
<li>
<code>value</code>: the value for the fixed parameter (greater 0 if <code>parameter = "s"</code>)</li>
</ul>
</div>
<div id="out" class="section level3">
<h3 class="hasAnchor">
<a href="#out" class="anchor"></a><code>out</code>
</h3>
<ul>
<li>
<code>id</code>: a character, identifying the model</li>
<li>
<code>rdir</code>: a character, defining the (relative) path of the folder with the model results</li>
<li>
<code>pp</code>: a boolean, determining whether progress plots should be created (in any case only if <code>model$P_r=2</code>)</li>
<li>
<code>results</code>: a boolean, determining whether estimated parameters should be returned by the function <code>rpb</code>.</li>
<li>
<code>waic</code>: a boolean, determining whether to compute the widely applicable information criterion (WAIC)</li>
</ul>
</div>
</div>
<div id="default-specifications-of-rprobitb" class="section level2">
<h2 class="hasAnchor">
<a href="#default-specifications-of-rprobitb" class="anchor"></a>Default specifications of RprobitB</h2>
<div id="model-1" class="section level3">
<h3 class="hasAnchor">
<a href="#model-1" class="anchor"></a><code>model</code>
</h3>
<ul>
<li><code>N = 100</code></li>
<li><code>T = 10</code></li>
<li><code>J = 2</code></li>
<li><code>P_f = 1</code></li>
<li><code>P_r = 0</code></li>
<li><code>C = NA</code></li>
</ul>
</div>
<div id="data-1" class="section level3">
<h3 class="hasAnchor">
<a href="#data-1" class="anchor"></a><code>data</code>
</h3>
<p><code>NULL</code></p>
</div>
<div id="parm-1" class="section level3">
<h3 class="hasAnchor">
<a href="#parm-1" class="anchor"></a><code>parm</code>
</h3>
<p>Per default, parameters are randomly drawn.</p>
</div>
<div id="lcus-1" class="section level3">
<h3 class="hasAnchor">
<a href="#lcus-1" class="anchor"></a><code>lcus</code>
</h3>
<ul>
<li><code>do_lcus = FALSE</code></li>
<li><code>C0 = 5</code></li>
<li><code>Cmax = 10</code></li>
<li><code>buffer = 100</code></li>
<li><code>epsmin = 0.01</code></li>
<li><code>epsmax = 0.99</code></li>
<li><code>distmin = 0.1</code></li>
</ul>
</div>
<div id="init-1" class="section level3">
<h3 class="hasAnchor">
<a href="#init-1" class="anchor"></a><code>init</code>
</h3>
<ul>
<li><code>at_true = FALSE</code></li>
<li>
<code>alpha0</code>: zero vector</li>
<li>
<code>b0</code>: zero matrices for each latent class</li>
<li>
<code>Omega0</code>: unity matrices for each latent class</li>
<li>
<code>Sigma0</code>: unity matrix</li>
<li>
<code>U0</code>: zero matrix</li>
<li>
<code>beta0</code>: zero matrix</li>
<li>
<code>m0</code>: each latent class has twice the membership than the previous one</li>
</ul>
</div>
<div id="prior-1" class="section level3">
<h3 class="hasAnchor">
<a href="#prior-1" class="anchor"></a><code>prior</code>
</h3>
<ul>
<li><code>eta = numeric(model[["P_f"]])</code></li>
<li><code>Psi = matrix(1,model[["P_f"]],model[["P_f"]]); diag(Psi) = 5</code></li>
<li><code>delta = 1</code></li>
<li><code>xi = numeric(model[["P_r"]])</code></li>
<li><code>D = matrix(1,model[["P_r"]],model[["P_r"]]); diag(D) = 5</code></li>
<li><code>nu = model[["P_r"]]+2</code></li>
<li><code>Theta = matrix(1,model[["P_r"]],model[["P_r"]]); diag(Theta) = 5</code></li>
<li><code>kappa = model[["J"]]+1</code></li>
<li><code>E = matrix(1,model[["J"]]-1,model[["J"]]-1); diag(E) = 5</code></li>
</ul>
</div>
<div id="mcmc-1" class="section level3">
<h3 class="hasAnchor">
<a href="#mcmc-1" class="anchor"></a><code>mcmc</code>
</h3>
<ul>
<li><code>R = 10000</code></li>
<li><code>B = R/2</code></li>
<li><code>Q = 100</code></li>
<li><code>nprint = floor(R/10)</code></li>
</ul>
</div>
<div id="norm-1" class="section level3">
<h3 class="hasAnchor">
<a href="#norm-1" class="anchor"></a><code>norm</code>
</h3>
<ul>
<li><code>parameter = "s"</code></li>
<li><code>index = "1"</code></li>
<li><code>value = "1"</code></li>
</ul>
</div>
<div id="out-1" class="section level3">
<h3 class="hasAnchor">
<a href="#out-1" class="anchor"></a><code>out</code>
</h3>
<ul>
<li><code>id = test</code></li>
<li><code>rdir = tempdir()</code></li>
<li><code>pp = FALSE</code></li>
<li><code>return = FALSE</code></li>
<li><code>waic = FALSE</code></li>
</ul>
</div>
</div>
<div id="example" class="section level2">
<h2 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h2>
<p>The code below fits a mixed multinomial probit model with</p>
<ul>
<li>
<code>P_f = 1</code> fixed<br>
</li>
<li>and <code>P_r = 2</code> random coefficients</li>
</ul>
<p>to simulated data with</p>
<ul>
<li>
<code>N = 100</code> decision makers,</li>
<li>variable choice occasions between <code>T = 10</code> and <code>T = 20</code>,</li>
<li>
<code>J = 3</code> choice alternatives,</li>
<li>and <code>C = 2</code> true latent classes.</li>
</ul>
<p>The number of latent classes is updated, because <code>do_lcus = TRUE</code> is set. The Gibbs sampler draws <code>R = 20000</code> samples. By default, the model is named <code>id = "test"</code> and results are saved in <code>rdir = "tempdir()"</code> (the path of the per-session temporary directory).</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>

<span class="co">### model specification</span>
<span class="va">model</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"N"</span> <span class="op">=</span> <span class="fl">100</span>, <span class="st">"T"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">10</span><span class="op">:</span><span class="fl">20</span>,<span class="fl">100</span>,replace<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span>, <span class="st">"J"</span> <span class="op">=</span> <span class="fl">3</span>, <span class="st">"P_f"</span> <span class="op">=</span> <span class="fl">1</span>, <span class="st">"P_r"</span> <span class="op">=</span> <span class="fl">2</span>, <span class="st">"C"</span> <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">lcus</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"do_lcus"</span> <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">mcmc</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"R"</span> <span class="op">=</span> <span class="fl">20000</span><span class="op">)</span>

<span class="co">### start estimation (about 3 minutes computation time)</span>
<span class="fu">RprobitB</span><span class="fu">::</span><span class="fu">fit_mnp</span><span class="op">(</span><span class="st">"model"</span> <span class="op">=</span> <span class="va">model</span>, <span class="st">"lcus"</span> <span class="op">=</span> <span class="va">lcus</span>, <span class="st">"mcmc"</span> <span class="op">=</span> <span class="va">mcmc</span><span class="op">)</span></code></pre></div>
</div>
<div id="on-screen-information" class="section level2">
<h2 class="hasAnchor">
<a href="#on-screen-information" class="anchor"></a>On-screen information</h2>
<p>During estimation, you get the following on-screen information:</p>
<ul>
<li>a summary of the model, normalization, and Gibbs sampler settings, and (if <code>lcus[["do_lcus"]]=TRUE</code>) the latent class updating scheme parameters</li>
<li>the sampling progress with expected time for completion (ETA)</li>
<li>a summary of the posterior distribution (where <em>x.</em> denotes latent class number <em>x</em> in case of <code>lcus[["do_lcus"]]=TRUE</code>) with
<ul>
<li>the true parameter values (only for simulated data)</li>
<li>the posterior mean</li>
<li>the posterior standard deviation</li>
<li>the 5% and 95% quantile of the posterior</li>
<li>the <a href="https://bookdown.org/rdpeng/advstatcomp/monitoring-convergence.html#gelman-rubin-statistic">Gelman-Rubin statistic</a> (R^)</li>
</ul>
</li>
<li>the model’s WAIC value (if <code>out[["waic"]]=TRUE</code>)</li>
<li>the path to the model results</li>
</ul>
</div>
<div id="model-results" class="section level2">
<h2 class="hasAnchor">
<a href="#model-results" class="anchor"></a>Model results</h2>
<p>In the output folder <code>out[["rdir"]]/out[["id"]]</code>, you can find the files</p>
<ul>
<li>
<em>protocol.txt</em>, a copy of the on-screen information,</li>
<li>
<em>several .rds-files</em> of inputs and outputs,</li>
<li>and different model visualizations:
<ul>
<li>
<em>acf.pdf</em>, the autocorrelation of the Gibbs samples with the <a href="https://mc-stan.org/docs/2_18/reference-manual/effective-sample-size-section.html">effective sample size</a>,</li>
<li>
<em>marginal.pdf</em>, estimated marginal distributions,</li>
<li>
<em>trace.pdf</em>, plots of the traces of the Gibbs samples,</li>
<li>and, if <code>model[["P_r"]] &gt; 0</code>, <em>contour.pdf</em>, contour plot and progress contour plots (only if <code>out[["pp"]] = TRUE</code>) of the Gibbs samples.</li>
</ul>
</li>
</ul>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-Albert:93">
<p>Albert, James H., and Siddhartha Chib. 1993. “Bayesian Analysis of Binary and Polychotomous Response Data.” <em>Journal of the American Statistical Association</em> 88.</p>
</div>
<div id="ref-Allenby:98">
<p>Allenby, Greg M., and Peter Rossi. 1998. “Marketing Models of Consumer Heterogeneity.” <em>Journal of Econometrics</em> 89.</p>
</div>
<div id="ref-Bauer:19">
<p>Bauer, Dietmar, Sebastian Büscher, and Manuel Batram. 2019. “Non-Parameteric Estiation of Mixed Discrete Choice Models.” <em>Second International Choice Modelling Conference in Kobe</em>.</p>
</div>
<div id="ref-mlogit">
<p>Croissant, Yves. 2020. “Estimation of Random Utility Models in R: The mlogit Package.” <em>Journal of Statistical Software</em> 95 (11): 1–41. <a href="https://doi.org/10.18637/jss.v095.i11">https://doi.org/10.18637/jss.v095.i11</a>.</p>
</div>
<div id="ref-Geweke:98">
<p>Geweke, John. 1998. “Efficient Simulation from the Multivariate Normal and Student-T Distributions Subject to Linear Constraints and the Evaluation of Constraint Probabilities.” <em>Comput. Sci. Statist.</em> 23.</p>
</div>
<div id="ref-Imai:05">
<p>Imai, Kosuke, and David A. van Dyk. 2005. “A Bayesian Analysis of the Multinomial Probit Model Using Marginal Data Augmentation.” <em>Journal of Econometrics</em> 124.</p>
</div>
<div id="ref-McCulloch:94">
<p>McCulloch, Robert, and Peter Rossi. 1994. “An Exact Likelihood Analysis of the Multinomial Probit Model.” <em>Journal of Econometrics</em> 64.</p>
</div>
<div id="ref-Mori:14">
<p>Mori, Harunori. 2014. “Bayes Estimation in the Hierarchical Multinomial Probit Model.” <em>Journal of the Japan Statistical Society</em> 44.</p>
</div>
<div id="ref-Nobile:98">
<p>Nobile, Agostino. 1998. “A Hybrid Markov Chain for the Bayesian Analysis of the Multinomial Probit Model.” <em>Statistics and Computing</em> 8.</p>
</div>
<div id="ref-Oel:20">
<p>Oelschläger, Lennart, and Dietmar Bauer. 2020. “Bayes Estimation of Latent Class Mixed Multinomial Probit Models.” <em>TRB Annual Meeting 2021</em>.</p>
</div>
<div id="ref-bayesm">
<p>Rossi, Peter. 2019. “Bayesm: Bayesian Inference for Marketing/Micro-Econometrics.” <a href="https://CRAN.R-project.org/package=bayesm">https://CRAN.R-project.org/package=bayesm</a>.</p>
</div>
<div id="ref-Scaccia:10">
<p>Scaccia, Luisa, and Edoardo Marcucci. 2010. “Bayesian Flexible Modelling of Mixed Logit Models.” <em>Proceedings from the 19th International Conference on Computational Statistics</em>.</p>
</div>
<div id="ref-Train:09">
<p>Train, Kenneth. 2009. <em>Discrete Choice Methods with Simulation</em>. 2. ed. Cambridge Univ. Press.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>For notational simplicity, the number of choice occasions <span class="math inline">\(T\)</span> is assumend to be the same for each decision maker here. However, <strong>RprobitB</strong> allows for a different number of choice occasions for each decision maker.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>We note that the model collapses to the (normally) mixed multinomial probit model if <span class="math inline">\(P_r&gt;0\)</span> and <span class="math inline">\(C=1\)</span> and to the basic multinomial probit model if <span class="math inline">\(P_r=0\)</span>.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Lennart Oelschläger, Dietmar Bauer.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
