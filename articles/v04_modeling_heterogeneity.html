<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Modeling heterogeneity • RprobitB</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Modeling heterogeneity">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">RprobitB</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.4</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/RprobitB.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/v01_model_definition.html">Model definition</a></li>
    <li><a class="dropdown-item" href="../articles/v02_choice_data.html">Choice data</a></li>
    <li><a class="dropdown-item" href="../articles/v03_model_fitting.html">Model fitting</a></li>
    <li><a class="dropdown-item" href="../articles/v04_modeling_heterogeneity.html">Modeling heterogeneity</a></li>
    <li><a class="dropdown-item" href="../articles/v05_choice_prediction.html">Choice prediction</a></li>
    <li><a class="dropdown-item" href="../articles/v06_model_selection.html">Model selection</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/loelschlaeger/RprobitB/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Modeling heterogeneity</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/loelschlaeger/RprobitB/blob/main/vignettes/v04_modeling_heterogeneity.Rmd" class="external-link"><code>vignettes/v04_modeling_heterogeneity.Rmd</code></a></small>
      <div class="d-none name"><code>v04_modeling_heterogeneity.Rmd</code></div>
    </div>

    
    
<p>In the vignette on the model definition, we pointed out that the
probit model can capture choice behavior heterogeneity by imposing a
mixing distribution on the coefficient vector. The implementation in
<a href="https://loelschlaeger.de/RprobitB/">RprobitB</a> is explained in this vignette<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;This vignette is built using R 4.4.1 with the
&lt;a href="https://loelschlaeger.de/RprobitB/"&gt;RprobitB&lt;/a&gt; 1.1.4 package.&lt;/p&gt;'><sup>1</sup></a>.</p>
<div class="section level2">
<h2 id="estimating-a-joint-normal-mixing-distribution">Estimating a joint normal mixing distribution<a class="anchor" aria-label="anchor" href="#estimating-a-joint-normal-mixing-distribution"></a>
</h2>
<p>The <a href="https://cran.r-project.org/package=mlogit" class="external-link">mlogit</a> package <span class="citation">(<a href="#ref-Croissant2020">Croissant 2020</a>)</span> contains the data
set <code>Electricity</code>, in which residential electricity customers
were asked to decide between four hypothetical electricity suppliers.
The suppliers differed in 6 characteristics:</p>
<ol style="list-style-type: decimal">
<li>their fixed price <code>pf</code> per kWh,</li>
<li>their contract length <code>cf</code>,</li>
<li>a boolean <code>loc</code>, indicating whether the supplier is a
local company,</li>
<li>a boolean <code>wk</code>, indicating whether the supplier is a well
known company,</li>
<li>a boolean <code>tod</code>, indicating whether the supplier offers a
time-of-day electricity price (which is higher during the day and lower
during the night), and</li>
<li>a boolean <code>seas</code>, indicating whether the supplier’s price
is seasonal dependent.</li>
</ol>
<p>This constitutes a choice situation where choice behavior
heterogeneity is expected: some customers might prefer a time-of-day
electricity price (because they may be not at home during the day),
while others can have the opposite preference. Ideally these differences
in preferences should be modeled using characteristics of the deciders.
In many cases (as in this data set) we do not have adequate information.
Instead these differences in taste can be captured by means of a mixing
distribution for the <code>tod</code> coefficient. This corresponds to
the assumption of a random coefficient from the underlying mixing
distribution to be drawn for each decider. We can use the estimated
mixing distribution to determine for example the share of deciders that
have a positive versus negative preference towards time-of-day
electricity prices.</p>
<p>Additionally, we expect correlations between the random coefficients
to certain covariates, for example a positive correlation between the
influence of <code>loc</code> and <code>wk</code>: deciders that prefer
local suppliers might also prefer well known companies due to
recommendations and past experiences, although they might be more
expensive than unknown suppliers. The fitted multivariate normal
distribution will reveal these correlations.</p>
<p>The following lines prepare the <code>Electricity</code> data set for
estimation. We use the convenience function <code><a href="../reference/as_cov_names.html">as_cov_names()</a></code>
that relabels the data columns for alternative specific covariates into
the required format
“<code>&lt;covariate&gt;_&lt;alternative&gt;</code>”, compare to the
vignette on choice data. Via the
<code>re = c("cl","loc","wk","tod","seas")</code> argument, we specify
that we want to model random effects for all but the price coefficient,
which we will fix to <code>-1</code> to interpret the other estimates as
monetary values.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"Electricity"</span>, package <span class="op">=</span> <span class="st">"mlogit"</span><span class="op">)</span></span>
<span><span class="va">Electricity</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/as_cov_names.html">as_cov_names</a></span><span class="op">(</span><span class="va">Electricity</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"pf"</span>, <span class="st">"cl"</span>, <span class="st">"loc"</span>, <span class="st">"wk"</span>, <span class="st">"tod"</span>, <span class="st">"seas"</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prepare_data.html">prepare_data</a></span><span class="op">(</span></span>
<span>  form <span class="op">=</span> <span class="va">choice</span> <span class="op">~</span> <span class="va">pf</span> <span class="op">+</span> <span class="va">cl</span> <span class="op">+</span> <span class="va">loc</span> <span class="op">+</span> <span class="va">wk</span> <span class="op">+</span> <span class="va">tod</span> <span class="op">+</span> <span class="va">seas</span> <span class="op">|</span> <span class="fl">0</span>,</span>
<span>  choice_data <span class="op">=</span> <span class="va">Electricity</span>,</span>
<span>  re <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"cl"</span>, <span class="st">"loc"</span>, <span class="st">"wk"</span>, <span class="st">"tod"</span>, <span class="st">"seas"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">model_elec</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_model.html">fit_model</a></span><span class="op">(</span><span class="va">data</span>, R <span class="op">=</span> <span class="fl">1000</span>, scale <span class="op">=</span> <span class="st">"pf := -1"</span><span class="op">)</span></span></code></pre></div>
<p>Calling the <code><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef()</a></code> method on the estimated model also
returns the estimated (marginal) variances of the mixing distribution
besides the average mean effects:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">model_elec</span><span class="op">)</span></span>
<span><span class="co">#&gt;         Estimate   (sd) Variance   (sd)</span></span>
<span><span class="co">#&gt; 1   pf     -1.00 (0.00)       NA   (NA)</span></span>
<span><span class="co">#&gt; 2   cl     -0.26 (0.03)     0.31 (0.04)</span></span>
<span><span class="co">#&gt; 3  loc      2.90 (0.20)     7.55 (0.88)</span></span>
<span><span class="co">#&gt; 4   wk      2.11 (0.16)     3.95 (0.52)</span></span>
<span><span class="co">#&gt; 5  tod     -9.75 (0.22)    11.83 (1.48)</span></span>
<span><span class="co">#&gt; 6 seas     -9.93 (0.18)     6.43 (0.78)</span></span></code></pre></div>
<p>By the sign of the estimates we can for example deduce, that the
existence of the time-of-day electricity price <code>tod</code> in the
contract has a negative effect. However, the deciders are very
heterogeneous here, because the estimated variance of this coefficient
is large. The same holds for the contract length <code>cl</code>. In
particular, the estimated share of the population that prefers to have a
longer contract length equals:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cl_mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">model_elec</span><span class="op">)</span><span class="op">[</span><span class="st">"cl"</span>, <span class="st">"mean"</span><span class="op">]</span></span>
<span><span class="va">cl_sd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">model_elec</span><span class="op">)</span><span class="op">[</span><span class="st">"cl"</span>, <span class="st">"var"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">pnorm</a></span><span class="op">(</span><span class="va">cl_mu</span> <span class="op">/</span> <span class="va">cl_sd</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.3181556</span></span></code></pre></div>
<p>The correlation between the covariates can be accessed as follows:<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;Setting &lt;code&gt;cor = FALSE&lt;/code&gt; instead returns the
estimated covariance matrix.&lt;/p&gt;"><sup>2</sup></a></p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cov_mix.html">cov_mix</a></span><span class="op">(</span><span class="va">model_elec</span>, cor <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt;               cl        loc           wk         tod         seas</span></span>
<span><span class="co">#&gt; cl    1.00000000 0.11421860  0.075483676 -0.06974856 -0.143653990</span></span>
<span><span class="co">#&gt; loc   0.11421860 1.00000000  0.799992150  0.13987311  0.010732549</span></span>
<span><span class="co">#&gt; wk    0.07548368 0.79999215  1.000000000  0.13084611 -0.006137288</span></span>
<span><span class="co">#&gt; tod  -0.06974856 0.13987311  0.130846113  1.00000000  0.536239533</span></span>
<span><span class="co">#&gt; seas -0.14365399 0.01073255 -0.006137288  0.53623953  1.000000000</span></span></code></pre></div>
<p>Here, we see the confirmation of our initial assumption about a high
correlation between <code>loc</code> and <code>wk</code>. The pairwise
mixing distributions can be visualized via calling the
<code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> method with the additional argument
<code>type = mixture</code>:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model_elec</span>, type <span class="op">=</span> <span class="st">"mixture"</span><span class="op">)</span></span></code></pre></div>
<p><img src="img%2Fplot-mixture-model-elec-1.png" width="75%" style="display: block; margin: auto;"></p>
</div>
<div class="section level2">
<h2 id="estimating-latent-classes">Estimating latent classes<a class="anchor" aria-label="anchor" href="#estimating-latent-classes"></a>
</h2>
<p>More generally, <a href="https://loelschlaeger.de/RprobitB/">RprobitB</a> allows to specify a Gaussian
mixture as the mixing distribution. In particular,</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>∼</mo><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mtext mathvariant="normal">MVN</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>b</mi><mi>c</mi></msub><mo>,</mo><msub><mi>Ω</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex"> \beta \sim \sum_{c=1}^C \text{MVN} (b_c,\Omega_c).</annotation></semantics></math>
This specification allows for a) a better approximation of the true
underlying mixing distribution and b) a preference based classification
of the deciders.</p>
<p>To estimate a latent mixture, specify a named list
<code>latent_classes</code> with the following arguments and submit it
to the estimation routine <code>fit_model</code>:</p>
<ul>
<li><p><code>C</code>, the fixed number (greater or equal 1) of latent
classes, which is set to 1 per default, <a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;If either &lt;code&gt;weight_update = TRUE&lt;/code&gt; or
&lt;code&gt;dp_update = TRUE&lt;/code&gt; (i.e. if classes are updated),
&lt;code&gt;C&lt;/code&gt; equals the initial number of latent classes.&lt;/p&gt;"><sup>3</sup></a></p></li>
<li><p><code>weight_update</code>, a boolean, set to <code>TRUE</code>
for a weight-based update of the latent classes, see below,</p></li>
<li><p><code>dp_update</code>, a boolean, set to <code>TRUE</code> for a
Dirichlet process-based update of the latent classes, see
below,</p></li>
<li><p><code>Cmax</code>, the maximum number of latent classes, set to
<code>10</code> per default.</p></li>
</ul>
<div class="section level3">
<h3 id="weight-based-update-of-the-latent-classes">Weight-based update of the latent classes<a class="anchor" aria-label="anchor" href="#weight-based-update-of-the-latent-classes"></a>
</h3>
<p>The following weight-based updating scheme is analogue to <span class="citation">Bauer, Büscher, and Batram (<a href="#ref-Bauer2019">2019</a>)</span> and executed within the burn-in
period:</p>
<ul>
<li><p>We remove class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>,
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>c</mi></msub><mo>&lt;</mo><msub><mi>ε</mi><mtext mathvariant="normal">min</mtext></msub></mrow><annotation encoding="application/x-tex">s_c&lt;\varepsilon_{\text{min}}</annotation></semantics></math>,
i.e. if the class weight
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>s</mi><mi>c</mi></msub><annotation encoding="application/x-tex">s_c</annotation></semantics></math>
drops below some threshold
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ε</mi><mtext mathvariant="normal">min</mtext></msub><annotation encoding="application/x-tex">\varepsilon_{\text{min}}</annotation></semantics></math>.
This case indicates that class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>
has a negligible impact on the mixing distribution.</p></li>
<li><p>We split class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>
into two classes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mn>1</mn></msub><annotation encoding="application/x-tex">c_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mn>2</mn></msub><annotation encoding="application/x-tex">c_2</annotation></semantics></math>,
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>c</mi></msub><mo>&gt;</mo><msub><mi>ε</mi><mtext mathvariant="normal">max</mtext></msub></mrow><annotation encoding="application/x-tex">s_c&gt;\varepsilon_\text{max}</annotation></semantics></math>.
This case indicates that class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>
has a high influence on the mixing distribution whose approximation can
potentially be improved by increasing the resolution in directions of
high variance. Therefore, the class means
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><msub><mi>c</mi><mn>1</mn></msub></msub><annotation encoding="application/x-tex">b_{c_1}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><msub><mi>c</mi><mn>2</mn></msub></msub><annotation encoding="application/x-tex">b_{c_2}</annotation></semantics></math>
of the new classes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mn>1</mn></msub><annotation encoding="application/x-tex">c_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mn>2</mn></msub><annotation encoding="application/x-tex">c_2</annotation></semantics></math>
are shifted in opposite directions from the class mean
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><mi>c</mi></msub><annotation encoding="application/x-tex">b_c</annotation></semantics></math>
of the old class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>
in the direction of the highest variance.</p></li>
<li><p>We join two classes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mn>1</mn></msub><annotation encoding="application/x-tex">c_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mn>2</mn></msub><annotation encoding="application/x-tex">c_2</annotation></semantics></math>
to one class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>,
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">∥</mo><msub><mi>b</mi><msub><mi>c</mi><mn>1</mn></msub></msub><mo>−</mo><msub><mi>b</mi><msub><mi>c</mi><mn>2</mn></msub></msub><mo stretchy="false" form="postfix">∥</mo><mo>&lt;</mo><msub><mi>ε</mi><mtext mathvariant="normal">distmin</mtext></msub></mrow><annotation encoding="application/x-tex">\lVert b_{c_1} - b_{c_2} \rVert&lt;\varepsilon_{\text{distmin}}</annotation></semantics></math>,
i.e. if the euclidean distance between the class means
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><msub><mi>c</mi><mn>1</mn></msub></msub><annotation encoding="application/x-tex">b_{c_1}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><msub><mi>c</mi><mn>2</mn></msub></msub><annotation encoding="application/x-tex">b_{c_2}</annotation></semantics></math>
drops below some threshold
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ε</mi><mtext mathvariant="normal">distmin</mtext></msub><annotation encoding="application/x-tex">\varepsilon_{\text{distmin}}</annotation></semantics></math>.
This case indicates location redundancy which should be repealed. The
parameters of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>
are assigned by adding the values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mn>1</mn></msub><annotation encoding="application/x-tex">c_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mn>2</mn></msub><annotation encoding="application/x-tex">c_2</annotation></semantics></math>
and averaging the values for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Ω</mi><annotation encoding="application/x-tex">\Omega</annotation></semantics></math>.</p></li>
</ul>
<p>These rules contain choices on the values for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ε</mi><mtext mathvariant="normal">min</mtext></msub><annotation encoding="application/x-tex">\varepsilon_{\text{min}}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ε</mi><mtext mathvariant="normal">max</mtext></msub><annotation encoding="application/x-tex">\varepsilon_{\text{max}}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ε</mi><mtext mathvariant="normal">distmin</mtext></msub><annotation encoding="application/x-tex">\varepsilon_{\text{distmin}}</annotation></semantics></math>.
The adequate value for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ε</mi><mtext mathvariant="normal">distmin</mtext></msub><annotation encoding="application/x-tex">\varepsilon_{\text{distmin}}</annotation></semantics></math>
depends on the scale of the parameters. Per default,
<a href="https://loelschlaeger.de/RprobitB/">RprobitB</a> sets</p>
<ul>
<li><p><code>epsmin = 0.01</code>,</p></li>
<li><p><code>epsmax = 0.99</code>, and</p></li>
<li><p><code>distmin = 0.1</code>.</p></li>
</ul>
<p>These values can be adapted through the <code>latent_class</code>
list.</p>
</div>
<div class="section level3">
<h3 id="dirichlet-process-based-update-of-the-latent-classes">Dirichlet process-based update of the latent classes<a class="anchor" aria-label="anchor" href="#dirichlet-process-based-update-of-the-latent-classes"></a>
</h3>
<p>As an alternative to the weight-based updating scheme to determine
the correct number
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
of latent classes, <a href="https://loelschlaeger.de/RprobitB/">RprobitB</a> implements the Dirichlet
process.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;A similar approach in the context of discrete choice can
be found in &lt;span class="citation"&gt;Burda, Harding, and Hausman (&lt;a href="#ref-Burda2008"&gt;2008&lt;/a&gt;)&lt;/span&gt;, where the Dirichlet process is
applied to estimate a mixed logit-probit model.&lt;/p&gt;'><sup>4</sup></a>
The Dirichlet Process is a Bayesian nonparametric method, where
nonparametric means that the number of model parameters can
theoretically grow to infinity. The method allows to add more mixture
components to the mixing distribution if needed for a better
approximation, see <span class="citation">Neal (<a href="#ref-Neal2000">2000</a>)</span> for a documentation of the general
case. The literature offers many representations of the method,
including the Chinese Restaurant Process <span class="citation">(<a href="#ref-Aldous1985">Aldous 1985</a>)</span>, the stick-braking
metaphor <span class="citation">(<a href="#ref-Sethuraman1994">Sethuraman 1994</a>)</span>, and the Polya
Urn model <span class="citation">(<a href="#ref-Blackwell1973">Blackwell
and MacQueen 1973</a>)</span>.</p>
<p>In our case, we face the situation to find a distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
that explains the decider-specific coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>β</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>n</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>N</mi></mrow></msub><annotation encoding="application/x-tex">(\beta_n)_{n = 1,\dots,N}</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
is supposed to be a mixture of an unknown number
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
of Gaussian densities,
i.e. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>=</mo><msub><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>C</mi></mrow></msub><msub><mi>s</mi><mi>c</mi></msub><mtext mathvariant="normal">MVN</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>b</mi><mi>c</mi></msub><mo>,</mo><msub><mi>Ω</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g = \sum_{c = 1,\dots,C} s_c \text{MVN}(b_c, \Omega_c)</annotation></semantics></math>.</p>
<p>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>n</mi></msub><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>C</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">z_n \in \{1,\dots,C\}</annotation></semantics></math>
denote the class membership of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>n</mi></msub><annotation encoding="application/x-tex">\beta_n</annotation></semantics></math>.
A priori, the mixture weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>s</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>c</mi></msub><annotation encoding="application/x-tex">(s_c)_c</annotation></semantics></math>
are given a Dirichlet prior with concentration parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mi>/</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">\delta/C</annotation></semantics></math>,
i.e. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>s</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>c</mi></msub><mo>∣</mo><mi>δ</mi><mo>∼</mo><msub><mtext mathvariant="normal">D</mtext><mi>C</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>δ</mi><mi>/</mi><mi>C</mi><mo>,</mo><mi>…</mi><mo>,</mo><mi>δ</mi><mi>/</mi><mi>C</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(s_c)_c \mid \delta \sim \text{D}_C(\delta/C,\dots,\delta/C)</annotation></semantics></math>.
<span class="citation">Rasmussen (<a href="#ref-Rasmussen1999">1999</a>)</span> shows that</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>Pr</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>n</mi></msub><mo>∣</mo><mi>δ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>δ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>+</mo><mi>δ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><munderover><mo>∏</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mfrac><mrow><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>m</mi><mi>c</mi></msub><mo>+</mo><mi>δ</mi><mi>/</mi><mi>C</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>δ</mi><mi>/</mi><mi>C</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex"> \Pr((z_n)_n\mid \delta) = \frac{\Gamma(\delta)}{\Gamma(N+\delta)} \prod_{c=1}^C \frac{\Gamma(m_c + \delta/C)}{\Gamma(\delta/C)}, </annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Gamma(\cdot)</annotation></semantics></math>
denotes the gamma function and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mi>c</mi></msub><mo>=</mo><mi>#</mi><mo stretchy="false" form="prefix">{</mo><mi>n</mi><mo>:</mo><msub><mi>z</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">m_c = \#\{n:z_n = c\}</annotation></semantics></math>
the number of elements that are currently allocated to class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>.
Crucially, the last equation is independent of the class weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>s</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>c</mi></msub><annotation encoding="application/x-tex">(s_c)_c</annotation></semantics></math>,
yet it still depends on the finite number
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
of latent classes. However, <span class="citation">Li, Schofield, and
Gönen (<a href="#ref-Li2019">2019</a>)</span> shows that</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>Pr</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi><mo>∣</mo><msub><mi>z</mi><mrow><mo>−</mo><mi>n</mi></mrow></msub><mo>,</mo><mi>δ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><msub><mi>m</mi><mrow><mi>c</mi><mo>,</mo><mo>−</mo><mi>n</mi></mrow></msub><mo>+</mo><mi>δ</mi><mi>/</mi><mi>C</mi></mrow><mrow><mi>N</mi><mo>−</mo><mn>1</mn><mo>+</mo><mi>δ</mi></mrow></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex"> \Pr(z_n = c \mid z_{-n}, \delta) = \frac{m_{c,-n} + \delta/C}{N-1+\delta},</annotation></semantics></math>
where the notation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">-n</annotation></semantics></math>
means excluding the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>th
element. We can let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
approach infinity to derive:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>Pr</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi><mo>∣</mo><msub><mi>z</mi><mrow><mo>−</mo><mi>n</mi></mrow></msub><mo>,</mo><mi>δ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>→</mo><mfrac><msub><mi>m</mi><mrow><mi>c</mi><mo>,</mo><mo>−</mo><mi>n</mi></mrow></msub><mrow><mi>N</mi><mo>−</mo><mn>1</mn><mo>+</mo><mi>δ</mi></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex"> \Pr(z_n = c \mid z_{-n}, \delta) \to \frac{m_{c,-n}}{N-1+\delta}. </annotation></semantics></math></p>
<p>Note that the allocation probabilities do not sum to 1, instead</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mfrac><msub><mi>m</mi><mrow><mi>c</mi><mo>,</mo><mo>−</mo><mi>n</mi></mrow></msub><mrow><mi>N</mi><mo>−</mo><mn>1</mn><mo>+</mo><mi>δ</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow><mrow><mi>N</mi><mo>−</mo><mn>1</mn><mo>+</mo><mi>δ</mi></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex"> \sum_{c = 1}^C \frac{m_{c,-n}}{N-1+\delta} = \frac{N-1}{N-1+\delta}. </annotation></semantics></math></p>
<p>The difference to 1 equals</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>Pr</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>n</mi></msub><mo>≠</mo><msub><mi>z</mi><mi>m</mi></msub><mspace width="0.222em"></mspace><mo>∀</mo><mspace width="0.222em"></mspace><mi>m</mi><mo>≠</mo><mi>n</mi><mo>∣</mo><msub><mi>z</mi><mrow><mo>−</mo><mi>n</mi></mrow></msub><mo>,</mo><mi>δ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mi>δ</mi><mrow><mi>N</mi><mo>−</mo><mn>1</mn><mo>+</mo><mi>δ</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \Pr(z_n \neq z_m ~ \forall ~ m \neq n \mid z_{-n}, \delta) = \frac{\delta}{N-1+\delta} </annotation></semantics></math></p>
<p>and constitutes the probability that a new cluster for observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
is created. <span class="citation">Neal (<a href="#ref-Neal2000">2000</a>)</span> points out that this probability
is proportional to the prior parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>δ</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math>:
A greater value for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>δ</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math>
encourages the creation of new clusters, a smaller value for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>δ</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math>
increases the probability of an allocation to an already existing
class.</p>
<p>In summary, the Dirichlet process updates the allocation of each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
coefficient vector one at a time, dependent on the other allocations.
The number of clusters can theoretically rise to infinity, however, as
we delete unoccupied clusters,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
is bounded by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>.
As a final step after the allocation update, we update the class means
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><mi>c</mi></msub><annotation encoding="application/x-tex">b_c</annotation></semantics></math>
and covariance matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Ω</mi><mi>c</mi></msub><annotation encoding="application/x-tex">\Omega_c</annotation></semantics></math>
by means of their posterior predictive distribution. The mean and
covariance matrix for a new generated cluster is drawn from the prior
predictive distribution. The corresponding formulas are given in <span class="citation">Li, Schofield, and Gönen (<a href="#ref-Li2019">2019</a>)</span>.</p>
<p>The Dirichlet process directly integrates into our existing Gibbs
sampler. Given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
values, it updated the class means
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><mi>c</mi></msub><annotation encoding="application/x-tex">b_c</annotation></semantics></math>
and class covariance matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Ω</mi><mi>c</mi></msub><annotation encoding="application/x-tex">\Omega_c</annotation></semantics></math>.
The Dirichlet process updating scheme is implemented in the function
<code><a href="../reference/update_classes_dp.html">update_classes_dp()</a></code>. In the following, we give a small
example in the bivariate case <code>P_r = 2</code>. We sample true class
means <code>b_true</code> and class covariance matrices
<code>Omega_true</code> for <code>C_true = 3</code> true latent classes.
The true (unbalanced) class sizes are given by the vector
<code>N</code>, and <code>z_true</code> denotes the true
allocations.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">P_r</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">C_true</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">70</span>, <span class="fl">30</span><span class="op">)</span></span>
<span><span class="op">(</span><span class="va">b_true</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">replicate</a></span><span class="op">(</span><span class="va">C_true</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">P_r</span><span class="op">)</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">P_r</span>, ncol <span class="op">=</span> <span class="va">C_true</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;            [,1]       [,2]       [,3]</span></span>
<span><span class="co">#&gt; [1,] -0.6264538 -0.8356286  0.3295078</span></span>
<span><span class="co">#&gt; [2,]  0.1836433  1.5952808 -0.8204684</span></span>
<span><span class="op">(</span><span class="va">Omega_true</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">replicate</a></span><span class="op">(</span><span class="va">C_true</span>, <span class="fu"><a href="../reference/rwishart.html">rwishart</a></span><span class="op">(</span><span class="va">P_r</span> <span class="op">+</span> <span class="fl">1</span>, <span class="fl">0.1</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="va">P_r</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">W</span>, simplify <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  nrow <span class="op">=</span> <span class="va">P_r</span> <span class="op">*</span> <span class="va">P_r</span>, ncol <span class="op">=</span> <span class="va">C_true</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;           [,1]        [,2]       [,3]</span></span>
<span><span class="co">#&gt; [1,] 0.3093652  0.14358543  0.2734617</span></span>
<span><span class="co">#&gt; [2,] 0.1012729 -0.07444148 -0.1474941</span></span>
<span><span class="co">#&gt; [3,] 0.1012729 -0.07444148 -0.1474941</span></span>
<span><span class="co">#&gt; [4,] 0.2648235  0.05751780  0.2184029</span></span>
<span><span class="va">beta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">c</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">C_true</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">n</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">N</span><span class="op">[</span><span class="va">c</span><span class="op">]</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">beta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">beta</span>, <span class="fu"><a href="../reference/rmvnorm.html">rmvnorm</a></span><span class="op">(</span>mu <span class="op">=</span> <span class="va">b_true</span><span class="op">[</span>, <span class="va">c</span>, drop <span class="op">=</span> <span class="cn">F</span><span class="op">]</span>, Sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">Omega_true</span><span class="op">[</span>, <span class="va">c</span>, drop <span class="op">=</span> <span class="cn">F</span><span class="op">]</span>, ncol <span class="op">=</span> <span class="va">P_r</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span></span>
<span><span class="va">z_true</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, times <span class="op">=</span> <span class="va">N</span><span class="op">)</span></span></code></pre></div>
<p>We specify the following prior parameters (for their definition see
the vignette on model fitting):</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">delta</span> <span class="op">&lt;-</span> <span class="fl">0.1</span></span>
<span><span class="va">xi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="va">P_r</span><span class="op">)</span></span>
<span><span class="va">D</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="va">P_r</span><span class="op">)</span></span>
<span><span class="va">nu</span> <span class="op">&lt;-</span> <span class="va">P_r</span> <span class="op">+</span> <span class="fl">2</span></span>
<span><span class="va">Theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="va">P_r</span><span class="op">)</span></span></code></pre></div>
<p>Initially, we start with <code>C = 1</code> latent classes. The class
mean <code>b</code> is set to zero, the covariance matrix
<code>Omega</code> to the identity matrix:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">beta</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">C</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fl">0</span>, nrow <span class="op">=</span> <span class="va">P_r</span>, ncol <span class="op">=</span> <span class="va">C</span><span class="op">)</span></span>
<span><span class="va">Omega</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="va">P_r</span><span class="op">)</span>, <span class="va">C</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">P_r</span> <span class="op">*</span> <span class="va">P_r</span>, ncol <span class="op">=</span> <span class="va">C</span><span class="op">)</span></span></code></pre></div>
<p>The following call to <code><a href="../reference/update_classes_dp.html">update_classes_dp()</a></code> updates the
latent classes in <code>100</code> iterations. Note that we specify the
arguments <code>Cmax</code> and <code>s_desc</code>. The former denotes
the maximum number of latent classes. This specification is not a
requirement for the Dirichlet process per se, but rather for its
implementation. Knowing the maximum possible class number, we can
allocate the required memory space, which leads to a speed improvement.
We later can verify that we won’t exceed the number of
<code>Cmax = 10</code> latent classes at any point of the Dirichlet
process. Setting <code>s_desc = TRUE</code> ensures that the classes are
ordered by their weights in a descending order to ensure
identifiability.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">for</span> <span class="op">(</span><span class="va">r</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">dp</span> <span class="op">&lt;-</span> <span class="fu">RprobitB</span><span class="fu">:::</span><span class="fu"><a href="../reference/update_classes_dp.html">update_classes_dp</a></span><span class="op">(</span></span>
<span>    Cmax <span class="op">=</span> <span class="fl">10</span>, <span class="va">beta</span>, <span class="va">z</span>, <span class="va">b</span>, <span class="va">Omega</span>, <span class="va">delta</span>, <span class="va">xi</span>, <span class="va">D</span>, <span class="va">nu</span>, <span class="va">Theta</span>, s_desc <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">z</span> <span class="op">&lt;-</span> <span class="va">dp</span><span class="op">$</span><span class="va">z</span></span>
<span>  <span class="va">b</span> <span class="op">&lt;-</span> <span class="va">dp</span><span class="op">$</span><span class="va">b</span></span>
<span>  <span class="va">Omega</span> <span class="op">&lt;-</span> <span class="va">dp</span><span class="op">$</span><span class="va">Omega</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The Dirichlet process was able to infer the true number
<code>C_true = 3</code> of latent classes:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">beta</span><span class="op">)</span>, xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html" class="external-link">bquote</a></span><span class="op">(</span><span class="va">beta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>, ylab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html" class="external-link">bquote</a></span><span class="op">(</span><span class="va">beta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span>
<span><span class="fu">RprobitB</span><span class="fu">:::</span><span class="fu"><a href="../reference/plot_class_allocation.html">plot_class_allocation</a></span><span class="op">(</span><span class="va">beta</span>, <span class="va">z</span>, <span class="va">b</span>, <span class="va">Omega</span>, r <span class="op">=</span> <span class="fl">100</span>, perc <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span></code></pre></div>
<p><img src="img%2Fdirichlet-example-plot-1.png" width="75%" style="display: block; margin: auto;"></p>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Aldous1985" class="csl-entry">
Aldous, David J. 1985. <span>“Exchangeability and Related
Topics.”</span> In <em><span>É</span>cole
d’<span>É</span>t<span>é</span> de Probabilit<span>é</span>s de
Saint-Flour XIII — 1983</em>, edited by P. L. Hennequin, 1–198. Berlin,
Heidelberg: Springer Berlin Heidelberg.
</div>
<div id="ref-Bauer2019" class="csl-entry">
Bauer, D., S. Büscher, and M. Batram. 2019. <span>“Non-Parameteric
Estiation of Mixed Discrete Choice Models.”</span> <em>Second
International Choice Modelling Conference in Kobe</em>.
</div>
<div id="ref-Blackwell1973" class="csl-entry">
Blackwell, D., and J. MacQueen. 1973. <span>“Ferguson Distributions via
<span>Polya</span> Urn Schemes.”</span> <em>The Annals of
Statistics</em> 1: 353–55.
</div>
<div id="ref-Burda2008" class="csl-entry">
Burda, M., M. Harding, and J. Hausman. 2008. <span>“A Bayesian Mixed
Logit–Probit Model for Multinomial Choice.”</span> <em>Journal of
Econometrics</em> 147 (2). <a href="https://doi.org/10.1016/j.jeconom.2008.09.029" class="external-link">https://doi.org/10.1016/j.jeconom.2008.09.029</a>.
</div>
<div id="ref-Croissant2020" class="csl-entry">
Croissant, Y. 2020. <span>“Estimation of Random Utility Models in : The
Package.”</span> <em>Journal of Statistical Software</em> 95 (11). <a href="https://doi.org/10.18637/jss.v095.i11" class="external-link">https://doi.org/10.18637/jss.v095.i11</a>.
</div>
<div id="ref-Li2019" class="csl-entry">
Li, Y., E. Schofield, and M. Gönen. 2019. <span>“A Tutorial on
<span>Dirichlet</span> Process Mixture Modeling.”</span> <em>Journal of
Mathematical Psychology</em> 91. <a href="https://doi.org/10.1016/j.jmp.2019.04.004" class="external-link">https://doi.org/10.1016/j.jmp.2019.04.004</a>.
</div>
<div id="ref-Neal2000" class="csl-entry">
Neal, R. M. 2000. <span>“Markov Chain Sampling Methods for
<span>Dirichlet</span> Process Mixture Models.”</span> <em>Journal of
Computational and Graphical Statistics</em> 9 (2). <a href="https://doi.org/10.2307/1390653" class="external-link">https://doi.org/10.2307/1390653</a>.
</div>
<div id="ref-Rasmussen1999" class="csl-entry">
Rasmussen, Carl. 1999. <span>“The Infinite <span>Gaussian</span> Mixture
Model.”</span> <em>Advances in Neural Information Processing
Systems</em> 12.
</div>
<div id="ref-Sethuraman1994" class="csl-entry">
Sethuraman, J. 1994. <span>“A Constructive Definition of
<span>Dirichlet</span> Priors.”</span> <em>Statistica Sinica</em> 4 (2):
639–50. <a href="http://www.jstor.org/stable/24305538" class="external-link">http://www.jstor.org/stable/24305538</a>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://loelschlaeger.de" class="external-link">Lennart Oelschläger</a>, <a href="https://de.wikipedia.org/wiki/Dietmar_Bauer" class="external-link">Dietmar Bauer</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
