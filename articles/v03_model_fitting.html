<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Model fitting • RprobitB</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Model fitting">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">RprobitB</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.2.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/RprobitB.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/v01_model_definition.html">Model definition</a></li>
    <li><a class="dropdown-item" href="../articles/v02_choice_data.html">Choice data</a></li>
    <li><a class="dropdown-item" href="../articles/v03_model_fitting.html">Model fitting</a></li>
    <li><a class="dropdown-item" href="../articles/v04_modeling_heterogeneity.html">Modeling heterogeneity</a></li>
    <li><a class="dropdown-item" href="../articles/v05_choice_prediction.html">Choice prediction</a></li>
    <li><a class="dropdown-item" href="../articles/v06_model_selection.html">Model selection</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/loelschlaeger/RprobitB/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Model fitting</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/loelschlaeger/RprobitB/blob/main/vignettes/v03_model_fitting.Rmd" class="external-link"><code>vignettes/v03_model_fitting.Rmd</code></a></small>
      <div class="d-none name"><code>v03_model_fitting.Rmd</code></div>
    </div>

    
    
<p>This vignette<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;This vignette is built using R 4.5.1 with the
&lt;a href="https://loelschlaeger.de/RprobitB/"&gt;RprobitB&lt;/a&gt; 1.2.0.9000 package.&lt;/p&gt;'><sup>1</sup></a> is a documentation of the estimation
procedure <code><a href="../reference/fit_model.html">fit_model()</a></code> in <a href="https://loelschlaeger.de/RprobitB/">RprobitB</a>.</p>
<div class="section level2">
<h2 id="bayes-estimation-of-the-probit-model">Bayes estimation of the probit model<a class="anchor" aria-label="anchor" href="#bayes-estimation-of-the-probit-model"></a>
</h2>
<p>Bayes estimation of the probit model builds upon the work of <span class="citation">McCulloch and Rossi (<a href="#ref-McCulloch1994">1994</a>)</span>, <span class="citation">Nobile (<a href="#ref-Nobile1998">1998</a>)</span>,
<span class="citation">Allenby and Rossi (<a href="#ref-Allenby1998">1998</a>)</span>, and <span class="citation">Imai and Dyk (<a href="#ref-Imai2005">2005</a>)</span>.
A key ingredient is the concept of data augmentation, see <span class="citation">Albert and Chib (<a href="#ref-Albert1993">1993</a>)</span>: The idea is to treat the latent
utilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>U</mi><annotation encoding="application/x-tex">U</annotation></semantics></math>
in the model equation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo>=</mo><mi>X</mi><mi>β</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">U = X\beta + \epsilon</annotation></semantics></math>
as additional parameters. Then, conditional on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>U</mi><annotation encoding="application/x-tex">U</annotation></semantics></math>,
the probit model constitutes a standard Bayesian linear regression
set-up. Its posterior distribution can be approximated by iteratively
drawing and updating each model parameter conditional on the other
parameters (the so-called Gibbs sampling approach).</p>
<p>A priori, we assume the following (conjugate) parameter
distributions:</p>
<ul>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>s</mi><mi>C</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>∼</mo><msub><mi>D</mi><mi>C</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>δ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(s_1,\dots,s_C)\sim D_C(\delta)</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mi>C</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>δ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">D_C(\delta)</annotation></semantics></math>
denotes the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>-dimensional
Dirichlet distribution with concentration parameter vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>δ</mi><mi>C</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\delta = (\delta_1,\dots,\delta_C)</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>∼</mo><msub><mtext mathvariant="normal">MVN</mtext><msub><mi>P</mi><mi>f</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><msub><mi>α</mi><mn>0</mn></msub></msub><mo>,</mo><msub><mi>Σ</mi><msub><mi>α</mi><mn>0</mn></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\alpha\sim \text{MVN}_{P_f}(\mu_{\alpha_0},\Sigma_{\alpha_0})</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mtext mathvariant="normal">MVN</mtext><msub><mi>P</mi><mi>f</mi></msub></msub><annotation encoding="application/x-tex">\text{MVN}_{P_f}</annotation></semantics></math>
denotes the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>P</mi><mi>f</mi></msub><annotation encoding="application/x-tex">P_f</annotation></semantics></math>-dimensional
normal distribution with mean
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>μ</mi><msub><mi>α</mi><mn>0</mn></msub></msub><annotation encoding="application/x-tex">\mu_{\alpha_0}</annotation></semantics></math>
and covariance
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Σ</mi><msub><mi>α</mi><mn>0</mn></msub></msub><annotation encoding="application/x-tex">\Sigma_{\alpha_0}</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>c</mi></msub><mo>∼</mo><msub><mtext mathvariant="normal">MVN</mtext><msub><mi>P</mi><mi>r</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><msub><mi>b</mi><mn>0</mn></msub></msub><mo>,</mo><msub><mi>Σ</mi><msub><mi>b</mi><mn>0</mn></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">b_c \sim \text{MVN}_{P_r}(\mu_{b_0}, \Sigma_{b_0})</annotation></semantics></math>,
independent for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Ω</mi><mi>c</mi></msub><mo>∼</mo><msubsup><mi>W</mi><msub><mi>P</mi><mi>r</mi></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>n</mi><msub><mi>Ω</mi><mn>0</mn></msub></msub><mo>,</mo><msub><mi>V</mi><msub><mi>Ω</mi><mn>0</mn></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Omega_c \sim W^{-1}_{P_r}(n_{\Omega_0}, V_{\Omega_0})</annotation></semantics></math>,
independent for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>W</mi><msub><mi>P</mi><mi>r</mi></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>n</mi><msub><mi>Ω</mi><mn>0</mn></msub></msub><mo>,</mo><msub><mi>V</mi><msub><mi>Ω</mi><mn>0</mn></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">W^{-1}_{P_r}(n_{\Omega_0}, V_{\Omega_0})</annotation></semantics></math>
denotes the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>P</mi><mi>r</mi></msub><annotation encoding="application/x-tex">P_r</annotation></semantics></math>-dimensional
inverse Wishart distribution with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><msub><mi>Ω</mi><mn>0</mn></msub></msub><annotation encoding="application/x-tex">n_{\Omega_0}</annotation></semantics></math>
degrees of freedom and scale matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><msub><mi>Ω</mi><mn>0</mn></msub></msub><annotation encoding="application/x-tex">V_{\Omega_0}</annotation></semantics></math>,</p></li>
<li><p>and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Σ</mi><mo>∼</mo><msubsup><mi>W</mi><mrow><mi>J</mi><mo>−</mo><mn>1</mn></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>n</mi><msub><mi>Σ</mi><mn>0</mn></msub></msub><mo>,</mo><msub><mi>V</mi><msub><mi>Σ</mi><mn>0</mn></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Sigma \sim W^{-1}_{J-1}(n_{\Sigma_0}, V_{\Sigma_0})</annotation></semantics></math>.</p></li>
</ul>
<p>These prior distributions imply the following conditional posterior
distributions:</p>
<ul>
<li><p>The class weights are drawn from the Dirichlet distribution
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>s</mi><mi>C</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>∣</mo><mi>δ</mi><mo>,</mo><mi>z</mi><mo>∼</mo><msub><mi>D</mi><mi>C</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>+</mo><msub><mi>m</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>δ</mi><mi>C</mi></msub><mo>+</mo><msub><mi>m</mi><mi>C</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
(s_1,\dots,s_C)\mid \delta,z \sim D_C(\delta_1+m_1,\dots,\delta_C+m_C),
\end{equation}</annotation></semantics></math> where for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">c=1,\dots,C</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mi>c</mi></msub><mo>=</mo><mi>#</mi><mo stretchy="false" form="prefix">{</mo><mi>n</mi><mo>:</mo><msub><mi>z</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">m_c=\#\{n:z_n=c\}</annotation></semantics></math>
denotes the current absolute class size.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;Mind that the model is invariant to permutations of the
class labels
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;…&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;1,\dots,C&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;.
For that reason, we accept an update only if the ordering
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mi&gt;…&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;s_1&amp;gt;\dots&amp;gt;s_C&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;
holds, thereby ensuring a unique labeling of the classes.&lt;/p&gt;'><sup>2</sup></a></p></li>
<li><p>Independently for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>,
we update the allocation variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>n</mi></msub><annotation encoding="application/x-tex">(z_n)_n</annotation></semantics></math>
from their conditional distribution
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">Prob</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi><mo>∣</mo><mi>s</mi><mo>,</mo><mi>β</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>Ω</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><msub><mi>s</mi><mi>c</mi></msub><msub><mi>ϕ</mi><msub><mi>P</mi><mi>r</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>β</mi><mi>n</mi></msub><mo>∣</mo><msub><mi>b</mi><mi>c</mi></msub><mo>,</mo><msub><mi>Ω</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><munder><mo>∑</mo><mi>c</mi></munder><msub><mi>s</mi><mi>c</mi></msub><msub><mi>ϕ</mi><msub><mi>P</mi><mi>r</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>β</mi><mi>n</mi></msub><mo>∣</mo><msub><mi>b</mi><mi>c</mi></msub><mo>,</mo><msub><mi>Ω</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
\text{Prob}(z_n=c\mid s,\beta,b,\Omega )=\frac{s_c\phi_{P_r}(\beta_n\mid b_c,\Omega_c)}{\sum_c s_c\phi_{P_r}(\beta_n\mid b_c,\Omega_c)}.
\end{equation}</annotation></semantics></math></p></li>
<li>
<p>The class means
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>b</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>c</mi></msub><annotation encoding="application/x-tex">(b_c)_c</annotation></semantics></math>
are updated independently for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>
via
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>c</mi></msub><mo>∣</mo><msub><mi>Σ</mi><msub><mi>b</mi><mn>0</mn></msub></msub><mo>,</mo><mi>Ω</mi><mo>,</mo><msub><mi>μ</mi><msub><mi>b</mi><mn>0</mn></msub></msub><mo>,</mo><mi>z</mi><mo>,</mo><mi>β</mi><mo>∼</mo><msub><mtext mathvariant="normal">MVN</mtext><msub><mi>P</mi><mi>r</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><msub><mi>b</mi><mi>c</mi></msub></msub><mo>,</mo><msub><mi>Σ</mi><msub><mi>b</mi><mi>c</mi></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
b_c\mid \Sigma_{b_0},\Omega,\mu_{b_0},z,\beta \sim\text{MVN}_{P_r}\left( \mu_{b_c}, \Sigma_{b_c}  \right),
\end{equation}</annotation></semantics></math> where</p>
<ul>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><msub><mi>b</mi><mi>c</mi></msub></msub><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>Σ</mi><msub><mi>b</mi><mn>0</mn></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mo>+</mo><msub><mi>m</mi><mi>c</mi></msub><msubsup><mi>Ω</mi><mi>c</mi><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>Σ</mi><msub><mi>b</mi><mn>0</mn></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>μ</mi><msub><mi>b</mi><mn>0</mn></msub></msub><mo>+</mo><msub><mi>m</mi><mi>c</mi></msub><msubsup><mi>Ω</mi><mi>c</mi><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mover><mi>b</mi><mo accent="true">‾</mo></mover><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu_{b_c}=(\Sigma_{b_0}^{-1}+m_c\Omega_c^{-1})^{-1}(\Sigma_{b_0}^{-1}\mu_{b_0} +m_c\Omega_c^{-1}\bar{b}_c)</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Σ</mi><msub><mi>b</mi><mi>c</mi></msub></msub><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>Σ</mi><msub><mi>b</mi><mn>0</mn></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mo>+</mo><msub><mi>m</mi><mi>c</mi></msub><msubsup><mi>Ω</mi><mi>c</mi><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\Sigma_{b_c}=(\Sigma_{b_0}^{-1}+m_c\Omega_c^{-1})^{-1}</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>b</mi><mo accent="true">‾</mo></mover><mi>c</mi></msub><mo>=</mo><msubsup><mi>m</mi><mi>c</mi><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mo>∑</mo><mrow><mi>n</mi><mo>:</mo><msub><mi>z</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi></mrow></msub><msub><mi>β</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\bar{b}_c=m_c^{-1}\sum_{n:z_n=c} \beta_n</annotation></semantics></math>.</p></li>
</ul>
</li>
<li><p>The class covariance matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Ω</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>c</mi></msub><annotation encoding="application/x-tex">(\Omega_c)_c</annotation></semantics></math>
are updated independently for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>
via
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Ω</mi><mi>c</mi></msub><mo>∣</mo><msub><mi>n</mi><msub><mi>Ω</mi><mn>0</mn></msub></msub><mo>,</mo><msub><mi>V</mi><msub><mi>Ω</mi><mn>0</mn></msub></msub><mo>,</mo><mi>z</mi><mo>,</mo><mi>β</mi><mo>,</mo><mi>b</mi><mo>∼</mo><msubsup><mi>W</mi><msub><mi>P</mi><mi>r</mi></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><msub><mi>Ω</mi><mi>c</mi></msub></msub><mo>,</mo><msub><mi>Σ</mi><msub><mi>Ω</mi><mi>c</mi></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
\Omega_c \mid n_{\Omega_0},V_{\Omega_0},z,\beta,b \sim W^{-1}_{P_r}(\mu_{\Omega_c},\Sigma_{\Omega_c}),
\end{equation}</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><msub><mi>Ω</mi><mi>c</mi></msub></msub><mo>=</mo><msub><mi>n</mi><msub><mi>Ω</mi><mn>0</mn></msub></msub><mo>+</mo><msub><mi>m</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">\mu_{\Omega_c}=n_{\Omega_0} + m_c</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Σ</mi><msub><mi>Ω</mi><mi>c</mi></msub></msub><mo>=</mo><msubsup><mi>V</mi><msub><mi>Ω</mi><mn>0</mn></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mo>+</mo><msub><mo>∑</mo><mrow><mi>n</mi><mo>:</mo><msub><mi>z</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>β</mi><mi>n</mi></msub><mo>−</mo><msub><mi>b</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>β</mi><mi>n</mi></msub><mo>−</mo><msub><mi>b</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>′</mi></mrow><annotation encoding="application/x-tex">\Sigma_{\Omega_c}=V_{\Omega_0}^{-1} + \sum_{n:z_n=c} (\beta_n-b_c)(\beta_n-b_c)'</annotation></semantics></math>.</p></li>
<li><p>Independently for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
and conditionally on the other components, the utility vectors
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mo>:</mo></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(U_{nt:})</annotation></semantics></math>
follow a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">J-1</annotation></semantics></math>-dimensional
truncated multivariate normal distribution, where the truncation points
are determined by the choices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">y_{nt}</annotation></semantics></math>.
To sample from a truncated multivariate normal distribution, we apply a
sub-Gibbs sampler, following the approach of <span class="citation">Geweke (<a href="#ref-Geweke1998">1998</a>)</span>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>∣</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><mo>,</mo><msub><mi>y</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mo>,</mo><mi>Σ</mi><mo>,</mo><mi>W</mi><mo>,</mo><mi>α</mi><mo>,</mo><mi>X</mi><mo>,</mo><mi>β</mi><mo>∼</mo><mi>𝒩</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub></msub><mo>,</mo><msub><mi>Σ</mi><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>⋅</mo><mrow><mo stretchy="true" form="prefix">{</mo><mtable><mtr><mtd columnalign="left" style="text-align: left"><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>&gt;</mo><mo>max</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><mo>,</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mtext mathvariant="normal">if</mtext><mspace width="0.222em"></mspace><msub><mi>y</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><mi>j</mi></mtd></mtr><mtr><mtd columnalign="left" style="text-align: left"><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mo>&lt;</mo><mo>max</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><mo>,</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mtext mathvariant="normal">if</mtext><mspace width="0.222em"></mspace><msub><mi>y</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mo>≠</mo><mi>j</mi></mtd></mtr></mtable></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
U_{ntj} \mid U_{nt(-j)},y_{nt},\Sigma,W,\alpha,X,\beta 
\sim \mathcal{N}(\mu_{U_{ntj}},\Sigma_{U_{ntj}}) \cdot \begin{cases}
1(U_{ntj}&gt;\max(U_{nt(-j)},0) ) &amp; \text{if}~ y_{nt}=j\\
1(U_{ntj}&lt;\max(U_{nt(-j)},0) ) &amp; \text{if}~ y_{nt}\neq j
\end{cases},
\end{equation}</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><annotation encoding="application/x-tex">U_{nt(-j)}</annotation></semantics></math>
denotes the vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mo>:</mo></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(U_{nt:})</annotation></semantics></math>
without the element
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">U_{ntj}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝒩</mi><annotation encoding="application/x-tex">\mathcal{N}</annotation></semantics></math>
denotes the univariate normal distribution,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Σ</mi><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub></msub><mo>=</mo><mn>1</mn><mi>/</mi><msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>j</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\Sigma_{U_{ntj}} = 1/(\Sigma^{-1})_{jj}</annotation></semantics></math>
and
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub></msub><mo>=</mo><msub><mi>W</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mi>′</mi><mi>α</mi><mo>+</mo><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub><mi>′</mi><msub><mi>β</mi><mi>n</mi></msub><mo>−</mo><msub><mi>Σ</mi><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mi>j</mi></mrow></msub></msub><msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>j</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><mo>−</mo><msub><mi>W</mi><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><mi>′</mi><mi>α</mi><mo>−</mo><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><mi>′</mi><msub><mi>β</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
\mu_{U_{ntj}} = W_{ntj}'\alpha + X_{ntj}'\beta_n - \Sigma_{U_{ntj}} (\Sigma^{-1})_{j(-j)}   (U_{nt(-j)} - W_{nt(-j)}'\alpha - X_{nt(-j)}' \beta_n ),
\end{equation}</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>j</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">(\Sigma^{-1})_{jj}</annotation></semantics></math>
denotes the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>,</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(j,j)</annotation></semantics></math>th
element of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><annotation encoding="application/x-tex">\Sigma^{-1}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>j</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><annotation encoding="application/x-tex">(\Sigma^{-1})_{j(-j)}</annotation></semantics></math>
the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>th
row without the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>th
entry,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><annotation encoding="application/x-tex">W_{nt(-j)}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><annotation encoding="application/x-tex">X_{nt(-j)}</annotation></semantics></math>
the coefficient matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">W_{nt}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">X_{nt}</annotation></semantics></math>,
respectively, without the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>th
column.</p></li>
<li>
<p>Updating the fixed coefficient vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
is achieved by applying the formula for Bayesian linear regression of
the regressors
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">W_{nt}</annotation></semantics></math>
on the regressands
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mo>:</mo></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mi>′</mi><msub><mi>β</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">(U_{nt:})-X_{nt}'\beta_n</annotation></semantics></math>,
i.e.
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>∣</mo><msub><mi>Σ</mi><msub><mi>α</mi><mn>0</mn></msub></msub><mo>,</mo><msub><mi>μ</mi><msub><mi>α</mi><mn>0</mn></msub></msub><mo>,</mo><mi>W</mi><mo>,</mo><mi>Σ</mi><mo>,</mo><mi>U</mi><mo>,</mo><mi>X</mi><mo>,</mo><mi>β</mi><mo>∼</mo><msub><mtext mathvariant="normal">MVN</mtext><msub><mi>P</mi><mi>f</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><mi>α</mi></msub><mo>,</mo><msub><mi>Σ</mi><mi>α</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
\alpha \mid \Sigma_{\alpha_0},\mu_{\alpha_0},W,\Sigma,U,X,\beta \sim \text{MVN}_{P_f}(\mu_\alpha,\Sigma_\alpha),
\end{equation}</annotation></semantics></math> where</p>
<ul>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><mi>α</mi></msub><mo>=</mo><msub><mi>Σ</mi><mi>α</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>Σ</mi><msub><mi>α</mi><mn>0</mn></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>μ</mi><msub><mi>α</mi><mn>0</mn></msub></msub><mo>+</mo><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi><mo>,</mo><mi>T</mi></mrow></msubsup><msub><mi>W</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><msup><mi>Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mo>:</mo></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mi>′</mi><msub><mi>β</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu_\alpha = \Sigma_\alpha (\Sigma_{\alpha_0}^{-1}\mu_{\alpha_0} + \sum_{n=1,t=1}^{N,T} W_{nt} \Sigma^{-1} ((U_{nt:})-X_{nt}'\beta_n) )</annotation></semantics></math></p></li>
<li><p>and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Σ</mi><mi>α</mi></msub><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>Σ</mi><msub><mi>α</mi><mn>0</mn></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mo>+</mo><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi><mo>,</mo><mi>T</mi></mrow></msubsup><msub><mi>W</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><msup><mi>Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><msubsup><mi>W</mi><mrow><mi>n</mi><mi>t</mi></mrow><mi>′</mi></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\Sigma_\alpha = (\Sigma_{\alpha_0}^{-1} + \sum_{n=1,t=1}^{N,T} W_{nt}\Sigma^{-1} W_{nt}^{'} )^{-1}</annotation></semantics></math>.</p></li>
</ul>
</li>
<li>
<p>Analogously to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
the random coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>β</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>n</mi></msub><annotation encoding="application/x-tex">(\beta_n)_n</annotation></semantics></math>
are updated independently via
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>n</mi></msub><mo>∣</mo><mi>Ω</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>X</mi><mo>,</mo><mi>Σ</mi><mo>,</mo><mi>U</mi><mo>,</mo><mi>W</mi><mo>,</mo><mi>α</mi><mo>∼</mo><msub><mtext mathvariant="normal">MVN</mtext><msub><mi>P</mi><mi>r</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><msub><mi>β</mi><mi>n</mi></msub></msub><mo>,</mo><msub><mi>Σ</mi><msub><mi>β</mi><mi>n</mi></msub></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
\beta_n \mid \Omega,b,X,\Sigma,U,W,\alpha \sim \text{MVN}_{P_r}(\mu_{\beta_n},\Sigma_{\beta_n}),
\end{equation}</annotation></semantics></math> where</p>
<ul>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><msub><mi>β</mi><mi>n</mi></msub></msub><mo>=</mo><msub><mi>Σ</mi><msub><mi>β</mi><mi>n</mi></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>Ω</mi><msub><mi>z</mi><mi>n</mi></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>b</mi><msub><mi>z</mi><mi>n</mi></msub></msub><mo>+</mo><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><msup><mi>Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mo>:</mo></mrow></msub><mo>−</mo><msub><mi>W</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mi>′</mi><mi>α</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu_{\beta_n} = \Sigma_{\beta_n} (\Omega_{z_n}^{-1}b_{z_n} + \sum_{t=1}^{T} X_{nt} \Sigma^{-1} (U_{nt:}-W_{nt}'\alpha) )</annotation></semantics></math></p></li>
<li><p>and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Σ</mi><msub><mi>β</mi><mi>n</mi></msub></msub><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>Ω</mi><msub><mi>z</mi><mi>n</mi></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mo>+</mo><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><msup><mi>Σ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><msubsup><mi>X</mi><mrow><mi>n</mi><mi>t</mi></mrow><mi>′</mi></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\Sigma_{\beta_n} = (\Omega_{z_n}^{-1} + \sum_{t=1}^{T} X_{nt}\Sigma^{-1} X_{nt}^{'} )^{-1}</annotation></semantics></math>
.</p></li>
</ul>
</li>
<li>
<p>The error term covariance matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Σ</mi><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math>
is updated by means of <span class="math display">$$\begin{equation}
\Sigma \mid n_{\Sigma_0}, V_{\Sigma_0}, U, W, \alpha, X, \beta \sim
W^{-1}_{J-1}(n_{\Sigma_0} + NT, V_{\Sigma_0} + S), \\
\end{equation}$$</span> where</p>
<ul>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi><mo>,</mo><mi>T</mi></mrow></msubsup><msub><mi>ε</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><msub><mi>ε</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mi>′</mi></mrow><annotation encoding="application/x-tex">S = \sum_{n=1,t=1}^{N,T} \varepsilon_{nt} \varepsilon_{nt}'</annotation></semantics></math></p></li>
<li><p>and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ε</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mrow><mi>n</mi><mi>t</mi><mo>:</mo></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><msub><mi>W</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mi>′</mi><mi>α</mi><mo>−</mo><msub><mi>X</mi><mrow><mi>n</mi><mi>t</mi></mrow></msub><mi>′</mi><msub><mi>β</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\varepsilon_{nt} = (U_{nt:}) - W_{nt}'\alpha - X_{nt}'\beta_n</annotation></semantics></math>.</p></li>
</ul>
</li>
</ul>
<div class="section level3">
<h3 id="parameter-normalization">Parameter normalization<a class="anchor" aria-label="anchor" href="#parameter-normalization"></a>
</h3>
<p>Samples obtained from the updating scheme described above lack
identification (except for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>
draws), compare to the vignette on the model definition. Therefore,
subsequent to the sampling, the following normalizations are required
for the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>th
updates in each iterations
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>:</p>
<ul>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>α</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>⋅</mo><msup><mi>ω</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\alpha^{(i)} \cdot \omega^{(i)}</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>b</mi><mi>c</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>⋅</mo><msup><mi>ω</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">b_c^{(i)} \cdot \omega^{(i)}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">c=1,\dots,C</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>U</mi><mrow><mi>n</mi><mi>t</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>⋅</mo><msup><mi>ω</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">U_{nt}^{(i)} \cdot \omega^{(i)}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">n = 1,\dots,N</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">t = 1,\dots,T</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>β</mi><mi>n</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>⋅</mo><msup><mi>ω</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\beta_n^{(i)} \cdot \omega^{(i)}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">n = 1,\dots,N</annotation></semantics></math>,</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Ω</mi><mi>c</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>⋅</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ω</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\Omega_c^{(i)} \cdot (\omega^{(i)})^2</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">c=1,\dots,C</annotation></semantics></math>,
and</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Σ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>⋅</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ω</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\Sigma^{(i)} \cdot (\omega^{(i)})^2</annotation></semantics></math>,</p></li>
</ul>
<p>where either
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ω</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><msqrt><mrow><mtext mathvariant="normal">const</mtext><mi>/</mi><msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>Σ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>j</mi><mi>j</mi></mrow></msub></mrow></msqrt></mrow><annotation encoding="application/x-tex">\omega^{(i)} = \sqrt{\text{const} / (\Sigma^{(i)})_{jj}}</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>Σ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>j</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">(\Sigma^{(i)})_{jj}</annotation></semantics></math>
the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>th
diagonal element of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Σ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\Sigma^{(i)}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>J</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\leq j \leq J-1</annotation></semantics></math>,
or alternatively
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ω</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><mtext mathvariant="normal">const</mtext><mi>/</mi><msubsup><mi>α</mi><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\omega^{(i)} = \text{const} / \alpha^{(i)}_p</annotation></semantics></math>
for some coordinate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>≤</mo><mi>p</mi><mo>≤</mo><msub><mi>P</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">1\leq p \leq P_f</annotation></semantics></math>
of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>th
draw for the coefficient vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.
Here,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="normal">const</mtext><annotation encoding="application/x-tex">\text{const}</annotation></semantics></math>
is any positive constant (typically 1). The preferences will be flipped
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ω</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\omega^{(i)} &lt; 0</annotation></semantics></math>,
which only is the case if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>α</mi><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\alpha^{(i)}_p &lt; 0</annotation></semantics></math>.</p>
</div>
<div class="section level3">
<h3 id="burn-in-and-thinning">Burn-in and thinning<a class="anchor" aria-label="anchor" href="#burn-in-and-thinning"></a>
</h3>
<p>The theory behind Gibbs sampling constitutes that the sequence of
samples produced by the updating scheme is a Markov chain with
stationary distribution equal to the desired joint posterior
distribution. It takes a certain number of iterations for that
stationary distribution to be approximated reasonably well. Therefore,
it is common practice to discard the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
out of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>
samples (the so-called burn-in period). Furthermore, correlation between
nearby samples should be expected. In order to obtain independent
samples, we consider only every
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>th
sample when computing Gibbs sample statistics like expectation and
standard deviation. The independence of the samples can be verified by
computing the serial correlation and the convergence of the Gibbs
sampler can be checked by considering trace plots, see below.</p>
</div>
</div>
<div class="section level2">
<h2 id="the-fit_model-function">The <code>fit_model()</code> function<a class="anchor" aria-label="anchor" href="#the-fit_model-function"></a>
</h2>
<p>The Gibbs sampling scheme described above can be executed by applying
the function</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/fit_model.html">fit_model</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">data</span><span class="op">)</span></span></code></pre></div>
<p>where <code>data</code> must be an <code>RprobitB_data</code> object
(see the vignette about choice data). The function has the following
optional arguments:</p>
<ul>
<li><p><code>scale</code>: A character which determines the <a href="#parameter-normalization">utility scale</a>. It is of the form
<code>"&lt;parameter&gt; := &lt;value&gt;"</code>, where
<code>&lt;parameter&gt;</code> is either the name of a fixed effect or
<code>Sigma_&lt;j&gt;,&lt;j&gt;</code> for the <code>&lt;j&gt;</code>th
diagonal element of <code>Sigma</code>, and <code>&lt;value&gt;</code>
is the value of the fixed parameter
(i.e. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="normal">const</mtext><annotation encoding="application/x-tex">\text{const}</annotation></semantics></math>
introduced <a href="#parameter-normalization">above</a>). Per default
<code>scale = "Sigma\_1,1 := 1"</code>, i.e. the first error-term
variance is fixed to 1.</p></li>
<li><p><code>R</code>: The number of iterations of the Gibbs sampler.
The default is <code>R = 10000</code>.</p></li>
<li><p><code>B</code>: The length of the burn-in period, i.e. a
non-negative number of samples to be discarded. The default is
<code>B = R/2</code>.</p></li>
<li><p><code>Q</code>: The thinning factor for the Gibbs samples,
i.e. only every <code>Q</code>th sample is kept. The default is
<code>Q = 1</code>.</p></li>
<li><p><code>print_progress</code>: A boolean, determining whether to
print the Gibbs sampler progress.</p></li>
<li>
<p><code>prior</code>: A named list of parameters for the prior
distributions (their default values are documented in the
<code><a href="../reference/check_prior.html">check_prior()</a></code> function):</p>
<ul>
<li><p><code>mu_alpha_0</code>: The mean vector of length
<code>P_f</code> of the normal prior for <code>alpha</code>.</p></li>
<li><p><code>Sigma_alpha_0</code>: The covariance matrix of dimension
<code>P_f</code> x <code>P_f</code> of the normal prior for
<code>alpha</code>.</p></li>
<li><p><code>delta</code>: The concentration parameter of length 1 of
the Dirichlet prior for <code>s</code>.</p></li>
<li><p><code>mu_b_0</code>: The mean vector of length <code>P_r</code>
of the normal prior for each <code>b_c</code>.</p></li>
<li><p><code>Sigma_b_0</code>: The covariance matrix of dimension
<code>P_r</code> x <code>P_r</code> of the normal prior for each
<code>b_c</code>.</p></li>
<li><p><code>n_Omega_0</code>: The degrees of freedom (a natural number
greater than <code>P_r</code>) of the Inverse Wishart prior for each
<code>Omega_c</code>.</p></li>
<li><p><code>V_Omega_0</code>: The scale matrix of dimension
<code>P_r</code> x <code>P_r</code> of the Inverse Wishart prior for
each <code>Omega_c</code>.</p></li>
<li><p><code>n_Sigma_0</code>: The degrees of freedom (a natural number
greater than <code>J - 1</code>) of the Inverse Wishart prior for
<code>Sigma</code>.</p></li>
<li><p><code>V_Sigma_0</code>: The scale matrix of dimension
<code>J-1</code> x <code>J-1</code> of the Inverse Wishart prior for
<code>Sigma</code>.</p></li>
</ul>
</li>
<li><p><code>latent_classes</code>: A list of parameters specifying the
number and the updating scheme of latent classes, see the vignette <a href="https://loelschlaeger.de/RprobitB/articles/v04_modeling_heterogeneity.html">on
modeling heterogeneity fitting</a>.</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h2>
<p>In <a href="https://loelschlaeger.de/RprobitB/articles/v02_choice_data.html">the
previous vignette on choice data</a>, we introduced the
<code>train_choice</code> data set that contains 2922 choices between
two fictional train route alternatives. The following lines fit a probit
model that explains the chosen trip alternatives (<code>choice</code>)
by their <code>price</code>, <code>time</code>, number of
<code>change</code>s, and level of <code>comfort</code> (the lower this
value the higher the comfort). For normalization, the first linear
coefficient, the <code>price</code>, was fixed to <code>-1</code>, which
allows to interpret the other coefficients as monetary values:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">form</span> <span class="op">&lt;-</span> <span class="va">choice</span> <span class="op">~</span> <span class="va">price</span> <span class="op">+</span> <span class="va">time</span> <span class="op">+</span> <span class="va">change</span> <span class="op">+</span> <span class="va">comfort</span> <span class="op">|</span> <span class="fl">0</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prepare_data.html">prepare_data</a></span><span class="op">(</span>form <span class="op">=</span> <span class="va">form</span>, choice_data <span class="op">=</span> <span class="va">train_choice</span>, id <span class="op">=</span> <span class="st">"deciderID"</span>, idc <span class="op">=</span> <span class="st">"occasionID"</span><span class="op">)</span></span>
<span><span class="va">model_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_model.html">fit_model</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">data</span>,</span>
<span>  scale <span class="op">=</span> <span class="st">"price := -1"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The estimated coefficients (using the mean of the Gibbs samples as a
point estimate) can be printed via</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">model_train</span><span class="op">)</span></span>
<span><span class="co">#&gt;            Estimate   (sd)</span></span>
<span><span class="co">#&gt; 1   price     -1.00 (0.00)</span></span>
<span><span class="co">#&gt; 2    time    -25.81 (2.18)</span></span>
<span><span class="co">#&gt; 3  change     -4.88 (0.88)</span></span>
<span><span class="co">#&gt; 4 comfort    -14.49 (0.94)</span></span></code></pre></div>
<p>The results indicate that the deciders value one hour travel time by
about 25€, an additional change by 5€, and a more comfortable class by
14€.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;These results are consistent with the ones that are
presented &lt;a href="https://cran.r-project.org/package=mlogit/vignettes/c5.mxl.html#train" class="external-link"&gt;in
a vignette of the mlogit package&lt;/a&gt; on the same data set but using the
logit model.&lt;/p&gt;'><sup>3</sup></a></p>
</div>
<div class="section level2">
<h2 id="checking-the-gibbs-samples">Checking the Gibbs samples<a class="anchor" aria-label="anchor" href="#checking-the-gibbs-samples"></a>
</h2>
<p>The Gibbs samples are saved in list form in the
<code>RprobitB_fit</code> object at the entry
<code>"gibbs_samples"</code>, i.e.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">model_train</span><span class="op">$</span><span class="va">gibbs_samples</span>, max.level <span class="op">=</span> <span class="fl">2</span>, give.attr <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; List of 2</span></span>
<span><span class="co">#&gt;  $ gibbs_samples_raw:List of 2</span></span>
<span><span class="co">#&gt;   ..$ alpha: num [1:1000, 1:4] -0.000713 -0.023068 -0.030523 -0.034482 -0.036309 ...</span></span>
<span><span class="co">#&gt;   ..$ Sigma: num [1:1000, 1] 1.09 1.11 1.04 1.06 1.01 ...</span></span>
<span><span class="co">#&gt;  $ gibbs_samples_nbt:List of 2</span></span>
<span><span class="co">#&gt;   ..$ alpha: num [1:500, 1:4] -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...</span></span>
<span><span class="co">#&gt;   ..$ Sigma: num [1:500, 1] 687 696 605 686 677 ...</span></span></code></pre></div>
<p>This object contains 2 elements:</p>
<ul>
<li><p><code>gibbs_samples_raw</code> is a list of the raw samples from
the Gibbs sampler,</p></li>
<li><p>and <code>gibbs_samples_nbt</code> are the Gibbs samples used for
parameter estimates, i.e. the normalized and thinned Gibbs samples after
the burn-in.</p></li>
</ul>
<p>Calling the summary function on the estimated
<code>RprobitB_fit</code> object yields additional information about the
Gibbs samples <code>gibbs_samples_nbt</code>. You can specify a list
<code>FUN</code> of functions that compute any point estimate of the
Gibbs samples<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;Use the function &lt;code&gt;&lt;a href="../reference/point_estimates.html"&gt;point_estimates()&lt;/a&gt;&lt;/code&gt; to
access the Gibbs sample statistics as an &lt;code&gt;RprobitB_parameter&lt;/code&gt;
object.&lt;/p&gt;'><sup>4</sup></a>, for example</p>
<ul>
<li><p><code>mean</code> for the arithmetic mean,</p></li>
<li><p><code>mode_approx</code> for the (approximated) conditional
posterior mode,</p></li>
<li><p><code><a href="https://rdrr.io/r/stats/sd.html" class="external-link">stats::sd</a></code> for the standard deviation,</p></li>
<li><p><code>R_hat</code> for the Gelman-Rubin statistic <span class="citation">(<a href="#ref-Gelman1992">Gelman and Rubin
1992</a>)</span> <a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;A Gelman-Rubin statistic close to 1 indicates that the
chain of Gibbs samples converged to the stationary distribution.&lt;/p&gt;"><sup>5</sup></a>,</p></li>
<li><p>or custom statistics like the absolute difference between the
median and the mean.</p></li>
</ul>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">model_train</span>,</span>
<span>  FUN <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="st">"mean"</span> <span class="op">=</span> <span class="va">mean</span>,</span>
<span>    <span class="st">"mode"</span> <span class="op">=</span> <span class="va">mode_approx</span>,</span>
<span>    <span class="st">"sd"</span> <span class="op">=</span> <span class="fu">stats</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/r/stats/sd.html" class="external-link">sd</a></span>,</span>
<span>    <span class="st">"R^"</span> <span class="op">=</span> <span class="va">R_hat</span>,</span>
<span>    <span class="st">"custom_stat"</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html" class="external-link">median</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="text-decoration: underline;">Probit model</span></span></span>
<span><span class="co"><span style="text-decoration: underline;">#&gt; </span>Formula: choice ~ price + time + change + comfort | 0 </span></span>
<span><span class="co">#&gt; R: 1000, B: 500, Q: 1</span></span>
<span><span class="co">#&gt; Level: Utility differences with respect to alternative 'B'.</span></span>
<span><span class="co">#&gt; Scale: Coefficient of effect 'price' (alpha_1) fixed to -1.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="text-decoration: underline;">Gibbs sample statistics</span></span></span>
<span><span class="co"><span style="text-decoration: underline;">#&gt; </span>               mean         mode           sd           R^  custom_stat</span></span>
<span><span class="co">#&gt;  alpha</span></span>
<span><span class="co">#&gt;                                                                        </span></span>
<span><span class="co">#&gt;      1        -1.00        -1.00         0.00         1.00         0.00</span></span>
<span><span class="co">#&gt;      2       -25.81       -25.59         2.18         1.00         0.06</span></span>
<span><span class="co">#&gt;      3        -4.88        -5.16         0.88         1.00         0.04</span></span>
<span><span class="co">#&gt;      4       -14.49       -14.54         0.94         1.00         0.02</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Sigma</span></span>
<span><span class="co">#&gt;                                                                        </span></span>
<span><span class="co">#&gt;    1,1       657.41       632.46        67.16         1.01         4.07</span></span></code></pre></div>
<p>Calling the <code>plot</code> method with the additional argument
<code>type = "trace"</code> plots the trace of the Gibbs samples
<code>gibbs_samples_nbt</code>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model_train</span>, type <span class="op">=</span> <span class="st">"trace"</span><span class="op">)</span></span></code></pre></div>
<p><img src="img/plot-trace-model-train-1.png" width="75%" style="display: block; margin: auto;"></p>
<p>Additionally, we can visualize the serial correlation of the Gibbs
samples via the argument <code>type = "acf"</code>. The boxes in the
top-right corner state the total sample size TSS (here <code>R</code> -
<code>B</code> = 10000 - 5000 = 5000), the effective sample size ESS,
and the factor by which TSS is larger than ESS.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model_train</span>, type <span class="op">=</span> <span class="st">"acf"</span><span class="op">)</span></span></code></pre></div>
<p><img src="img/plot-acf-model-train-1.png" width="75%" style="display: block; margin: auto;"></p>
<p>Here, the effective sample size is the value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">TSS</mtext><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>+</mo><msub><mo>∑</mo><mrow><mi>k</mi><mo>≥</mo><mn>1</mn></mrow></msub><msub><mi>ρ</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{TSS} / (1 + \sum_{k\geq 1} \rho_k)</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ρ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\rho_k</annotation></semantics></math>
is the auto correlation between the chain offset by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
positions. The auto correlations are estimated via the
<code><a href="https://rdrr.io/r/stats/acf.html" class="external-link">stats::acf()</a></code> function.</p>
</div>
<div class="section level2">
<h2 id="model-transformation-after-estimation">Model transformation after estimation<a class="anchor" aria-label="anchor" href="#model-transformation-after-estimation"></a>
</h2>
<p>The <code>transform</code> method can be used to transform an
<code>RprobitB_fit</code> object in three ways:</p>
<ol style="list-style-type: decimal">
<li>change the length <code>B</code> of the burn-in period, for
example</li>
</ol>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">model_train</span>, B <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>change the thinning factor <code>Q</code> of the Gibbs samples, for
example</li>
</ol>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">model_train</span>, Q <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>or change the model normalization <code>scale</code>, for
example</li>
</ol>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">model_train</span>, scale <span class="op">=</span> <span class="st">"Sigma_1 := 1"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Albert1993" class="csl-entry">
Albert, J. H., and S. Chib. 1993. <span>“Bayesian Analysis of Binary and
Polychotomous Response Data.”</span> <em>Journal of the American
Statistical Association</em> 88.
</div>
<div id="ref-Allenby1998" class="csl-entry">
Allenby, G. M., and P. Rossi. 1998. <span>“Marketing Models of Consumer
Heterogeneity.”</span> <em>Journal of Econometrics</em> 89.
</div>
<div id="ref-Gelman1992" class="csl-entry">
Gelman, A., and D. B. Rubin. 1992. <span>“Inference from Iterative
Simulation Using Multiple Sequences.”</span> <em>Statistical
Science</em> 7 (4).
</div>
<div id="ref-Geweke1998" class="csl-entry">
Geweke, J. 1998. <span>“Efficient Simulation from the Multivariate
Normal and <span class="nocase">Student-t</span> Distributions Subject
to Linear Constraints and the Evaluation of Constraint
Probabilities.”</span> <em>Computing Science and Statistics</em> 23.
</div>
<div id="ref-Imai2005" class="csl-entry">
Imai, K., and D. A. van Dyk. 2005. <span>“A <span>Bayesian</span>
Analysis of the Multinomial Probit Model Using Marginal Data
Augmentation.”</span> <em>Journal of Econometrics</em>.
</div>
<div id="ref-McCulloch1994" class="csl-entry">
McCulloch, R., and P. Rossi. 1994. <span>“An Exact Likelihood Analysis
of the Multinomial Probit Model.”</span> <em>Journal of
Econometrics</em> 64.
</div>
<div id="ref-Nobile1998" class="csl-entry">
Nobile, A. 1998. <span>“A Hybrid Markov Chain for the
<span>Bayesian</span> Analysis of the Multinomial Probit Model.”</span>
<em>Statistics and Computing</em> 8.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://loelschlaeger.de" class="external-link">Lennart Oelschläger</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
