\documentclass[article]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{thumbpdf,lmodern}

%% additional packages
\usepackage{amssymb,amsmath}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}
\SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}
<<preliminaries, echo=FALSE, results=hide>>=
options(prompt = "> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
library(RprobitB)
@


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Lennart Oelschl\"ager \\Bielefeld University \And Dietmar Bauer\\Bielefeld University}
\Plainauthor{Lennart Oelschl\"ager, Dietmar Bauer}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{\pkg{RprobitB}: Bayes Estimation of Discrete Choice Behavior Heterogeneity via Probit Models in \proglang{R}}
\Plaintitle{RprobitB: Bayes Estimation of Discrete Choice Behavior Heterogeneity via Probit Models in R}
\Shorttitle{RprobitB}

%% - \Abstract{} almost as usual
\Abstract{
\pkg{RprobitB} is an \proglang{R} package for Bayes estimation of probit models with a special focus on modeling choice behavior heterogeneity. In comparison to competing packages it places a focus on approximating the mixing distribution via a latent mixture of Gaussian distributions and thereby providing a classification of deciders. It provides tools for data management, model estimation via Markov Chain Monte Carlo Simulation, diagnostics tools for the Gibbs sampling and a prediction function. This paper demonstrates the functionalities of \pkg{RprobitB} on known choice datasets and compares estimation results across packages.
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{discrete choice, probit models, heterogeneity, Bayes estimation, \proglang{R}}
\Plainkeywords{discrete choice, probit models, heterogeneity, Bayes estimation, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Lennart Oelschl\"ager\\
  Department of Business Administration and Economics\\
  Bielefeld University\\
  Postfach 10 01 31\\
  E-mail: \email{lennart.oelschlaeger@uni-bielefeld.de}
}

\begin{document}
%% I have no idea what this does. Maybe we need this in the future.
%% \SweaveOpts{concordance=TRUE}

%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, \fct{} and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section{Introduction}
\label{sec:introduction}

%% Short introduction
The multinomial probit model is one of the most widely-used statistical models to explain the choices that individuals make among a discrete set of alternatives, which is of central interest in many scientific areas, for example in transportation and marketing. In many such choice scenarios it is reasonable to assume, that the preferences of the decision makers are non-homogeneous. Based on personal characteristics, deciders generally weight attributes like time and cost differently. Heterogeneity in choice behavior can be modeled using mixing distributions for the coefficients. Recently, Oelschlaeger and Bauer proposed a new instrument for approximating the underlying mixing distribution that combines Bayes estimation and semi-parametric methods. This paper presents the implementation of the methodology in the \proglang{R} package \pkg{RprobitB}.

%% Overview RUMs
Traditionally, discrete choice models are interpreted as random utility models, including the multinomial logit (MNL) and the multinomial probit (MNP) model as the most prominent members. The MNL model affords straightforward analysis but suffers from the well-known independence of irrelevant alternatives assumption. In contrast, the MNP model avoids this assumption, which however comes at the price of more complex parameter estimation, cf. \cite{Train:2009}. In their basic form, these models often fail to take into account heterogeneity of individual deciders, cf. \cite{Train:2009}, Chapter 6, or \cite{Train:2016}. A concrete example of heterogeneous preferences is constituted by the value of travel time, cf. \cite{Cirillo:2006}. Modeling heterogeneity in preferences is indispensable in such cases and has been elaborated in both the MNL and the MNP model by imposing mixing distributions on the coefficients, cf. \cite{Train:2009} and \cite{Bhat:2011}.

%How are the mixing distribution specified currently?
Specifying these mixing distributions is an important part of the model selection. In absence of alternatives, it has been common practice so far to try different types of standard parametric distributions (including the normal, log-normal, uniform and tent distribution) and to perform a likelihood value-based model selection, cf. \cite{Train:2009}, Chapter 6. Aiming to capture correlation patterns across parameters, \cite{Fountas:2018} and \cite{Fountas:2019} apply multivariate normal mixing distributions in their probit models, which however comes at the price of imposing the rather strong normality assumption on their parameters.

In order to alleviate these restrictions \cite{Train:2016} proposes a non-parametric approach based on grid methods. Building on the ideas of \cite{Train:2016} and \cite{Bhat:2018} recently \cite{Bauer:2019} introduced procedures for non-parametrically estimating latent class mixed multinomial probit models where the number of classes is chosen iteratively in the algorithm. These procedures have been demonstrated to be useful in reasonable sized cross-sectional data sets. However, for large panel data sets with a significant number of choice occasions per person, the approach is numerically extremely demanding in particular due to its non-parametric nature and has to deal with the curse of dimensionality.

%What is the potential benefit of Bayesian estimation?
In the Bayesian framework \cite{Scaccia:2010} presents the idea to estimate latent class logit models with a fixed prespecified number of Gaussian components. This approach does not require the maximization of the likelihood while at the same time it allows for approximation of the underlying mixing distribution. The same idea has also been applied to probit models, cf. \cite{Xiong:2013} for an analysis of adolescent driver-injury data. In both cases however, the specification of the number of latent classes is based only on a trial-and-error strategy.

%What approach do we suggest to specify the mixing distributions?
Oelschlaeger and Bauer presents a more flexible approach that combines the ideas of a Bayesian framework, approximating the mixing distribution through a mixture of normal distributions and updates on the number of latent classes within the algorithm analogously to \cite{Bauer:2019}. As a consequence, the procedure unites the benefits of a reduced numerical complexity for the estimation compared to the non-parametric likelihood maximization approach and the ability to approximate any mixing distribution. Presenting simulation results on artificial test cases, it is shown that the approach is capable of approximating the underlying mixing distributions and thereby guiding the specification of mixing distributions for real-world applications.

%% Comparison to other packages
This packages adds to the line of discrete choice software packages in R in the following way: Its focus is entirely on Bayesian estimation, thereby it differs from the packages Rchoice. Furthermore, it places a focus on modeling choice behaviour heterogeneity by approximating the underlying mixing distribution through a latent mixture of normal distributions. The method is explained in detail in Oelschlaeger and Bauer.

%% Article overview
In this article we present the methodology, give an overview over the functionality of the package and apply the package to data sets. Some of them were already analysed and we aim to reconstruct their findings. In addition, we added two datasets that are especially appropriate for \pkg{RprobitB} in modeling choice behaviour heterogeneits. The first one is a dataset of contraception choice from the German family panel pairfam. It contains repeated observations of males and femals over several years having different social demographics and relationship status choosing different means of contraception. This choice a priori can be considered to be very hetereogenous and dependent on factors not directly observable by the researcher. The second application deals with the opening choice of chess players depending on their and their openents playing strenght measured in the popular measure system Elo, their gender and nationality. Like the contraception example, this choice a priori can be considers to depend on psychological factors that are not directly observable by the researcher. By applying the functionality of this package we demonstrate how we are able to classify the players into different categories of playing style.

1. With \pkg{RprobitB}, you can model the choices made by deciders among a discrete set of alternatives. For example, think of tourists that want to book a flight to their holiday destination. The knowledge why they prefer a certain route over another is of great value for airlines, especially the customer's willingness to pay for say a faster or more comfortable flight alternative.

2. Different deciders value different choice attributes differently. For example, it is imaginable that business people place a higher value on flight time and are willing to pay more for a faster route alternative than vacationers. Such choice behavior heterogeneity can be addressed by \pkg{RprobitB}. Furthermore, the package enables to identify groups of deciders that share similar preferences.

3. Finally, the package enables prediction of choice behavior when certain choice attributes change, for example the proportion of customers who will choose the competitor's product in the event of a price increase.

The functions of \pkg{RprobitB} can be grouped into ones for data management, model fitting, and model evaluation, see the flowchart below. The package can be used for two different purposes: (a) estimation of a model for given data and (b) estimation of a model for simulated data. Simulation typically serves to assess the properties of estimation algorithms either for research or in a bootstrap like fashion. \pkg{RprobitB} supports these functions.

\begin{figure}[t!]
  \includegraphics[scale = 0.4]{flowchart.png}
  \caption{Flowchart of the package functionality.}
  \label{fig:flowchart}
\end{figure}


\section{The probit model} \label{sec:probit_model}

The probit model is a regression-type model where the dependent variable only takes a finite number of values and the error term is normally distributed \citep{Agresti:2015}. Its purpose is to estimate the probability that the dependent variable takes a certain, discrete value. The model's most popular application are discrete choice scenarios, in which the dependent variable is one of finitely many and mutually exclusive alternatives (that are not ordered), and explanatory variables typically are characteristics of the deciders or the alternatives. This section defines the model via latent utilities, outlines an extension for modeling heterogeneity, and discusses necessary normalization for parameter identification.

\subsection{Latent utilities} \label{subsec:latent_utilities}

Assume that we possess data of $N$ decision makers which choose between $J \geq 2$ alternatives at each of $T$ choice occasions.\footnote{For notational simplicity, the number of choice occasions $T$ is assumed to be the same for each decision maker here. However, we are not restricted to this case: \pkg{RprobitB} allows for unbalanced panels, i.e. varying $T$. Of course, the cross-sectional case $T = 1$ is possible.} Specific to each decision maker, alternative and choice occasion, we furthermore observe $P$ choice attributes that we use to explain the choices. The choice attributes cannot be linked directly to the discrete choices but must take a detour over a latent variable. In the discrete choice setting, this variable can be interpreted as the decider's utility of a certain alternative. Decider $n$'s utility $U_{ntj}$ for alternative $j$ at choice occasion $t$ is modeled as

\begin{equation}
  \label{eqn:utility}
  U_{ntj} = X_{ntj}'\beta + \epsilon_{ntj}
\end{equation}

for $n=1,\dots,N$, $t=1,\dots,T$ and $j=1,\dots,J$. Here, $X_{ntj}$ is a (column) vector of $P$ characteristics of $j$ as faced by $n$ at $t$, $\beta \in {\mathbb R}^{P}$ is a vector of coefficients, and $(\epsilon_{nt:}) = (\epsilon_{nt1},\dots,\epsilon_{ntJ})' \sim \text{MVN}_{J} (0,\Sigma)$ is the model's error term vector for $n$ at $t$, which in the probit model is assumed to be multivariate normally distributed with zero mean and covariance matrix $\Sigma$.\footnote{The assumption about the error-term distribution distinguishes the probit from the logit model. In the latter, each $\epsilon_{nti}$ is assumed to be independently extreme value distributed.}

Now let $y_{nt}=j$ denote the event that decision maker $n$ chooses alternative $j$ at choice occasion $t$. Assuming utility maximizing behavior of the decision makers, the decisions are linked to the utilities via

\begin{equation}
y_{nt} = {\arg \max}_{j = 1,\dots,J} U_{ntj}.
\end{equation}

\subsection{Choice behavior heterogeneity} \label{subsec:heterogeneity}

Note that the coefficient vector $\beta$ in equation \ref{eqn:utility} is constant across decision makers. This assumption is too restrictive for many applications.\footnote{For example, consider the case of modeling the choice of a means of transportation to work: It is easily imaginable that business people and pensioners do not share the same sensitivities towards cost and time.} Relaxing this assumption, heterogeneity in choice behavior can be modeled by imposing a distribution on $\beta$ such that each decider can have their own preferences.

Formally, we define $\beta = (\alpha, \beta_n)$, where $\alpha$ are $P_f$ coefficients that are constant across deciders and $\beta_n$ are $P_r$ decider-specific coefficients. Consequently, $P = P_f + P_r$. Now if $P_r>0$, $\beta_n$ is distributed according to some $P_r$-variate distribution, the so-called mixing distribution.

Choosing an appropriate mixing distribution is a notoriously difficult task of the model specification. In many applications, different types of standard parametric distributions (including the normal, log-normal, uniform and tent distribution) are tried in conjunction with a likelihood value-based model selection, cf. \cite{Train:2009}, Chapter 6. Instead, \pkg{RprobitB} implements the approach of \cite{Oelschlaeger:2020} to approximate any underlying mixing distribution by a mixture of (multivariate) Gaussian densities. More precisely, the underlying mixing distribution for the random coefficients $(\beta_n)_{n}$ is approximated by a mixture of $P_r$-variate normal densities $\phi_{P_r}$ with mean vectors $b=(b_c)_{c}$ and covariance matrices $\Omega=(\Omega_c)_{c}$ using $C$ components:

\begin{equation}
\beta_n\mid b,\Omega \sim \sum_{c=1}^{C} s_c \phi_{P_r} (\cdot \mid b_c,\Omega_c).
\end{equation}

Here, $(s_c)_{c}$ are weights satisfying $0 < s_c\leq 1$ for $c=1,\dots,C$ and $\sum_c s_c=1$. One interpretation of the latent class model is obtained by introducing variables $z=(z_n)_n$, allocating each decision maker $n$ to class $c$ with probability $s_c$, i.e.

\begin{equation}
\text{Prob}(z_n=c)=s_c \land \beta_n \mid z,b,\Omega \sim \phi_{P_r}(\cdot \mid b_{z_n},\Omega_{z_n}).
\end{equation}

This interpretation enables a classification of the deciders in terms of their preferences, see Section ... for an example.

\subsection{Model normalization} \label{subsec:normalization}

Any utility model is invariant towards the level and the scale of utility, as \cite{Train:2009} points out. Therefore, we consider the normalized model

\begin{equation}
\tilde{U}_{ntj} = \tilde{X}_{ntj}' \beta + \tilde{\epsilon}_{ntj},
\end{equation}

$n=1,\dots,N$, $t=1,\dots,T$ and $j=1,\dots,J-1$, where (choosing $J$ as the reference alternative) $\tilde{U}_{ntj} = U_{ntj} - U_{ntJ}$, $\tilde{X}_{ntj} = X_{ntj} - X_{ntJ}$, and $\tilde{\epsilon}_{ntj} = \epsilon_{ntj} - \epsilon_{ntJ}$, where $(\tilde{\epsilon}_{nt:}) = (\tilde{\epsilon}_{nt1},...,\tilde{\epsilon}_{nt(J-1)})' \sim \text{MVN}_{J-1} (0,\tilde{\Sigma})$ and $\tilde{\Sigma}$ denotes a covariance matrix with the top-left element restricted to one.\footnote{\pkg{RprobitB} provides an alternative to fixing an error term variance in order to normalize with respect to scale by fixing an element of $\alpha$, see Section ...}

\section{Choice data} \label{sec:choice_data}

This section formulates data requirements and introduces the formula framework of \pkg{RprobitB} for specifying a model equation. Subsequently, we demonstrate how to pass a formula to either \fct{prepare\_data} (for preparing an empirical data set) or \fct{simulate\_choices} (for simulating choices) with the help of examples.

\subsection{Data requirements} \label{subsec:data_requirements}

Choice data sets typically consist of the observed choices in conjunction with choice characteristics.\footnote{In \pkg{RprobitB} only unordered alternatives (that is, alternatives cannot be ranked) are modeled. Every decider may take one or repeated choices (called choice occasions).} The following formal requirements are requested by \pkg{RprobitB}: Data sets must be (a) of class \class{data.frame}, (b) in wide format (that means each row provides the full information for one choice occasion), (c) contain a column with unique identifiers for each decision maker\footnote{Additionally, it can contain a column with identifier for each choice situation of each decider. If this information is missing, these identifier are generated automatically by the appearance of the choices in the data set.}, (d) contain a column with the observed choices (required for model fitting but not for prediction), and (e) contain columns for the values of each alternative specific covariate for each alternative and for each decider specific covariate. The underlying set of choice alternatives is assumed to be mutually exclusive (one can choose one and only one alternative that are all different), exhaustive (the alternatives do not leave other options open), and finite \citep{Train:2009}.

\subsection{Model formula} \label{subsec:model_formula}

We have to inform \pkg{RprobitB} about the covariates we want to include in our model via specifying a \code{formula} object. Say we want to model the utility $U_{n,t,j}$ of decider $n$ at choice occasion $t$ for alternative $j$ via the linear equation

$$U_{n,t,j} = A_{n,t,j} \beta_1 + B_{n,t} \beta_{2,j} + C_{n,t,j} \beta_{3,j} + \epsilon_{n,tj}.$$

Here, $A$ and $C$ are alternative and choice situation specific covariates, whereas $B$ is choice situation specific. The coefficient $\beta_1$ is generic (i.e. the same for each alternative), whereas $\beta_{2,j}$ and $\beta_{3,j}$ are alternative specific.

To represent this structure, the \code{formula} object is of the form (analogously to {mlogit}) \code{choice ~ A | B | C}, where

- \code{choice} is the dependent variable (the discrete choice we aim to explain),

- \code{A} are alternative and choice situation specific covariates with a generic coefficient (we call them covariates of type 1),

- \code{B} are choice situation specific covariates with alternative specific coefficients. Mind that not all alternative specific coefficients of type 2-covariates are identified. This is because the probit model is estimated on utility differences since the level of the utility is irrelevant, see the vignette on the model definition. Therefore, the coefficient of the last alternative of each type 2-covariate is set to 0. (we call them covariates of type 2),

- and \code{C} are alternative and choice situation specific covariates with
alternative specific coefficients (we call them covariates of type 3).

Specifying a \code{formula} object for \pkg{RprobitB} must be consistent with the following rules:

- By default, alternative specific constants (ASCs) ASCs capture the average effect on utility of all factors that are not included in the model. Due to identifiability, we cannot estimate ASCs for all the alternatives. Therefore, they are added for all except for the last alternative. are added to the model. They can be removed by adding \code{+ 0} in the second spot, e.g. \code{choice ~ A | B + 0 | C}.

- To exclude covariates of the backmost categories, use either \code{0}, e.g. \code{choice ~ A | B | 0} or just leave this part out and write \code{choice ~ A | B}. However, to exclude covariates of front categories, we have to use \code{0}, e.g. \code{choice ~ 0 | B}.

- To include more than one covariate of the same category, use \code{+}, e.g. \code{choice ~ A1 + A2 | B}.

- If we don't want to include any covariates of the second category but we want to estimate alternative specific constants, add \code{1} in the second spot, e.g. \code{choice ~ A | 1}. The expression \code{choice ~ A | 0} is interpreted as no covariates of the second category and no alternative specific constants.

To impose random effects for specific variables, we need to define a character vector \code{re} with the corresponding variable names. To have random effects for the alternative specific constants, include \code{"ASC"} in \code{re}.

\subsection{The prepare data function} \label{subsec:prepare_data}

Before model estimation with \pkg{RprobitB}, any empirical choice data set \code{choice_data} must pass the \fct{prepare\_data} function:

<<prepare-data-call, eval=FALSE>>=
data <- prepare_data(form = form, choice_data = choice_data)
@

The function performs compatibility checks and data transformations and returns an object of class \class{RprobitB\_data} that can be fed into the estimation routine \fct{mcmc}. The following arguments are optional:

- \code{re}: The character vector of variable names of \code{form} with random effects. \code{re = NULL} per default, i.e. no random effects.

- \code{alternatives}: We may not want to consider all alternatives in \code{choice_data}. In that case, we can specify a character vector \code{alternatives} with selected names of alternatives. If not specified, the choice set is defined by the observed choices.

- \code{id}: A character (single string), the name of the column in \code{choice_data} that contains a unique identifier for each decision maker. The default is \code{"id"}.

- \code{idc}: A character, the name of the column in \code{choice_data} that contains a unique identifier for each choice situation given the decision maker. Per default, these identifier are generated by the appearance of the choices in the data set.

- \code{standardize}: A character vector of variable names of \code{form} that get standardized. Covariates of type 1 or 3 have to be addressed by \code{<covariate>_<alternative>}. If \code{standardize = "all"}, all covariates get standardized. Per default, no covariate is standardized.

- \code{impute}: Specifies how to handle missing entries (\code{NA, NaN, -Inf, Inf}) in \code{choice_data}. The following options are available:

  - \code{"complete_cases"}, which removes rows containing missing entries (the default),

  - \code{"zero_out"}, which replaces missing entries by zero,

  - \code{"mean"}, which imputes missing entries by the covariate mean.

\subsection{Example 1: Train data} \label{subsec:train_data_prep}

The Train data set contains 2929 stated choices by 235 Dutch individuals deciding between two virtual train trip options based on the price, the travel time, the level of comfort, and the number of changes. It fulfills the above requirements: Each row represents one choice occasion, the columns \code{id} and \code{choiceid} identify the deciders and the choice occasions, respectively. The column \code{choice} gives the observed choices. Four alternative-specific covariates are available, namely \code{price}, \code{time}, \code{change}, and \code{comfort}. There values are given for each alternative. For alternative specific variables, the alternative names must be added to the covariates via the \code{\_} separator.

<<overview-Train-data>>=
data("Train", package = "mlogit")
str(Train)
@

We specify a model formula for the Train data set. Say we want to include all the covariates \code{price}, \code{time}, \code{comfort}, and \code{change}, which are all alternative specific (that is, they contain a potentially different value for each alternative, such as different prices for A and B), so either of type 1 or type 3. The difference between type 1 and type 3 is that in the former case, we would estimate a generic coefficient (i.e. a coefficient that is constant across alternatives), whereas in the latter case, we would estimate alternative specific coefficients. Deciding between type 1 and type 3 for these covariates belongs into the topic of model selection, for which we provide a separate vignette. For now, we go with type 1 for all covariates and remove ASCs:

<<Train-formula>>=
form <- choice ~ price + time + comfort + change | 0
@

Additionally, we specify random effects for \code{price} and \code{time} (because we would typically expect heterogeneity here):

<<Train-re>>=
re <- c("price","time")
@

\pkg{RprobitB} provides the function \fct{check\_form} which can be used to check if \code{form} and \code{re} are correctly interpreted:

<<check-form>>=
check_form(form = form, re = re)
@

Let's prepare the Train data set for estimation with our previous specification of \code{form} and \code{re}:

<<prepare-Train-data>>=
data <- prepare_data(form = form, choice_data = Train, re = re, id = "id", idc = "choiceid")
@

The \fct{summary} and \fct{plot} methods provide a quick data overview:

<<summary-plot-Train-data, fig=TRUE, width = 9>>=
summary(data)
plot(data)
@

\subsection{Simulate choices} \label{subsec:simulate_choices}

The \fct{simulate\_choices} function simulates discrete choice data from a prespecified probit model. Say we want to simulate the choices of \code{N} deciders in \code{T} choice occasions (\code{T} can be either a positive number, representing a fixed number of choice occasions for each decision maker, or a vector of length \code{N} with decision maker specific numbers of choice occasions) among \code{J} alternatives from a model formulation \code{form}, we have to call

<<simulate-choices-call, eval=FALSE>>=
data <- simulate_choices(form = form, N = N, T = T, J = J)
@

The function \fct{simulate\_choices} has the following optional arguments:

- \code{re}: The character vector of variable names of \code{form} with random effects.

- \code{alternatives}: A character vector of length \code{J} with the names of the choice alternatives. If not specified, the alternatives are labeled by the first \code{J} upper-case letters of the Roman alphabet.

- \code{covariates}: A named list of covariate values. Each element must be a vector of length equal to the number of choice occasions and named according to a covariate, or follow the naming convention for alternative specific covariates, i.e. \code{<covariate>\_<alternative>}. Covariates for which no values are specified are drawn from a standard normal distribution.

- \code{standardize}: A character vector of variable names of \code{form} that get standardized.

- \code{seed}: Set a seed for the simulation.

We can specify the true parameters by adding values for

- \code{alpha}, the fixed coefficient vector,

- \code{C}, the number (greater or equal 1) of latent classes of decision makers,

- \code{s}, the vector of class weights,

- \code{b}, the matrix of class means as columns,

- \code{Omega}, the matrix of class covariance matrices as columns,

- \code{Sigma}, the differenced error term covariance matrix, or \code{Sigma\_full}, the full error term covariance matrix,

- \code{beta}, the matrix of the decision-maker specific coefficient vectors,

- \code{z}, the class allocation vector.

True parameters that are not specified will be set at random.

\subsection{Example 2: Simulated choices} \label{subsec:example_simulated_choices}

For illustration, we simulate the choices of \code{N = 100} deciders at \code{T = 10} choice occasions between the alternatives \code{A} and \code{B}:

<<data-sim-meta>>=
N <- 100
T <- 10
alternatives <- c("A", "B")
form <- choice ~ var1 | var2 | var3
re <- c("ASC", "var2")
@

\pkg{RprobitB} provides the function \fct{overview\_effects} which can be used to get an overview of the effects for which parameters can be specified:

<<data-sim-overview>>=
overview_effects(form = form, re = re, alternatives = alternatives)
@

Hence, the coefficient vector \code{alpha} must be of length 3, where the elements 1 to 3 correspond to \code{var1}, \code{var3\_A}, and \code{var3\_B}, respectively. The matrix \code{b} must be of dimension \code{2 x C}, where (by default) \code{C = 1} and row 1 and 2 correspond to \code{var2\_A} and \code{ASC\_A}, respectively.

<<data-sim>>=
data <- simulate_choices(
  form = form,
  N = N,
  T = T,
  J = 2,
  re = re,
  alternatives = alternatives,
  seed = 1,
  alpha = c(-1,0,1),
  b = matrix(c(2,-0.5), ncol = 1)
)
summary(data)
@

We can visualize the covariates grouped by the chosen alternatives:

<<data-sim-plot-by-choice, fig=TRUE, width = 9>>=
plot(data, by_choice = TRUE)
@

What we see is consistent with our specification: Higher values of \code{var1\_A} for example correspond more frequently to choice \code{B} (upper-right panel), because the coefficient of \code{var1} (the first value of \code{alpha}) is negative.

\subsection{Train and test data set} \label{subsec:train_test}

The function \fct{train\_test} can be used to split the output of \fct{prepare\_data} or \fct{simulate\_choices} into a train and a test subset. This is useful when evaluating the prediction performance of a fitted model. For example, the following code puts 70\% of deciders from our simulated \code{data} into the train subsample and 30\% of deciders in the test subsample:

<<data-split-deciders>>=
train_test(data, test_proportion = 0.3, by = "N")
@

Alternatively, the following code puts 2 randomly chosen choice occasions per decider from \code{data} into the test subsample, the rest goes into the train subsample:

<<data-split-occasions>>=
train_test(data, test_number = 2, by = "T", random = TRUE, seed = 1)
@

\section{Model fitting} \label{sec:model_fitting}

Bayes estimation of the probit model builds upon the work of \cite{McCulloch:1994}, \cite{Nobile:1998}, \cite{Allenby:1998}, and \cite{Imai:2005}. A key ingredient is the concept of data augmentation, see \cite{Albert:1993}: The idea is to treat the latent utilities $U$ in the model equation $U = X\beta + \epsilon$ as additional parameters. Then, conditional on $U$, the probit model constitutes a standard Bayesian linear regression set-up. Its posterior distribution can be approximated by iteratively drawing and updating each model parameter conditional on the other parameters (the so-called Gibbs sampling approach).

A priori, we assume the following (conjugate) parameter distributions:

- $(s_1,\dots,s_C)\sim D_C(\delta)$, where $D_C(\delta)$ denotes the $C$-dimensional Dirichlet distribution with concentration parameter vector $\delta = (\delta_1,\dots,\delta_C)$,

- $\alpha\sim \text{MVN}_{P_f}(\psi,\Psi)$, where $\text{MVN}_{P_f}$ denotes the $P_f$-dimensional normal distribution with mean $\psi$ and covariance $\Psi$,

- $b_c \sim \text{MVN}_{P_r}(\xi,\Xi)$, independent for all $c$,

- $\Omega_c \sim W^{-1}_{P_r}(\nu,\Theta)$, independent for all $c$, where $W^{-1}_{P_r}(\nu,\Theta)$ denotes the $P_r$-dimensional inverse Wishart distribution with $\nu$ degrees of freedom and scale matrix $\Theta$,

- and $\Sigma \sim W^{-1}_{J-1}(\kappa,\Lambda)$.

These prior distributions imply the following conditional posterior distributions:

- The class weights are drawn from the Dirichlet distribution
\begin{equation}
(s_1,\dots,s_C)\mid \delta,z \sim D_C(\delta_1+m_1,\dots,\delta_C+m_C),
\end{equation}
where for $c=1,\dots,C$, $m_c=\#\{n:z_n=c\}$ denotes the current absolute class size. Mind that the model is invariant to permutations of the class labels $1,\dots,C$. For that reason, we accept an update only if the ordering $s_1>\dots>s_C$ holds, thereby ensuring a unique labeling of the classes.

- Independently for all $n$, we update the allocation variables $(z_n)_n$ from their conditional distribution
\begin{equation}
\text{Prob}(z_n=c\mid s,\beta,b,\Omega )=\frac{s_c\phi_{P_r}(\beta_n\mid b_c,\Omega_c)}{\sum_c s_c\phi_{P_r}(\beta_n\mid b_c,\Omega_c)}.
\end{equation}

- The class means $(b_c)_c$ are updated independently for all $c$ via
\begin{equation}
b_c\mid \Xi,\Omega,\xi,z,\beta \sim\text{MVN}_{P_r}\left( \mu_{b_c}, \Sigma_{b_c}  \right),
\end{equation}
where $\mu_{b_c}=(\Xi^{-1}+m_c\Omega_c^{-1})^{-1}(\Xi^{-1}\xi +m_c\Omega_c^{-1}\bar{b}_c)$, $\Sigma_{b_c}=(\Xi^{-1}+m_c\Omega_c^{-1})^{-1}$, $\bar{b}_c=m_c^{-1}\sum_{n:z_n=c} \beta_n$.

- The class covariance matrices $(\Omega_c)_c$ are updated independently for all $c$ via
\begin{equation}
\Omega_c \mid \nu,\Theta,z,\beta,b \sim W^{-1}_{P_r}(\mu_{\Omega_c},\Sigma_{\Omega_c}),
\end{equation}
where $\mu_{\Omega_c}=\nu+m_c$ and $\Sigma_{\Omega_c}=\Theta^{-1} + \sum_{n:z_n=c} (\beta_n-b_c)(\beta_n-b_c)'$.

- Independently for all $n$ and $t$ and conditionally on the other components, the utility vectors $(U_{nt:})$ follow a $J-1$-dimensional truncated multivariate normal distribution, where the truncation points are determined by the choices $y_{nt}$. To sample from a truncated multivariate normal distribution, we apply a sub-Gibbs sampler, following the approach of \cite{Geweke:1998}:
\begin{equation}
U_{ntj} \mid U_{nt(-j)},y_{nt},\Sigma,W,\alpha,X,\beta
\sim \mathcal{N}(\mu_{U_{ntj}},\Sigma_{U_{ntj}}) \cdot \begin{cases}
1(U_{ntj}>\max(U_{nt(-j)},0) ) & \text{if}~ y_{nt}=j\\
1(U_{ntj}<\max(U_{nt(-j)},0) ) & \text{if}~ y_{nt}\neq j
\end{cases},
\end{equation}
where $U_{nt(-j)}$ denotes the vector $(U_{nt:})$ without the element $U_{ntj}$, $\mathcal{N}$ denotes the univariate normal distribution, $\Sigma_{U_{ntj}} = 1/(\Sigma^{-1})_{jj}$ and
\begin{equation}
\mu_{U_{ntj}} = W_{ntj}'\alpha + X_{ntj}'\beta_n - \Sigma_{U_{ntj}} (\Sigma^{-1})_{j(-j)}   (U_{nt(-j)} - W_{nt(-j)}'\alpha - X_{nt(-j)}' \beta_n ),
\end{equation}
where $(\Sigma^{-1})_{jj}$ denotes the $(j,j)$th element of $\Sigma^{-1}$, $(\Sigma^{-1})_{j(-j)}$ the $j$th row without the $j$th entry, $W_{nt(-j)}$ and $X_{nt(-j)}$ the coefficient matrices $W_{nt}$ and $X_{nt}$, respectively, without the $j$th column.

- Updating the fixed coefficient vector $\alpha$ is achieved by applying the formula for Bayesian linear regression of the regressors $W_{nt}$ on the regressands $(U_{nt:})-X_{nt}'\beta_n$, i.e.
\begin{equation}
\alpha \mid \Psi,\psi,W,\Sigma,U,X,\beta \sim \text{MVN}_{P_f}(\mu_\alpha,\Sigma_\alpha),
\end{equation}
where $\mu_\alpha = \Sigma_\alpha (\Psi^{-1}\psi + \sum_{n=1,t=1}^{N,T} W_{nt} \Sigma^{-1} ((U_{nt:})-X_{nt}'\beta_n) )$ and $\Sigma_\alpha = (\Psi^{-1} + \sum_{n=1,t=1}^{N,T} W_{nt}\Sigma^{-1} W_{nt}^{'} )^{-1}$.

- Analogously to $\alpha$, the random coefficients $(\beta_n)_n$ are updated independently via
\begin{equation}
\beta_n \mid \Omega,b,X,\Sigma,U,W,\alpha \sim \text{MVN}_{P_r}(\mu_{\beta_n},\Sigma_{\beta_n}),
\end{equation}
where $\mu_{\beta_n} = \Sigma_{\beta_n} (\Omega_{z_n}^{-1}b_{z_n} + \sum_{t=1}^{T} X_{nt} \Sigma^{-1} (U_{nt}-W_{nt}'\alpha) )$ and $\Sigma_{\beta_n} = (\Omega_{z_n}^{-1} + \sum_{t=1}^{T} X_{nt}\Sigma^{-1} X_{nt}^{'} )^{-1}$ .

- The error term covariance matrix $\Sigma$ is updated by means of
\begin{equation}
\Sigma \mid \kappa,\Lambda,U,W,\alpha,X,\beta \sim W^{-1}_{J-1}(\kappa+NT,\Lambda+S), \\
\end{equation}
where $S = \sum_{n=1,t=1}^{N,T} \varepsilon_{nt} \varepsilon_{nt}'$ and $\varepsilon_{nt} = (U_{nt:}) - W_{nt}'\alpha - X_{nt}'\beta_n$.

\subsection{Parameter normalization} \label{subsec:parameter_normalization}

Samples obtained from the updating scheme described above lack identification (except for $s$ and $z$ draws), compare to the vignette on the model definition. Therefore, subsequent to the sampling, the following normalization is required for the $i$th update in each iteration $i$:

- $\alpha^{(i)} \cdot \omega^{(i)}$,

- $b_c^{(i)} \cdot \omega^{(i)}$, $c=1,\dots,C$,

- $U_{nt}^{(i)} \cdot \omega^{(i)}$, $n = 1,\dots,N$, $t = 1,\dots,T$,

- $\beta_n^{(i)} \cdot \omega^{(i)}$, $n = 1,\dots,N$,

- $\Omega_c^{(i)} \cdot (\omega^{(i)})^2$, $c=1,\dots,C$, and

- $\Sigma^{(i)} \cdot (\omega^{(i)})^2$,

where either $\omega^{(i)} = \sqrt{\text{const} / (\Sigma^{(i)})_{jj}}$ with $(\Sigma^{(i)})_{jj}$ the $j$th diagonal element of $\Sigma^{(i)}$, $1\leq j \leq J-1$, or alternatively $\omega^{(i)} = \text{const} / \alpha^{(i)}_p$ for some coordinate $1\leq p \leq P_f$ of the $i$th draw for the coefficient vector $\alpha$. Here, $\text{const}$ is any positive constant (typically 1). The preferences will be flipped if $\omega^{(i)} < 0$, which only is the case if $\alpha^{(i)}_p < 0$.

\subsection{Burn-in and thinning} \label{subsec:burn_thin}

The theory behind Gibbs sampling constitutes that the sequence of samples produced by the updating scheme is a Markov chain with stationary distribution equal to the desired joint posterior distribution. It takes a certain number of iterations for that stationary distribution to be approximated reasonably well. Therefore, it is common practice to discard the first $B$ out of $R$ samples (the so-called burn-in period). Furthermore, correlation between nearby samples should be expected. In order to obtain independent samples, we consider only every $Q$th sample when computing Gibbs sample statistics like expectation and standard deviation. The independence of the samples can be verified by computing the serial correlation and the convergence of the Gibbs sampler can be checked by considering trace plots, see below.

\subsection{The mcmc function} \label{subsec:mcmc_function}

The Gibbs sampling scheme described above can be executed by applying the function

<<mcmc-call, eval=FALSE>>=
mcmc(data = data)
@

where \code{data} must be an \class{RprobitB\_data} object (see the vignette about choice data). The function has the following optional arguments:

- \code{scale}: A named list of three elements, determining the parameter normalization:

  - \code{parameter}: Either \code{"a"} (for an element of \code{alpha}) or \code{"s"} (for a diagonal element of \code{Sigma}). Use the \fct{overview\_effects} function to determine the parameter index. Note that you can set \code{"parameter" = "a"} only if the model has parameters with a fixed coefficient, i.e. only if \code{P\_f>0}.

  - \code{index}: The index of the parameter that gets fixed.

  - \code{value}: The value for the fixed parameter (i.e. the value $\text{const}$ introduced above.

  Per default, the first error-term variance is fixed to 1, i.e. \code{scale = list("parameter" = "s", "index" = 1, "value" = 1)}.

- \code{R}: The number of iterations of the Gibbs sampler. The default is \code{R = 10000}.

- \code{B}: The length of the burn-in period, i.e. a non-negative number of samples to be discarded. The default is \code{B = R/2}.

- \code{Q}: The thinning factor for the Gibbs samples, i.e. only every \code{Q}th sample is kept. The default is \code{Q = 1}.

- \code{print\_progress}: A boolean, determining whether to print the Gibbs sampler progress.

- \code{prior}: A named list of parameters for the prior distributions (their default values are documented in the \fct{check\_prior} function):

  - \code{eta}: The mean vector of length \code{P\_f} of the normal prior for \code{alpha}.

  - \code{Psi}: The covariance matrix of dimension \code{P\_f x P\_f} of the normal prior for \code{alpha}.

  - \code{delta}: The concentration parameter of length 1 of the Dirichlet prior for \code{s}.

  - \code{xi}: The mean vector of length \code{P\_r} of the normal prior for each \code{b\_c}.

  - \code{D}: The covariance matrix of dimension \code{P\_r} x \code{P\_r} of the normal prior for each \code{b\_c}.

  - \code{nu}: The degrees of freedom (a natural number greater than \code{P\_r}) of the Inverse Wishart prior for each \code{Omega\_c}.

  - \code{Theta}: The scale matrix of dimension \code{P\_r} x \code{P\_r} of the Inverse Wishart prior for each \code{Omega\_c}.

  - \code{kappa}: The degrees of freedom (a natural number greater than \code{J-1}) of the Inverse Wishart prior for \code{Sigma}.

  - \code{E}: The scale matrix of dimension \code{J-1} x \code{J-1} of the Inverse Wishart prior for \code{Sigma}.

- \code{latent\_classes}: A list of parameters specifying the number and the updating scheme of latent classes, see the vignette on modeling heterogeneity fitting.

\subsection{Example 1: Train (cont.)} \label{subsec:train_cont}

In the previous vignette on choice data we introduced the Train data set from the mlogit package \citep{Croissant:2020} that contains 2922 choices between two fictional train route alternatives. First, we transform the travel \code{time} from minutes to hours and the travel \code{price} from guilders to euros:

<<transform-Train>>=
data("Train", package = "mlogit")
Train$price_A <- Train$price_A / 100 * 2.20371
Train$price_B <- Train$price_B / 100 * 2.20371
Train$time_A <- Train$time_A / 60
Train$time_B <- Train$time_B / 60
@

The following lines fit a probit model that explains the chosen trip alternatives (\code{choice}) by their \code{price}, \code{time}, number of \code{change} s, and level of \code{comfort} (the lower this value the higher the comfort). For normalization, the first linear coefficient, the \code{price}, was fixed to \code{-1}, which allows to interpret the other coefficients as monetary values:

<<Train-fit, eval=FALSE>>=
form <- choice ~ price + time + change + comfort | 0
data <- prepare_data(form = form, choice_data = Train)
model_train <- mcmc(
  data = data,
  scale = list("parameter" = "a", index = 1, value = -1)
)
@

The estimated model is saved in \pkg{RprobitB} and can be accessed via

<<load-model-Train>>=
data(model_train, package = "RprobitB")
@

The estimated coefficients (using the mean of the Gibbs samples as a point estimate) can be printed via

<<coef-model-Train>>=
coef(model_train)
@

and visualized via

<<plot-coef-model-train, fig=TRUE>>=
plot(coef(model_train), sd = 3)
@

The results indicate that the deciders value one hour travel time by about 25 euros, an additional change by 5 euros, and a more comfortable class by 14 euros. These results are consistent with the ones that are presented in a vignette of the mlogit package on the same data set but using the logit model.

\subsection{Checking the Gibbs samples} \label{subsec:checking-gibbs-samples}

The Gibbs samples are saved in list form in the \class{RprobitB\_fit} object at the entry \code{"gibbs\_samples"}, i.e.

<<str-gibbs-samples>>=
str(model_train$gibbs_samples, max.level = 2, give.attr = FALSE)
@

This object contains 2 elements:

- \code{gibbs\_samples\_raw} is a list of the raw samples from the Gibbs sampler,

- and \code{gibbs\_samples\_nbt} are the Gibbs samples used for parameter estimates, i.e. the normalized and thinned Gibbs samples after the burn-in.

Calling the summary function on the estimated \class{RprobitB\_fit} object yields additional information about the Gibbs samples \code{gibbs\_samples\_nbt}. You can specify a list \code{FUN} of functions that compute any point estimate of the Gibbs samples (Use the function \fct{point\_estimates} to access the Gibbs sample statistics as an \class{RprobitB\_parameter} object), for example

- \fct{mean} for the arithmetic mean,

- \fct{stats::sd} for the standard deviation,

- \fct{R\_hat} for the Gelman-Rubin statistic \citep{Gelman:1992} (A Gelman-Rubin statistic close to 1 indicates that the chain of Gibbs samples converged to the stationary distribution),

- or custom statistics like the absolute difference between the median and the mean.

<<summary-model-train>>=
summary(model_train,
        FUN = c("mean"        = mean,
                "sd"          = stats::sd,
                "R^"          = R_hat,
                "custom_stat" = function(x) abs(mean(x) - median(x))
                )
       )
@

Calling the \fct{plot} method with the additional argument \code{type = "trace"} plots the trace of the Gibbs samples \code{gibbs\_samples\_nbt}:

<<plot-trace-model-train, fig=TRUE>>=
par(mfrow = c(2,1))
plot(model_train, type = "trace")
@

Additionally, we can visualize the serial correlation of the Gibbs samples via the argument \code{type = "acf"}. The boxes in the top-right corner state the total sample size TSS (here \code{R} - \code{B} = 10000 - 5000 = 5000), the effective sample size ESS, and the factor by which TSS is larger than ESS.

<<plot-acf-model-train, fig=TRUE>>=
par(mfrow = c(2,3))
plot(model_train, type = "acf")
@

Here, the effective sample size is the value $\text{TSS} / (1 + \sum_{k\geq 1} \rho_k)$, where $\rho_k$ is the auto correlation between the chain offset by $k$ positions. The auto correlations are estimated via the \fct{stats::acf} function.

\subsection{Model transformation after estimation} \label{subsec:model_transformation}

The \fct{transform} method can be used to transform an \class{RprobitB\_fit} object in three ways:

1. change the length \code{B} of the burn-in period, for example
<<transform-model-train-B>>=
model_train <- transform(model_train, B = 1)
@

2. change the thinning factor \code{Q} of the Gibbs samples, for example
<<transform-model-train-Q>>=
model_train <- transform(model_train, Q = 100)
@

3. or change the model normalization \code{scale}, for example
<<transform-model-train-scale>>=
model_train <- transform(model_train, scale = list(parameter = "s", index = 1, value = 1))
@

\subsection{Estimating a joint normal mixing distribution} \label{subsec:normal_mix}

The \pkg{mlogit} package \citep{Croissant:2020} contains the data set \code{Electricity}, in which residential electricity customers were asked to decide between four hypothetical electricity suppliers. The suppliers differed in 6 characteristics:

1. their fixed price \code{pf} per kWh,
2. their contract length \code{cf},
3. a boolean \code{loc}, indicating whether the supplier is a local company,
4. a boolean \code{wk}, indicating whether the supplier is a well known company,
5. a boolean \code{tod}, indicating whether the supplier offers a time-of-day electricity price (which is higher during the day and lower during the night), and
6. a boolean \code{seas}, indicating whether the supplier's price is seasonal dependent.

This constitutes a choice situation where choice behavior heterogeneity is expected: some customers might prefer a time-of-day electricity price (because they may be not at home during the day), while others can have the opposite preference. Ideally these differences in preferences should be modeled using characteristics of the deciders. In many cases (as in this data set) we do not have adequate information. Instead these differences in taste can be captured by means of a mixing distribution for the \code{tod} coefficient. This corresponds to the assumption of a random coefficient from the underlying mixing distribution to be drawn for each decider. We can use the estimated mixing distribution to determine for example the share of deciders that have a positive versus negative preference towards time-of-day electricity prices.

Additionally, we expect correlations between the random coefficients to certain covariates, for example a positive correlation between the influence of \code{loc} and \code{wk}: deciders that prefer local suppliers might also prefer well known companies due to recommendations and past experiences, although they might be more expensive than unknown suppliers. The fitted multivariate normal distribution will reveal these correlations.

The following lines prepare the \code{Electricity} data set for estimation. We use the convenience function \fct{as\_cov\_names} that relabels the data columns for alternative specific covariates into the required format \code{"<covariate>\_<alternative>"}, compare to the vignette on choice data. Via the \code{re = c("cl","loc","wk","tod","seas")} argument, we specify that we want to model random effects for all but the price coefficient, which we will fix to \code{-1} to interpret the other estimates as monetary values.

<<estimate-elec-model, eval = FALSE>>=
data("Electricity", package = "mlogit")
Electricity <- as_cov_names(Electricity, c("pf","cl","loc","wk","tod","seas"), 1:4)
data <- prepare_data(
  form = choice ~ pf + cl + loc + wk + tod + seas | 0,
  choice_data = Electricity,
  re = c("cl","loc","wk","tod","seas")
  )
model_elec <- mcmc(data, R = 1000, scale = list(parameter = "a", index = 1, value = -1))
@

The estimated model is saved in \pkg{RprobitB} and can be accessed via:

<<load-model-ele>>=
data(model_elec, package = "RprobitB")
@

Calling the \fct{coef} method on the estimated model also returns the estimated (marginal) variances of the mixing distribution besides the average mean effects:

<<coef-model-elec>>=
coef(model_elec)
@

By the sign of the estimates we can for example deduce, that the existence of the time-of-day electricity price \code{tod} in the contract has a negative effect. However, the deciders are very heterogeneous here, because the estimated variance of this coefficient is large (\code{12.37}). The same holds for the contract length \code{cl}. In particular, the estimated share of the population that prefers to have a longer contract length equals:

<<compute-mixdistr-share>>=
cl_mu <- coef(model_elec)["cl","mean"]
cl_sd <- sqrt(coef(model_elec)["cl","var"])
pnorm(cl_mu / cl_sd)
@

The correlation between the covariates can be accessed as follows (setting \code{cor = FALSE} instead returns the estimated covariance matrix):

<<cov-mixdistr>>=
cov_mix(model_elec, cor = TRUE)
@

Here, we see the confirmation of our initial assumption about a high correlation between \code{loc} and \code{wk}. The pairwise mixing distributions can be visualized via calling the \fct{plot} method with the additional argument \code{type = mixture}:

<<plot-mixture-model-elec, fig=TRUE>>=
plot(model_elec, type = "mixture")
@

\subsection{Estimating latent classes} \label{subsec:latent_classes}

More generally, \pkg{RprobitB} allows to specify a Gaussian mixture as the mixing distribution. In particular,

$$ \beta \sim \sum_{c=1}^C \text{MVN} (b_c,\Omega_c).$$

This specification allows for a) a better approximation of the true underlying mixing distribution and b) a preference based classification of the deciders.

To estimate a latent mixture, specify a named list \code{latent\_classes} with the following arguments and submit it to the estimation routine \fct{mcmc}:

- \code{C}, the fixed number (greater or equal 1) of latent classes, which is set to 1 per default,

- \code{weight\_update}, a boolean, set to \code{TRUE} for a weight-based update of the latent classes, see below,

- \code{dp\_update}, a boolean, set to \code{TRUE} for a Dirichlet process-based update of the latent classes, see below,

- \code{Cmax}, the maximum number of latent classes, set to \code{10} per default.

\paragraph{Weight-based update of the latent classes:}

The following weight-based updating scheme is analogue to \cite{Bauer:2019} and executed within the burn-in period:

- We remove class $c$, if $s_c<\varepsilon_{\text{min}}$, i.e. if the class weight $s_c$ drops below some threshold $\varepsilon_{\text{min}}$. This case indicates that class $c$ has a negligible impact on the mixing distribution.

- We split class $c$ into two classes $c_1$ and $c_2$, if $s_c>\varepsilon_\text{max}$. This case indicates that class $c$ has a high influence on the mixing distribution whose approximation can potentially be improved by increasing the resolution in directions of high variance. Therefore, the class means $b_{c_1}$ and $b_{c_2}$ of the new classes $c_1$ and $c_2$ are shifted in opposite directions from the class mean $b_c$ of the old class $c$ in the direction of the highest variance.

- We join two classes $c_1$ and $c_2$ to one class $c$, if $\lVert b_{c_1} - b_{c_2} \rVert<\varepsilon_{\text{distmin}}$, i.e. if the euclidean distance between the class means $b_{c_1}$ and $b_{c_2}$  drops below some threshold $\varepsilon_{\text{distmin}}$. This case indicates location redundancy which should be repealed. The parameters of $c$ are assigned by adding the values of $s$ from $c_1$ and $c_2$ and averaging the values for $b$ and $\Omega$.

These rules contain choices on the values for $\varepsilon_{\text{min}}$, $\varepsilon_{\text{max}}$ and $\varepsilon_{\text{distmin}}$. The adequate value for $\varepsilon_{\text{distmin}}$ depends on the scale of the parameters. Per default, \pkg{RprobitB} sets  \code{epsmin = 0.01}, \code{epsmax = 0.99}, and \code{distmin = 0.1}. These values can be adapted through the \code{latent\_class} list.

\paragraph{Dirichlet process-based update of the latent classes:}

As an alternative to the weight-based updating scheme to determine the correct number $C$ of latent classes, \pkg{RprobitB} implemented the Dirichlet process. A similar approach in the context of discrete choice can be found in \cite{Burda:2008}, where the Dirichlet process is applied to estimate a mixed logit-probit model. The Dirichlet Process is a Bayesian nonparametric method, where nonparametric means that the number of model parameters can theoretically grow to infinity. The method allows to add more mixture components to the mixing distribution if needed for a better approximation, see \cite{Neal:2000} for a documentation of the general case. The literature offers many representations of the method, including the Chinese Restaurant Process \citep{Aldous:1985}, the stick-braking metaphor \citep{Sethuraman:1994}, and the Polya Urn model \citep{Blackwell:1973}.

In our case, we face the situation to find a distribution $g$ that explains the decider-specific coefficients $(\beta_n)_{n = 1,\dots,N}$, where $g$ is supposed to be a mixture of an unknown number $C$ of Gaussian densities, i.e. $g = \sum_{c = 1,\dots,C} s_c \text{MVN}(b_c, \Omega_c)$.

Let $z_n \in \{1,\dots,C\}$ denote the class membership of $\beta_n$. A priori, the mixture weights $(s_c)_c$ are given a Dirichlet prior with concentration parameter $\delta/C$, i.e. $(s_c)_c \mid \delta \sim \text{D}_C(\delta/C,\dots,\delta/C)$. \cite{Rasmussen:2000} shows that

$$ \Pr((z_n)_n\mid \delta) = \frac{\Gamma(\delta)}{\Gamma(N+\delta)} \prod_{c=1}^C \frac{\Gamma(m_c + \delta/C)}{\Gamma(\delta/C)}, $$
where $\Gamma(\cdot)$ denotes the gamma function and $m_c = \#\{n:z_n = c\}$ the number of elements that are currently allocated to class $c$. Crucially, the last equation is independent of the class weights $(s_c)_c$, yet it still depends on the finite number $C$ of latent classes. However, \cite{Li:2019} shows that

$$ \Pr(z_n = c \mid z_{-n}, \delta) = \frac{m_{c,-n} + \delta/C}{N-1+\delta},$$
where the notation $-n$ means excluding the $n$th element. We can let $C$ approach infinity to derive:

$$ \Pr(z_n = c \mid z_{-n}, \delta) \to \frac{m_{c,-n}}{N-1+\delta}. $$

Note that the allocation probabilities do not sum to 1, instead

$$ \sum_{c = 1}^C \frac{m_{c,-n}}{N-1+\delta} = \frac{N-1}{N-1+\delta}. $$

The difference to 1 equals

$$ \Pr(z_n \neq z_m ~ \forall ~ m \neq n \mid z_{-n}, \delta) = \frac{\delta}{N-1+\delta} $$

and constitutes the probability that a new cluster for observation $n$ is created. \cite{Neal:2000} points out that this probability is proportional to the prior parameter $\delta$: A greater value for $\delta$ encourages the creation of new clusters, a smaller value for $\delta$ increases the probability of an allocation to an already existing class.

In summary, the Dirichlet process updates the allocation of each $\beta$ coefficient vector one at a time, dependent on the other allocations. The number of clusters can theoretically rise to infinity, however, as we delete unoccupied clusters, $C$ is bounded by $N$. As a final step after the allocation update, we update the class means $b_c$ and covariance matrices $\Omega_c$ by means of their posterior predictive distribution. The mean and covariance matrix for a new generated cluster is drawn from the prior predictive distribution. The corresponding formulas are given in \cite{Li:2019}.

The Dirichlet process directly integrates into our existing Gibbs sampler. Given $\beta$ values, it updated the class means $b_c$ and class covariance matrices $\Omega_c$. The Dirichlet process updating scheme is implemented in the function \fct{update\_classes\_dp}. In the following, we give a small example in the bivariate case \code{P\_r = 2}. We sample true class means \code{b\_true} and class covariance matrices \code{Omega\_true} for \code{C\_true = 3} true latent classes. The true (unbalanced) class sizes are given by the vector \code{N}, and \code{z_true} denotes the true allocations.

<<sim-dirichlet>>=
set.seed(1)
P_r <- 2
C_true <- 3
N <- c(100,70,30)
(b_true <- matrix(replicate(C_true, rnorm(P_r)), nrow = P_r, ncol = C_true))
(Omega_true <- matrix(replicate(C_true, rwishart(P_r + 1, 0.1*diag(P_r))$W, simplify = TRUE),
                      nrow = P_r*P_r, ncol = C_true))
beta <- c()
for(c in 1:C_true) for(n in 1:N[c])
  beta <- cbind(beta, rmvnorm(mu = b_true[,c,drop=F], Sigma = matrix(Omega_true[,c,drop=F], ncol = P_r)))
z_true <- rep(1:3, times = N)
@

We specify the following prior parameters (for their definition see the vignette on model fitting):

<<dirichlet-prior>>=
delta <- 0.1
xi <- numeric(P_r)
D <- diag(P_r)
nu <- P_r + 2
Theta <- diag(P_r)
@

Initially, we start with \code{C = 1} latent classes. The class mean \code{b} is set to zero, the covariance matrix \code{Omega} to the identity matrix:

<<dirichlet-inits>>=
z <- rep(1, ncol(beta))
C <- 1
b <- matrix(0, nrow = P_r, ncol = C)
Omega <- matrix(rep(diag(P_r), C), nrow = P_r*P_r, ncol = C)
@

The following call to \fct{update\_classes\_dp} updates the latent classes in \code{100} iterations. Note that we specify the arguments \code{Cmax} and \code{s\_desc}. The former denotes the maximum number of latent classes. This specification is not a requirement for the Dirichlet process per se, but rather for its implementation. Knowing the maximum possible class number, we can allocate the required memory space, which leads to a speed improvement. We later can verify that we won't exceed the number of \code{Cmax = 10} latent classes at any point of the Dirichlet process. Setting \code{s\_desc = TRUE} ensures that the classes are ordered by their weights in a descending order to ensure identifiability.

<<dirichlet-process-app>>=
for(r in 1:100){
  dp <- RprobitB:::update_classes_dp(
    Cmax = 10, beta, z, b, Omega, delta, xi, D, nu, Theta, s_desc = TRUE
    )
  z <- dp$z
  b <- dp$b
  Omega <- dp$Omega
}
@

The Dirichlet process was able to infer the true number \code{C\_true = 3} of latent classes:

<<dirichlet-example-plot, fig=TRUE>>=
par(mfrow = c(1,2))
plot(t(beta), xlab = bquote(beta[1]), ylab = bquote(beta[2]), pch = 19)
RprobitB:::plot_class_allocation(beta, z, b, Omega, r = 100, perc = 0.95)
@

\section{Choice prediction} \label{sec:choice_prediction}

This section discusses in-sample and out-of-sample prediction within \pkg{RprobitB}. The former case refers to reproducing the observed choices on the basis of the covariates and the fitted model and subsequently using the deviations between prediction and reality as an indicator for the model performance. The latter means forecasting choice behavior for changes in the choice attributes. For illustration, we revisit the probit model of travelers deciding between two fictional train route alternatives:

<<load-model-train>>=
data("model_train", package = "RprobitB")
@


\subsection{Reproducing the observed choices} \label{subsec:reproducing_observed_choices}

\pkg{RprobitB} provides a \fct{predict} method for \class{RprobitB\_fit} objects. Per default, the method returns a confusion matrix, which gives an overview of the in-sample prediction performance:

<<predict-model-train>>=
predict(model_train)
@

By setting the argument \code{overview = FALSE}, the method instead returns predictions on the level of individual choice occasions:

<<predict-model-train-indlevel>>=
pred <- predict(model_train, overview = FALSE)
head(pred, n = 10)
@

Among the three incorrect predictions shown here, the one for decider \code{id = 1} in choice occasion \code{idc = 8} is the most outstanding. Alternative \code{B} was chosen although the model predicts a probability of 75\% for alternative \code{A}. We can use the convenience function \fct{get\_cov} to extract the characteristics of this particular choice situation:

<<model-train-covs>>=
get_cov(model_train, id = 1, idc = 8)
@

The trip option \code{A} was 20 euros cheaper and 30 minutes faster, which by our model outweighs the better comfort class for alternative \code{B}, recall the estimated effects:

<<model-train-coeffs>>=
coef(model_train)
@

The misclassification can be explained by preferences that differ from the average decider (choice behavior heterogeneity), or by unobserved factors that influenced the choice. Indeed, the variance of the error term was estimated high:

<<model-train-Sigma>>=
point_estimates(model_train)$Sigma
@

Apart from the prediction accuracy, the model performance can be evaluated more nuanced in terms of sensitivity and specificity. The following snippet exemplary shows how to visualize these measures by means of a receiver operating characteristic (ROC) curve \citep{Fawcett:2006}, using the \pkg{plotROC} package \citep{Sachs:2017}. The curve is constructed by plotting the true positive fraction against the false positive fraction at various cutoffs (here \code{n.cuts = 20}). The closer the curve is to the top-left corner, the better the binary classification.

<<roc-example, fig=TRUE>>=
library(plotROC)
ggplot(data = pred, aes(m = A, d = ifelse(true == "A", 1, 0))) +
  geom_roc(n.cuts = 20, labels = FALSE) +
  style_roc(theme = theme_grey)
@

\subsection{Forecasting choice behavior} \label{subsec:forcasting_choice_behavior}

The \fct{predict} method has an additional \code{data} argument. Per default, \code{data = NULL}, which results into the in-sample case outlined above. Alternatively, \code{data} can be either an \class{RprobitB\_data} object (for example the test subsample derived from the \fct{train\_test} function, or a data frame of custom choice characteristics.

We demonstrate the second case in the following. Assume that a train company wants to anticipate the effect of a price increase on their market share. By our model, increasing the ticket price from 100 euros to 110 euros (ceteris paribus) draws 15\% of the customers to the competitor who does not increase their prices.

<<predict-model-train-given-covs-1>>=
predict(
  model_train,
  data = data.frame("price_A" = c(100,110),
                    "price_B" = c(100,100)),
  overview = FALSE)
@

However, offering a better comfort class compensates for the higher price and even results in a gain of 7\% market share:

<<predict-model-train-given-covs-2>>=
predict(
  model_train,
  data = data.frame("price_A"   = c(100,110),
                    "comfort_A" = c(1,0),
                    "price_B"   = c(100,100),
                    "comfort_B" = c(1,1)),
  overview = FALSE)
@

\section{Model selection} \label{sec:model_selection}

The task of model selection targets the question: If there are several competing models, how do I choose the most appropriate one? This section outlines the model selection tools implemented in \pkg{RprobitB}. For illustration, we revisit the probit model of travelers deciding between two fictional train route alternatives:

<<load-model-train>>=
data("model_train", package = "RprobitB")
model_train
@

As a competing model, we consider explaining the choices only by the alternative's price, i.e. the probit model with the formula \code{choice ~ price | 0`}. (This model is also saved in \pkg{RprobitB} and can be accessed via \code{data("model\_train\_sparse", package = "RprobitB")}.)

<<nested-model-train, eval = FALSE>>=
model_train_sparse <- nested_model(model_train, form = choice ~ price | 0)
@

<<load-train-sparse-model, echo = FALSE>>=
data("model_train_sparse", package = "RprobitB")
@

The \fct{nested\_model} function helps to estimate a new version of \code{model\_train} with new specifications. Here, only \code{form} has been changed.

\paragraph{The model selection function:}

\pkg{RprobitB} provides the convenience function \fct{model\_selection}, which takes an arbitrary number of \class{RprobitB\_fit} objects and returns a matrix of model selection criteria:

<<model-selection-example>>=
model_selection(model_train, model_train_sparse,
                criteria = c("npar", "LL", "AIC", "BIC", "WAIC", "MMLL", "BF", "pred_acc"))
@

Specifying \code{criteria} is optional. Per default, \code{criteria = c("npar", "LL", "AIC", "BIC")}. The available model selection criteria are explained in the following.

\paragraph{npar:}

\code{"npar"} yields the number of model parameters, which is computed by the \fct{npar} method:

<<npar-example>>=
npar(model_train, model_train_sparse)
@

Here, \code{model\_train} has 4 parameters (a coefficient for price, time, change, and comfort, respectively), while \code{model\_train\_sparse} has only a single price coefficient.

\paragraph{LL:}

If \code{"LL"} is included in \code{criteria}, \fct{model\_selection} returns the model's log-likelihood values. They can also be directly accessed via the \fct{logLik} method. The log-likelihood values are per default computed at the point estimates derived from the Gibbs sample means. \fct{logLik} has the argument \code{par\_set}, where alternative statistics for the point estimate can be specified.

<<oglik-example>>=
logLik(model_train)
logLik(model_train_sparse)
@

\paragraph{AIC:}

Including \code{"AIC"} yields the Akaike's Information Criterion \citep{Akaike:1974}, which is computed as $$-2 \cdot \text{LL} + k \cdot \text{npar},$$
where $\text{LL}$ is the model's log-likelihood value, $k$ is the penalty per parameter with $k = 2$ per default for the classical AIC, and $\text{npar}$ is the number of parameters in the fitted model.

Alternatively, the \fct{AIC} method also returns the AIC values:

<<aic-example>>=
AIC(model_train, model_train_sparse, k = 2)
@

The AIC quantifies the trade-off between over- and under-fitting, where smaller values are preferred. Here, the increase in goodness of fit justifies the additional 3 parameters of \code{model\_train}.

\paragraph{BIC:}

Similar to the AIC, \code{"BIC"} yields the Bayesian Information Criterion \citep{Schwarz:1978}, which is defined as $$-2 \cdot \text{LL} + \log{(\text{nobs})} \cdot \text{npar},$$
where $\text{LL}$ is the model's log-likelihood value, $\text{nobs}$ is the number of data points (which can be accessed via the \fct{nobs} method), and $\text{npar}$ is the number of parameters in the fitted model. The interpretation is analogue to AIC.

\pkg{RprobitB} also provided a method for the BIC value:

<<bic-example>>=
BIC(model_train, model_train_sparse)
@

\paragraph{WAIC:}

WAIC is short for Widely Applicable (or Watanabe-Akaike) Information Criterion \citep{Watanabe:2010}. As for AIC and BIC, the smaller the WAIC value the better the model. Including \code{"WAIC"} in \code{criteria} yields the WAIC value, its standard error \code{se(WAIC)}, and the effective number of parameters \code{pWAIC}, see below.

The WAIC is defined as

$$-2  \cdot \text{lppd} + 2\cdot p_\text{WAIC},$$

where $\text{lppd}$ stands for log pointwise predictive density and $p_\text{WAIC}$ is a penalty term proportional to the variance in the posterior distribution that is sometimes called effective number of parameters, see \cite{McElreath:2016} p. 220 for a reference.

The $\text{lppd}$ is approximated as follows. Let $$p_{si} = \Pr(y_i\mid \theta_s)$$ be the probability of observation $y_i$ (here the single choices) given the $s$-th set $\theta_s$ of parameter samples from the posterior. Then

$$\text{lppd} = \sum_i \log \left( S^{-1} \sum_s p_{si} \right).$$
The penalty term is computed as the sum over the variances in log-probability for each observation:
$$p_\text{WAIC} = \sum_i \mathbb{V}_{\theta}  \log (p_{si}) . $$
The $\text{WAIC}$ has a standard error of
$$\sqrt{n \cdot \mathbb{V}_i \left[-2 \left(\text{lppd} - \mathbb{V}_{\theta}  \log (p_{si})  \right)\right]},$$
where $n$ is the number of choices.

Before computing the WAIC of an \code{RprobitB\_fit} object, the probabilities $p_{si}$ must be computed via the \fct{compute\_p\_si} function:

<<compute-psi-train, eval = FALSE>>=
model_train <- compute_p_si(model_train)
@

Afterwards, the WAIC can be accessed as follows, where the number in brackets is the standard error:

<<waic-example>>=
WAIC(model_train)
WAIC(model_train_sparse)
@

You can visualize the convergence of the WAIC as follows:

<<waictrace, fig=TRUE>>=
plot(WAIC(model_train))
plot(WAIC(model_train_sparse))
@

Here, both approximations look satisfactory. If the WAIC value does not seem to have converged, use more Gibbs samples by increasing \code{R} in \fct{mcmc} or decreasing \code{B} or \code{Q} via \fct{transform}, see the vignette on model fitting.

\paragraph{MMLL:}

\code{"MMLL"} in \code{criteria} stands for marginal model log-likelihood. The model's marginal likelihood $\Pr(y\mid M)$ for a model $M$ and data $y$ is required for the computation of Bayes factors, see below. In general, the term has no closed form and must be approximated numerically.

\pkg{RprobitB} uses the posterior Gibbs samples derived from the \fct{mcmc} function to approximate the model's marginal likelihood via the posterior harmonic mean estimator \citep{Newton:1994}: Let $S$ denote the number of available posterior samples $\theta_1,\dots,\theta_S$. Then,
$$\Pr(y\mid M) = \left(\mathbb{E}_\text{posterior} 1/\Pr(y\mid \theta,M) \right)^{-1} \approx \left( \frac{1}{S} \sum_s 1/\Pr(y\mid \theta_s,M) \right) ^{-1} = \tilde{\Pr}(y\mid M).$$

By the law of large numbers, $\tilde{\Pr}(y\mid M) \to \Pr(y\mid M)$ almost surely as $S \to \infty$.

As for the WAIC, computing the MMLL relies on the probabilities $p_{si} = \Pr(y_i\mid \theta_s)$, which must first be computed via the \fct{compute\_p\_si} function. Afterwards, the \fct{mml} function can be called with an \class{RprobitB\_fit} object as input. The function returns the \class{RprobitB\_fit} object, where the marginal likelihood value is saved as the entry \code{"mml"} and the marginal log-likelihood value as the attribute \code{"mmll"}. Note that the marginal likelihood value is very small. The given representation is required so that the value is not rounded to 0 by the computer.

<<mml_train>>=
model_train <- mml(model_train)
model_train$mml
attr(model_train$mml, "mmll")
@

Analogue to the WAIC value, the computation of the MMLL is an approximation that improves with rising (posterior) sample size. The convergence can again be verified visually via the \fct{plot} method:

<<mmltrace, fig=TRUE, width = 9>>=
plot(model_train$mml, log = TRUE)
@

There are two options for improving the approximation: As for the WAIC, you can use more posterior samples. Alternatively, you can combine the posterior harmonic mean estimate with the prior arithmetic mean estimator \citep{Hammersley:1964}: For this approach, $S$ samples $\theta_1,\dots,\theta_S$ are drawn from the model's prior distribution. Then,

$$\Pr(y\mid M) = \mathbb{E}_\text{prior} \Pr(y\mid \theta,M) \approx \frac{1}{S} \sum_s \Pr(y\mid \theta_s,M) = \tilde{\Pr}(y\mid M).$$

Again, it hols by the law of large numbers, that $\tilde{\Pr}(y\mid M) \to \Pr(y\mid M)$ almost surely as $S \to \infty$. The final approximation of the model's marginal likelihood than is a weighted sum of the posterior harmonic mean estimate and the prior arithmetic mean estimate, where the weights are determined by the sample sizes.

To use the prior arithmetic mean estimator, call the \fct{mml} function with a specification of the number of prior draws \code{S} and set \code{recompute = TRUE}:

<<arithmetic_mean_estimator, eval = FALSE>>=
model_train <- mml(model_train, S = 1000, recompute = TRUE)
@

Note that the prior arithmetic mean estimator works well if the prior and posterior distribution have a similar shape and strong overlap, as \cite{Gronau:2017} points out. Otherwise, most of the sampled prior values result in a likelihood value close to zero, thereby contributing only marginally to the approximation. In this case, a very large number \code{S} of prior samples is required.

\paragraph{Bayes factor:}

The Bayes factor is an index of relative posterior model plausibility of one model over another \citep{Marin:2014}. Given data $\texttt{y}$ and two models $\texttt{mod0}$ and $\texttt{mod1}$, it is defined as

$$
BF(\texttt{mod0},\texttt{mod1}) = \frac{\Pr(\texttt{mod0} \mid \texttt{y})}{\Pr(\texttt{mod1} \mid \texttt{y})} = \frac{\Pr(\texttt{y} \mid \texttt{mod0} )}{\Pr(\texttt{y} \mid \texttt{mod1})} / \frac{\Pr(\texttt{mod0})}{\Pr(\texttt{mod1})}.
$$

The ratio $\Pr(\texttt{mod0}) / \Pr(\texttt{mod1})$ expresses the factor by which $\texttt{mod0}$ a priori is assumed to be the correct model. Per default, \pkg{RprobitB} sets $\Pr(\texttt{mod0}) = \Pr(\texttt{mod1}) = 0.5$. The front part $\Pr(\texttt{y} \mid \texttt{mod0} ) / \Pr(\texttt{y} \mid \texttt{mod1})$ is the ratio of the marginal model likelihoods. A value of $BF(\texttt{mod0},\texttt{mod1}) > 1$ means that the model $\texttt{mod0}$ is more strongly supported by the data under consideration than $\texttt{mod1}$.

Adding \code{"BF"} to the \code{criteria} argument of \fct{model\_selection} yields the Bayes factors. We see a decisive evidence \citep{Jeffreys:1998} in favor of \class{model\_train}.

<<bayes-factor-example>>=
model_selection(model_train, model_train_sparse, criteria = c("BF"))
@

\paragraph{pred acc:}

Finally, adding \code{"pred_acc"} to the \code{criteria} argument for the \fct{model\_selection} function returns the share of correctly predicted choices. From the output of \fct{model\_selection} above (or alternatively the one in the following) we deduce that \class{model\_train} correctly predicts about 6\% of the choices more than \class{model\_train\_sparse}:

<<pred-acc-example>>=
pred_acc(model_train, model_train_sparse)
@

\section{Applications} \label{sec:applications}


\subsection{Chess opening choice} \label{subsec:chess_opening_choice}

\subsection{Berserking choice in online chess} \label{subsec:berserk}

\subsection{Child wish} \label{subsec:child_wish}

\subsection{Contraception choice} \label{subsec:contraception_choice}


\section{Conclusion} \label{sec:conclusion}

%% The problem
This paper addressed the problem of specifying mixing distributions in the multinomial probit model with a panel data setting, constituting an important part of the model selection for which the literature does not provide much guidance so far. In the absence of alternatives, many applications of the mixed multinomial probit model rely on different types of standard parametric distributions for modelling heterogeneity in preferences in combination with a likelihood-value based model selection. This course of action is very restrictive and imposes strong assumptions on the distribution of the model parameters that could potentially lead to misspecification and biased estimates.

%% Our solution
We proposed a new approach that improves the current specification strategies in several ways: First, our approach does not require any distributional assumption, since the latent class setting is flexible enough to approximate practically any distribution shape and allowing for any correlation pattern. Second, the weight-based updating scheme ensures that the number of latent classes does not need to be prespecified. Third, the imposed Bayesian estimation framework avoids many numerical problems that occur in the frequentist approach. Most notably, no likelihood function has to be evaluated nor approximated. Comparing the numerical estimation speed to the non-parametric frequentist approach of \cite{Bauer:2019}, we found that our implementation of the Bayesian approach is at least 10 times faster. The improvement becomes more distinct for panel data settings with a high number of choice occasions. This is due to the fact that for given total sample size $NT$ a large $T$ is beneficial for the Bayesian approach as then the number of vectors $\beta_n,~ n = 1,...,N$ is comparatively small, while in the frequentist approach calculating the likelihood becomes more challenging for increasing the number $T$ of choice situations faced by each of the $N$ individuals. On the other hand, the grid based frequentist approach of \cite{Bauer:2019} can potentially achieve a better approximation (especially of point masses) due to the relatively high number of latent classes. However, this approach requires that a suitable grid is set prior to the estimation with a specification of upper bounds for the coefficients. Additionally, the curse of dimensionality plays a crucial role, which is less of a burden in the Bayesian approach. Note that for a fully specified parametric structure these concerns do not play such a big role also for the frequentist approach.

%% Planned extensions
Our simulation results verified that the proposed approach achieves good approximations of the mixing distribution in common choice modelling situations, where the underlying heterogeneity cannot be captured by standard parametric distributions. It would be interesting to apply the approach also to empirical data in the future. Additionally,
further research on how to properly address sign-restricted coefficients is required.


\section*{Computational details}

The results in this paper were obtained using
\proglang{R}~\Sexpr{paste(R.Version()[6:7], collapse = ".")} with the
\pkg{RprobitB}~\Sexpr{packageVersion("RprobitB")} package. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at \url{https://CRAN.R-project.org/}.


\section*{Acknowledgments}

This work has been financed partly by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - Projektnummer 356500581 which is gratefully acknowledged.

\bibliography{ref}


\end{document}
