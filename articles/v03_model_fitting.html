<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="RprobitB">
<title>Model fitting • RprobitB</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Model fitting">
<meta property="og:description" content="RprobitB">
<meta property="og:image" content="https://loelschlaeger.de/RprobitB/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">RprobitB</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.3</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/RprobitB.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/v01_model_definition.html">Model definition</a>
    <a class="dropdown-item" href="../articles/v02_choice_data.html">Choice data</a>
    <a class="dropdown-item" href="../articles/v03_model_fitting.html">Model fitting</a>
    <a class="dropdown-item" href="../articles/v04_modeling_heterogeneity.html">Modeling heterogeneity</a>
    <a class="dropdown-item" href="../articles/v05_choice_prediction.html">Choice prediction</a>
    <a class="dropdown-item" href="../articles/v06_model_selection.html">Model selection</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/loelschlaeger/RprobitB/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Model fitting</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/loelschlaeger/RprobitB/blob/HEAD/vignettes/v03_model_fitting.Rmd" class="external-link"><code>vignettes/v03_model_fitting.Rmd</code></a></small>
      <div class="d-none name"><code>v03_model_fitting.Rmd</code></div>
    </div>

    
    
<p>This vignette<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;This vignette is built using R 4.3.2 with the {RprobitB}
1.1.3 package.&lt;/p&gt;"><sup>1</sup></a> is a documentation of the estimation
procedure <code><a href="../reference/fit_model.html">fit_model()</a></code> in {RprobitB}.</p>
<div class="section level2">
<h2 id="bayes-estimation-of-the-probit-model">Bayes estimation of the probit model<a class="anchor" aria-label="anchor" href="#bayes-estimation-of-the-probit-model"></a>
</h2>
<p>Bayes estimation of the probit model builds upon the work of <span class="citation">McCulloch and Rossi (<a href="#ref-McCulloch:1994" role="doc-biblioref">1994</a>)</span>, <span class="citation">Nobile (<a href="#ref-Nobile:1998" role="doc-biblioref">1998</a>)</span>, <span class="citation">Allenby and Rossi (<a href="#ref-Allenby:1998" role="doc-biblioref">1998</a>)</span>, and <span class="citation">Imai
and Dyk (<a href="#ref-Imai:2005" role="doc-biblioref">2005</a>)</span>.
A key ingredient is the concept of data augmentation, see <span class="citation">Albert and Chib (<a href="#ref-Albert:1993" role="doc-biblioref">1993</a>)</span>: The idea is to treat the latent
utilities <span class="math inline">\(U\)</span> in the model equation
<span class="math inline">\(U = X\beta + \epsilon\)</span> as additional
parameters. Then, conditional on <span class="math inline">\(U\)</span>,
the probit model constitutes a standard Bayesian linear regression
set-up. Its posterior distribution can be approximated by iteratively
drawing and updating each model parameter conditional on the other
parameters (the so-called Gibbs sampling approach).</p>
<p>A priori, we assume the following (conjugate) parameter
distributions:</p>
<ul>
<li><p><span class="math inline">\((s_1,\dots,s_C)\sim
D_C(\delta)\)</span>, where <span class="math inline">\(D_C(\delta)\)</span> denotes the <span class="math inline">\(C\)</span>-dimensional Dirichlet distribution with
concentration parameter vector <span class="math inline">\(\delta =
(\delta_1,\dots,\delta_C)\)</span>,</p></li>
<li><p><span class="math inline">\(\alpha\sim
\text{MVN}_{P_f}(\psi,\Psi)\)</span>, where <span class="math inline">\(\text{MVN}_{P_f}\)</span> denotes the <span class="math inline">\(P_f\)</span>-dimensional normal distribution with
mean <span class="math inline">\(\psi\)</span> and covariance <span class="math inline">\(\Psi\)</span>,</p></li>
<li><p><span class="math inline">\(b_c \sim
\text{MVN}_{P_r}(\xi,\Xi)\)</span>, independent for all <span class="math inline">\(c\)</span>,</p></li>
<li><p><span class="math inline">\(\Omega_c \sim
W^{-1}_{P_r}(\nu,\Theta)\)</span>, independent for all <span class="math inline">\(c\)</span>, where <span class="math inline">\(W^{-1}_{P_r}(\nu,\Theta)\)</span> denotes the
<span class="math inline">\(P_r\)</span>-dimensional inverse Wishart
distribution with <span class="math inline">\(\nu\)</span> degrees of
freedom and scale matrix <span class="math inline">\(\Theta\)</span>,</p></li>
<li><p>and <span class="math inline">\(\Sigma \sim
W^{-1}_{J-1}(\kappa,\Lambda)\)</span>.</p></li>
</ul>
<p>These prior distributions imply the following conditional posterior
distributions:</p>
<ul>
<li><p>The class weights are drawn from the Dirichlet distribution <span class="math display">\[\begin{equation}
(s_1,\dots,s_C)\mid \delta,z \sim D_C(\delta_1+m_1,\dots,\delta_C+m_C),
\end{equation}\]</span> where for <span class="math inline">\(c=1,\dots,C\)</span>, <span class="math inline">\(m_c=\#\{n:z_n=c\}\)</span> denotes the current
absolute class size.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;Mind that the model is invariant to permutations of the
class labels &lt;span class="math inline"&gt;\(1,\dots,C\)&lt;/span&gt;. For that
reason, we accept an update only if the ordering &lt;span class="math inline"&gt;\(s_1&amp;gt;\dots&amp;gt;s_C\)&lt;/span&gt; holds, thereby
ensuring a unique labeling of the classes.&lt;/p&gt;'><sup>2</sup></a></p></li>
<li><p>Independently for all <span class="math inline">\(n\)</span>, we
update the allocation variables <span class="math inline">\((z_n)_n\)</span> from their conditional
distribution <span class="math display">\[\begin{equation}
\text{Prob}(z_n=c\mid s,\beta,b,\Omega )=\frac{s_c\phi_{P_r}(\beta_n\mid
b_c,\Omega_c)}{\sum_c s_c\phi_{P_r}(\beta_n\mid b_c,\Omega_c)}.
\end{equation}\]</span></p></li>
<li><p>The class means <span class="math inline">\((b_c)_c\)</span> are
updated independently for all <span class="math inline">\(c\)</span> via
<span class="math display">\[\begin{equation}
b_c\mid \Xi,\Omega,\xi,z,\beta \sim\text{MVN}_{P_r}\left( \mu_{b_c},
\Sigma_{b_c}  \right),
\end{equation}\]</span> where <span class="math inline">\(\mu_{b_c}=(\Xi^{-1}+m_c\Omega_c^{-1})^{-1}(\Xi^{-1}\xi
+m_c\Omega_c^{-1}\bar{b}_c)\)</span>, <span class="math inline">\(\Sigma_{b_c}=(\Xi^{-1}+m_c\Omega_c^{-1})^{-1}\)</span>,
<span class="math inline">\(\bar{b}_c=m_c^{-1}\sum_{n:z_n=c}
\beta_n\)</span>.</p></li>
<li><p>The class covariance matrices <span class="math inline">\((\Omega_c)_c\)</span> are updated independently
for all <span class="math inline">\(c\)</span> via <span class="math display">\[\begin{equation}
\Omega_c \mid \nu,\Theta,z,\beta,b \sim
W^{-1}_{P_r}(\mu_{\Omega_c},\Sigma_{\Omega_c}),
\end{equation}\]</span> where <span class="math inline">\(\mu_{\Omega_c}=\nu+m_c\)</span> and <span class="math inline">\(\Sigma_{\Omega_c}=\Theta^{-1} + \sum_{n:z_n=c}
(\beta_n-b_c)(\beta_n-b_c)'\)</span>.</p></li>
<li><p>Independently for all <span class="math inline">\(n\)</span> and
<span class="math inline">\(t\)</span> and conditionally on the other
components, the utility vectors <span class="math inline">\((U_{nt:})\)</span> follow a <span class="math inline">\(J-1\)</span>-dimensional truncated multivariate
normal distribution, where the truncation points are determined by the
choices <span class="math inline">\(y_{nt}\)</span>. To sample from a
truncated multivariate normal distribution, we apply a sub-Gibbs
sampler, following the approach of <span class="citation">Geweke (<a href="#ref-Geweke:1998" role="doc-biblioref">1998</a>)</span>: <span class="math display">\[\begin{equation}
U_{ntj} \mid U_{nt(-j)},y_{nt},\Sigma,W,\alpha,X,\beta
\sim \mathcal{N}(\mu_{U_{ntj}},\Sigma_{U_{ntj}}) \cdot \begin{cases}
1(U_{ntj}&gt;\max(U_{nt(-j)},0) ) &amp; \text{if}~ y_{nt}=j\\
1(U_{ntj}&lt;\max(U_{nt(-j)},0) ) &amp; \text{if}~ y_{nt}\neq j
\end{cases},
\end{equation}\]</span> where <span class="math inline">\(U_{nt(-j)}\)</span> denotes the vector <span class="math inline">\((U_{nt:})\)</span> without the element <span class="math inline">\(U_{ntj}\)</span>, <span class="math inline">\(\mathcal{N}\)</span> denotes the univariate normal
distribution, <span class="math inline">\(\Sigma_{U_{ntj}} =
1/(\Sigma^{-1})_{jj}\)</span> and <span class="math display">\[\begin{equation}
\mu_{U_{ntj}} = W_{ntj}'\alpha + X_{ntj}'\beta_n -
\Sigma_{U_{ntj}} (\Sigma^{-1})_{j(-j)}   (U_{nt(-j)} -
W_{nt(-j)}'\alpha - X_{nt(-j)}' \beta_n ),
\end{equation}\]</span> where <span class="math inline">\((\Sigma^{-1})_{jj}\)</span> denotes the <span class="math inline">\((j,j)\)</span>th element of <span class="math inline">\(\Sigma^{-1}\)</span>, <span class="math inline">\((\Sigma^{-1})_{j(-j)}\)</span> the <span class="math inline">\(j\)</span>th row without the <span class="math inline">\(j\)</span>th entry, <span class="math inline">\(W_{nt(-j)}\)</span> and <span class="math inline">\(X_{nt(-j)}\)</span> the coefficient matrices <span class="math inline">\(W_{nt}\)</span> and <span class="math inline">\(X_{nt}\)</span>, respectively, without the <span class="math inline">\(j\)</span>th column.</p></li>
<li><p>Updating the fixed coefficient vector <span class="math inline">\(\alpha\)</span> is achieved by applying the
formula for Bayesian linear regression of the regressors <span class="math inline">\(W_{nt}\)</span> on the regressands <span class="math inline">\((U_{nt:})-X_{nt}'\beta_n\)</span>, i.e. <span class="math display">\[\begin{equation}
\alpha \mid \Psi,\psi,W,\Sigma,U,X,\beta \sim
\text{MVN}_{P_f}(\mu_\alpha,\Sigma_\alpha),
\end{equation}\]</span> where <span class="math inline">\(\mu_\alpha =
\Sigma_\alpha (\Psi^{-1}\psi + \sum_{n=1,t=1}^{N,T} W_{nt} \Sigma^{-1}
((U_{nt:})-X_{nt}'\beta_n) )\)</span> and <span class="math inline">\(\Sigma_\alpha = (\Psi^{-1} + \sum_{n=1,t=1}^{N,T}
W_{nt}\Sigma^{-1} W_{nt}^{'} )^{-1}\)</span>.</p></li>
<li><p>Analogously to <span class="math inline">\(\alpha\)</span>, the
random coefficients <span class="math inline">\((\beta_n)_n\)</span> are
updated independently via <span class="math display">\[\begin{equation}
\beta_n \mid \Omega,b,X,\Sigma,U,W,\alpha \sim
\text{MVN}_{P_r}(\mu_{\beta_n},\Sigma_{\beta_n}),
\end{equation}\]</span> where <span class="math inline">\(\mu_{\beta_n}
= \Sigma_{\beta_n} (\Omega_{z_n}^{-1}b_{z_n} + \sum_{t=1}^{T} X_{nt}
\Sigma^{-1} (U_{nt:}-W_{nt}'\alpha) )\)</span> and <span class="math inline">\(\Sigma_{\beta_n} = (\Omega_{z_n}^{-1} +
\sum_{t=1}^{T} X_{nt}\Sigma^{-1} X_{nt}^{'} )^{-1}\)</span>
.</p></li>
<li><p>The error term covariance matrix <span class="math inline">\(\Sigma\)</span> is updated by means of <span class="math display">\[\begin{equation}
\Sigma \mid \kappa,\Lambda,U,W,\alpha,X,\beta \sim
W^{-1}_{J-1}(\kappa+NT,\Lambda+S), \\
\end{equation}\]</span> where <span class="math inline">\(S =
\sum_{n=1,t=1}^{N,T} \varepsilon_{nt} \varepsilon_{nt}'\)</span> and
<span class="math inline">\(\varepsilon_{nt} = (U_{nt:}) -
W_{nt}'\alpha - X_{nt}'\beta_n\)</span>.</p></li>
</ul>
<div class="section level3">
<h3 id="parameter-normalization">Parameter normalization<a class="anchor" aria-label="anchor" href="#parameter-normalization"></a>
</h3>
<p>Samples obtained from the updating scheme described above lack
identification (except for <span class="math inline">\(s\)</span> and
<span class="math inline">\(z\)</span> draws), compare to the vignette
on the model definition. Therefore, subsequent to the sampling, the
following normalizations are required for the <span class="math inline">\(i\)</span>th updates in each iterations <span class="math inline">\(i\)</span>:</p>
<ul>
<li><p><span class="math inline">\(\alpha^{(i)} \cdot
\omega^{(i)}\)</span>,</p></li>
<li><p><span class="math inline">\(b_c^{(i)} \cdot
\omega^{(i)}\)</span>, <span class="math inline">\(c=1,\dots,C\)</span>,</p></li>
<li><p><span class="math inline">\(U_{nt}^{(i)} \cdot
\omega^{(i)}\)</span>, <span class="math inline">\(n =
1,\dots,N\)</span>, <span class="math inline">\(t =
1,\dots,T\)</span>,</p></li>
<li><p><span class="math inline">\(\beta_n^{(i)} \cdot
\omega^{(i)}\)</span>, <span class="math inline">\(n =
1,\dots,N\)</span>,</p></li>
<li><p><span class="math inline">\(\Omega_c^{(i)} \cdot
(\omega^{(i)})^2\)</span>, <span class="math inline">\(c=1,\dots,C\)</span>, and</p></li>
<li><p><span class="math inline">\(\Sigma^{(i)} \cdot
(\omega^{(i)})^2\)</span>,</p></li>
</ul>
<p>where either <span class="math inline">\(\omega^{(i)} =
\sqrt{\text{const} / (\Sigma^{(i)})_{jj}}\)</span> with <span class="math inline">\((\Sigma^{(i)})_{jj}\)</span> the <span class="math inline">\(j\)</span>th diagonal element of <span class="math inline">\(\Sigma^{(i)}\)</span>, <span class="math inline">\(1\leq j \leq J-1\)</span>, or alternatively <span class="math inline">\(\omega^{(i)} = \text{const} /
\alpha^{(i)}_p\)</span> for some coordinate <span class="math inline">\(1\leq p \leq P_f\)</span> of the <span class="math inline">\(i\)</span>th draw for the coefficient vector <span class="math inline">\(\alpha\)</span>. Here, <span class="math inline">\(\text{const}\)</span> is any positive constant
(typically 1). The preferences will be flipped if <span class="math inline">\(\omega^{(i)} &lt; 0\)</span>, which only is the
case if <span class="math inline">\(\alpha^{(i)}_p &lt; 0\)</span>.</p>
</div>
<div class="section level3">
<h3 id="burn-in-and-thinning">Burn-in and thinning<a class="anchor" aria-label="anchor" href="#burn-in-and-thinning"></a>
</h3>
<p>The theory behind Gibbs sampling constitutes that the sequence of
samples produced by the updating scheme is a Markov chain with
stationary distribution equal to the desired joint posterior
distribution. It takes a certain number of iterations for that
stationary distribution to be approximated reasonably well. Therefore,
it is common practice to discard the first <span class="math inline">\(B\)</span> out of <span class="math inline">\(R\)</span> samples (the so-called burn-in period).
Furthermore, correlation between nearby samples should be expected. In
order to obtain independent samples, we consider only every <span class="math inline">\(Q\)</span>th sample when computing Gibbs sample
statistics like expectation and standard deviation. The independence of
the samples can be verified by computing the serial correlation and the
convergence of the Gibbs sampler can be checked by considering trace
plots, see below.</p>
</div>
</div>
<div class="section level2">
<h2 id="the-fit_model-function">The <code>fit_model()</code> function<a class="anchor" aria-label="anchor" href="#the-fit_model-function"></a>
</h2>
<p>The Gibbs sampling scheme described above can be executed by applying
the function</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/fit_model.html">fit_model</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">data</span><span class="op">)</span></span></code></pre></div>
<p>where <code>data</code> must be an <code>RprobitB_data</code> object
(see the vignette about choice data). The function has the following
optional arguments:</p>
<ul>
<li><p><code>scale</code>: A character which determines the <a href="#parameter-normalization">utility scale</a>. It is of the form
<code>"&lt;parameter&gt; := &lt;value&gt;"</code>, where
<code>&lt;parameter&gt;</code> is either the name of a fixed effect or
<code>Sigma_&lt;j&gt;,&lt;j&gt;</code> for the <code>&lt;j&gt;</code>th
diagonal element of <code>Sigma</code>, and <code>&lt;value&gt;</code>
is the value of the fixed parameter (i.e. <span class="math inline">\(\text{const}\)</span> introduced <a href="#parameter-normalization">above</a>). Per default
<code>scale = "Sigma\_1,1 := 1"</code>, i.e. the first error-term
variance is fixed to 1.</p></li>
<li><p><code>R</code>: The number of iterations of the Gibbs sampler.
The default is <code>R = 10000</code>.</p></li>
<li><p><code>B</code>: The length of the burn-in period, i.e. a
non-negative number of samples to be discarded. The default is
<code>B = R/2</code>.</p></li>
<li><p><code>Q</code>: The thinning factor for the Gibbs samples,
i.e. only every <code>Q</code>th sample is kept. The default is
<code>Q = 1</code>.</p></li>
<li><p><code>print_progress</code>: A boolean, determining whether to
print the Gibbs sampler progress.</p></li>
<li>
<p><code>prior</code>: A named list of parameters for the prior
distributions (their default values are documented in the
<code><a href="../reference/check_prior.html">check_prior()</a></code> function):</p>
<ul>
<li><p><code>eta</code>: The mean vector of length <code>P_f</code> of
the normal prior for <code>alpha</code>.</p></li>
<li><p><code>Psi</code>: The covariance matrix of dimension
<code>P_f</code> x <code>P_f</code> of the normal prior for
<code>alpha</code>.</p></li>
<li><p><code>delta</code>: The concentration parameter of length 1 of
the Dirichlet prior for <code>s</code>.</p></li>
<li><p><code>xi</code>: The mean vector of length <code>P_r</code> of
the normal prior for each <code>b_c</code>.</p></li>
<li><p><code>D</code>: The covariance matrix of dimension
<code>P_r</code> x <code>P_r</code> of the normal prior for each
<code>b_c</code>.</p></li>
<li><p><code>nu</code>: The degrees of freedom (a natural number greater
than <code>P_r</code>) of the Inverse Wishart prior for each
<code>Omega_c</code>.</p></li>
<li><p><code>Theta</code>: The scale matrix of dimension
<code>P_r</code> x <code>P_r</code> of the Inverse Wishart prior for
each <code>Omega_c</code>.</p></li>
<li><p><code>kappa</code>: The degrees of freedom (a natural number
greater than <code>J-1</code>) of the Inverse Wishart prior for
<code>Sigma</code>.</p></li>
<li><p><code>E</code>: The scale matrix of dimension <code>J-1</code> x
<code>J-1</code> of the Inverse Wishart prior for
<code>Sigma</code>.</p></li>
</ul>
</li>
<li><p><code>latent_classes</code>: A list of parameters specifying the
number and the updating scheme of latent classes, see the vignette <a href="https://loelschlaeger.de/RprobitB/articles/v04_modeling_heterogeneity.html">on
modeling heterogeneity fitting</a>.</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h2>
<p>In <a href="https://loelschlaeger.de/RprobitB/articles/v02_choice_data.html">the
previous vignette on choice data</a>, we introduced the Train data set
from the {mlogit} package <span class="citation">(<a href="#ref-Croissant:2020" role="doc-biblioref">Croissant
2020</a>)</span> that contains 2922 choices between two fictional train
route alternatives. First, we transform the travel <code>time</code>
from minutes to hours and the travel <code>price</code> from guilders to
euros:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"Train"</span>, package <span class="op">=</span> <span class="st">"mlogit"</span><span class="op">)</span></span>
<span><span class="va">Train</span><span class="op">$</span><span class="va">price_A</span> <span class="op">&lt;-</span> <span class="va">Train</span><span class="op">$</span><span class="va">price_A</span> <span class="op">/</span> <span class="fl">100</span> <span class="op">*</span> <span class="fl">2.20371</span></span>
<span><span class="va">Train</span><span class="op">$</span><span class="va">price_B</span> <span class="op">&lt;-</span> <span class="va">Train</span><span class="op">$</span><span class="va">price_B</span> <span class="op">/</span> <span class="fl">100</span> <span class="op">*</span> <span class="fl">2.20371</span></span>
<span><span class="va">Train</span><span class="op">$</span><span class="va">time_A</span> <span class="op">&lt;-</span> <span class="va">Train</span><span class="op">$</span><span class="va">time_A</span> <span class="op">/</span> <span class="fl">60</span></span>
<span><span class="va">Train</span><span class="op">$</span><span class="va">time_B</span> <span class="op">&lt;-</span> <span class="va">Train</span><span class="op">$</span><span class="va">time_B</span> <span class="op">/</span> <span class="fl">60</span></span></code></pre></div>
<p>The following lines fit a probit model that explains the chosen trip
alternatives (<code>choice</code>) by their <code>price</code>,
<code>time</code>, number of <code>change</code>s, and level of
<code>comfort</code> (the lower this value the higher the comfort). For
normalization, the first linear coefficient, the <code>price</code>, was
fixed to <code>-1</code>, which allows to interpret the other
coefficients as monetary values:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">form</span> <span class="op">&lt;-</span> <span class="va">choice</span> <span class="op">~</span> <span class="va">price</span> <span class="op">+</span> <span class="va">time</span> <span class="op">+</span> <span class="va">change</span> <span class="op">+</span> <span class="va">comfort</span> <span class="op">|</span> <span class="fl">0</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prepare_data.html">prepare_data</a></span><span class="op">(</span>form <span class="op">=</span> <span class="va">form</span>, choice_data <span class="op">=</span> <span class="va">Train</span><span class="op">)</span></span>
<span><span class="va">model_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_model.html">fit_model</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">data</span>,</span>
<span>  scale <span class="op">=</span> <span class="st">"price := -1"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The estimated coefficients (using the mean of the Gibbs samples as a
point estimate) can be printed via</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">model_train</span><span class="op">)</span></span>
<span><span class="co">#&gt;            Estimate   (sd)</span></span>
<span><span class="co">#&gt; 1   price     -1.00 (0.00)</span></span>
<span><span class="co">#&gt; 2    time    -25.90 (2.09)</span></span>
<span><span class="co">#&gt; 3  change     -4.82 (0.84)</span></span>
<span><span class="co">#&gt; 4 comfort    -14.49 (0.86)</span></span></code></pre></div>
<p>and visualized via</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">model_train</span><span class="op">)</span>, sd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<p><img src="plot-coef-model-train-1.png" width="75%" style="display: block; margin: auto;"></p>
<p>The results indicate that the deciders value one hour travel time by
about 25€, an additional change by 5€, and a more comfortable class by
14€.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;These results are consistent with the ones that are
presented &lt;a href="https://cran.r-project.org/package=mlogit/vignettes/c5.mxl.html#train" class="external-link"&gt;in
a vignette of the mlogit package&lt;/a&gt; on the same data set but using the
logit model.&lt;/p&gt;'><sup>3</sup></a></p>
</div>
<div class="section level2">
<h2 id="checking-the-gibbs-samples">Checking the Gibbs samples<a class="anchor" aria-label="anchor" href="#checking-the-gibbs-samples"></a>
</h2>
<p>The Gibbs samples are saved in list form in the
<code>RprobitB_fit</code> object at the entry
<code>"gibbs_samples"</code>, i.e.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">model_train</span><span class="op">$</span><span class="va">gibbs_samples</span>, max.level <span class="op">=</span> <span class="fl">2</span>, give.attr <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; List of 2</span></span>
<span><span class="co">#&gt;  $ gibbs_samples_raw:List of 2</span></span>
<span><span class="co">#&gt;   ..$ alpha: num [1:1000, 1:4] -0.000713 -0.022961 -0.031988 -0.036215 -0.03571 ...</span></span>
<span><span class="co">#&gt;   ..$ Sigma: num [1:1000, 1] 1.05 1.1 1.03 1.02 1.01 ...</span></span>
<span><span class="co">#&gt;  $ gibbs_samples_nbt:List of 2</span></span>
<span><span class="co">#&gt;   ..$ alpha: num [1:500, 1:4] -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...</span></span>
<span><span class="co">#&gt;   ..$ Sigma: num [1:500, 1] 617 611 626 552 734 ...</span></span></code></pre></div>
<p>This object contains 2 elements:</p>
<ul>
<li><p><code>gibbs_samples_raw</code> is a list of the raw samples from
the Gibbs sampler,</p></li>
<li><p>and <code>gibbs_samples_nbt</code> are the Gibbs samples used for
parameter estimates, i.e. the normalized and thinned Gibbs samples after
the burn-in.</p></li>
</ul>
<p>Calling the summary function on the estimated
<code>RprobitB_fit</code> object yields additional information about the
Gibbs samples <code>gibbs_samples_nbt</code>. You can specify a list
<code>FUN</code> of functions that compute any point estimate of the
Gibbs samples<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;Use the function &lt;code&gt;&lt;a href="../reference/point_estimates.html"&gt;point_estimates()&lt;/a&gt;&lt;/code&gt; to
access the Gibbs sample statistics as an &lt;code&gt;RprobitB_parameter&lt;/code&gt;
object.&lt;/p&gt;'><sup>4</sup></a>, for example</p>
<ul>
<li><p><code>mean</code> for the arithmetic mean,</p></li>
<li><p><code><a href="https://rdrr.io/r/stats/sd.html" class="external-link">stats::sd</a></code> for the standard deviation,</p></li>
<li><p><code>R_hat</code> for the Gelman-Rubin statistic <span class="citation">(<a href="#ref-Gelman:1992" role="doc-biblioref">Gelman
and Rubin 1992</a>)</span> <a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;A Gelman-Rubin statistic close to 1 indicates that the
chain of Gibbs samples converged to the stationary distribution.&lt;/p&gt;"><sup>5</sup></a>,</p></li>
<li><p>or custom statistics like the absolute difference between the
median and the mean.</p></li>
</ul>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">model_train</span>,</span>
<span>  FUN <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="st">"mean"</span> <span class="op">=</span> <span class="va">mean</span>,</span>
<span>    <span class="st">"sd"</span> <span class="op">=</span> <span class="fu">stats</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/r/stats/sd.html" class="external-link">sd</a></span>,</span>
<span>    <span class="st">"R^"</span> <span class="op">=</span> <span class="va">R_hat</span>,</span>
<span>    <span class="st">"custom_stat"</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html" class="external-link">median</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="text-decoration: underline;">Probit model</span></span></span>
<span><span class="co"><span style="text-decoration: underline;">#&gt; </span>Formula: choice ~ price + time + change + comfort | 0 </span></span>
<span><span class="co">#&gt; R: 1000, B: 500, Q: 1</span></span>
<span><span class="co">#&gt; Level: Utility differences with respect to alternative 'B'.</span></span>
<span><span class="co">#&gt; Scale: Coefficient of effect 'price' (alpha_1) fixed to -1.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="text-decoration: underline;">Gibbs sample statistics</span></span></span>
<span><span class="co"><span style="text-decoration: underline;">#&gt; </span>               mean           sd           R^  custom_stat</span></span>
<span><span class="co">#&gt;  alpha</span></span>
<span><span class="co">#&gt;                                                           </span></span>
<span><span class="co">#&gt;      1        -1.00         0.00         1.00         0.00</span></span>
<span><span class="co">#&gt;      2       -25.90         2.09         1.04         0.07</span></span>
<span><span class="co">#&gt;      3        -4.82         0.84         1.00         0.02</span></span>
<span><span class="co">#&gt;      4       -14.49         0.86         1.00         0.02</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Sigma</span></span>
<span><span class="co">#&gt;                                                           </span></span>
<span><span class="co">#&gt;    1,1       661.69        59.21         1.03         7.30</span></span></code></pre></div>
<p>Calling the <code>plot</code> method with the additional argument
<code>type = "trace"</code> plots the trace of the Gibbs samples
<code>gibbs_samples_nbt</code>:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model_train</span>, type <span class="op">=</span> <span class="st">"trace"</span><span class="op">)</span></span></code></pre></div>
<p><img src="plot-trace-model-train-1.png" width="75%" style="display: block; margin: auto;"></p>
<p>Additionally, we can visualize the serial correlation of the Gibbs
samples via the argument <code>type = "acf"</code>. The boxes in the
top-right corner state the total sample size TSS (here <code>R</code> -
<code>B</code> = 10000 - 5000 = 5000), the effective sample size ESS,
and the factor by which TSS is larger than ESS.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model_train</span>, type <span class="op">=</span> <span class="st">"acf"</span><span class="op">)</span></span></code></pre></div>
<p><img src="plot-acf-model-train-1.png" width="75%" style="display: block; margin: auto;"></p>
<p>Here, the effective sample size is the value <span class="math inline">\(\text{TSS} / (1 + \sum_{k\geq 1} \rho_k)\)</span>,
where <span class="math inline">\(\rho_k\)</span> is the auto
correlation between the chain offset by <span class="math inline">\(k\)</span> positions. The auto correlations are
estimated via the <code><a href="https://rdrr.io/r/stats/acf.html" class="external-link">stats::acf()</a></code> function.</p>
</div>
<div class="section level2">
<h2 id="model-transformation-after-estimation">Model transformation after estimation<a class="anchor" aria-label="anchor" href="#model-transformation-after-estimation"></a>
</h2>
<p>The <code>transform</code> method can be used to transform an
<code>RprobitB_fit</code> object in three ways:</p>
<ol style="list-style-type: decimal">
<li>change the length <code>B</code> of the burn-in period, for
example</li>
</ol>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">model_train</span>, B <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>change the thinning factor <code>Q</code> of the Gibbs samples, for
example</li>
</ol>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">model_train</span>, Q <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>or change the model normalization <code>scale</code>, for
example</li>
</ol>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">model_train</span>, scale <span class="op">=</span> <span class="st">"Sigma_1 := 1"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Albert:1993" class="csl-entry">
Albert, J. H., and S. Chib. 1993. <span>“Bayesian Analysis of Binary and
Polychotomous Response Data.”</span> <em>Journal of the American
Statistical Association</em> 88. <a href="https://doi.org/10.2307/2290350" class="external-link">https://doi.org/10.2307/2290350</a>.
</div>
<div id="ref-Allenby:1998" class="csl-entry">
Allenby, G. M., and P. Rossi. 1998. <span>“Marketing Models of Consumer
Heterogeneity.”</span> <em>Journal of Econometrics</em> 89. <a href="https://doi.org/10.1016/S0304-4076(98)00055-4" class="external-link">https://doi.org/10.1016/S0304-4076(98)00055-4</a>.
</div>
<div id="ref-Croissant:2020" class="csl-entry">
Croissant, Y. 2020. <span>“Estimation of Random Utility Models in r: The
Mlogit Package.”</span> <em>Journal of Statistical Software</em> 95
(11). <a href="https://doi.org/10.18637/jss.v095.i11" class="external-link">https://doi.org/10.18637/jss.v095.i11</a>.
</div>
<div id="ref-Gelman:1992" class="csl-entry">
Gelman, A., and D. B. Rubin. 1992. <span>“Inference from Iterative
Simulation Using Multiple Sequences.”</span> <em>Statistical
Science</em> 7 (4). <a href="https://doi.org/10.1214/ss/1177011136" class="external-link">https://doi.org/10.1214/ss/1177011136</a>.
</div>
<div id="ref-Geweke:1998" class="csl-entry">
Geweke, J. 1998. <span>“Efficient Simulation from the Multivariate
Normal and Student-t Distributions Subject to Linear Constraints and the
Evaluation of Constraint Probabilities.”</span> <em>Computing Science
and Statistics</em> 23.
</div>
<div id="ref-Imai:2005" class="csl-entry">
Imai, K., and D. A. van Dyk. 2005. <span>“A Bayesian Analysis of the
Multinomial Probit Model Using Marginal Data Augmentation.”</span>
<em>Journal of Econometrics</em> 124.
</div>
<div id="ref-McCulloch:1994" class="csl-entry">
McCulloch, R., and P. Rossi. 1994. <span>“An Exact Likelihood Analysis
of the Multinomial Probit Model.”</span> <em>Journal of
Econometrics</em> 64. <a href="https://doi.org/10.1016/0304-4076(94)90064-7" class="external-link">https://doi.org/10.1016/0304-4076(94)90064-7</a>.
</div>
<div id="ref-Nobile:1998" class="csl-entry">
Nobile, A. 1998. <span>“A Hybrid Markov Chain for the Bayesian Analysis
of the Multinomial Probit Model.”</span> <em>Statistics and
Computing</em> 8. <a href="https://doi.org/10.1023/A:1008905311214" class="external-link">https://doi.org/10.1023/A:1008905311214</a>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by <a href="https://loelschlaeger.de" class="external-link">Lennart Oelschläger</a>, <a href="https://de.wikipedia.org/wiki/Dietmar_Bauer" class="external-link">Dietmar Bauer</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
