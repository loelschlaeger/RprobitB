# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Update class weight vector
#'
#' @param m \[`numeric(C)`\]\cr
#' The vector of current class frequencies.
#'
#' @inheritParams check_prior
#'
#' @return
#' An update for \code{s}.
#'
#' @examples
#' update_s(delta = 1, m = 4:1)
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_s <- function(delta, m) {
    .Call(`_RprobitB_update_s`, delta, m)
}

#' Update class allocation vector
#'
#' @inheritParams RprobitB_parameter
#'
#' @return
#' An update for \code{z}.
#'
#' @examples
#' update_z(
#'   s = c(0.6, 0.4), beta = matrix(c(-2, 0, 2), ncol = 3),
#'   b = cbind(0, 1), Omega = cbind(1, 1)
#' )
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_z <- function(s, beta, b, Omega) {
    .Call(`_RprobitB_update_z`, s, beta, b, Omega)
}

#' Update class sizes
#'
#' @param non_zero \[`logical(1)`\]\cr
#' Enforce strictly positive values in \code{m} (for numerical stability)?
#'
#' @inheritParams RprobitB_parameter
#'
#' @return
#' An update for \code{m}.
#'
#' @examples
#' update_m(C = 4, z = c(1, 1, 1, 2, 2, 3))
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_m <- function(C, z, non_zero = FALSE) {
    .Call(`_RprobitB_update_m`, C, z, non_zero)
}

#' Update mean of a single class
#'
#' @param Omega_c \[`matrix(P_r, P_r)`\]\cr
#' The class covariance matrix.
#'
#' @param bar_b_c \[`numeric(P_r)`\]\cr
#' The average observation of this class.
#'
#' @param m_c \[`integer(1)`\]\cr
#' The number of observations in this class.
#'
#' @param Sigma_b_0_inv \[`matrix(P_r, P_r)`\]\cr
#' The prior precision of the class mean.
#'
#' @inheritParams check_prior
#'
#' @return
#' An update for \code{b_c}.
#'
#' @examples
#' update_b_c(
#'   bar_b_c = c(0, 0), Omega_c = diag(2), m_c = 10,
#'   Sigma_b_0_inv = diag(2), mu_b_0 = c(0, 0)
#' )
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_b_c <- function(bar_b_c, Omega_c, m_c, Sigma_b_0_inv, mu_b_0) {
    .Call(`_RprobitB_update_b_c`, bar_b_c, Omega_c, m_c, Sigma_b_0_inv, mu_b_0)
}

#' Update class means
#'
#' @inheritParams RprobitB_parameter
#' @inheritParams update_s
#' @inheritParams update_b_c
#' @inheritParams check_prior
#'
#' @return
#' A matrix of updated means for each class in columns.
#'
#' @examples
#' N <- 100
#' b <- cbind(c(0, 0), c(1, 1))
#' Omega <- matrix(c(1, 0.3, 0.3, 0.5, 1, -0.3, -0.3, 0.8), ncol = 2)
#' z <- c(rep(1, N / 2), rep(2, N / 2))
#' m <- as.numeric(table(z))
#' beta <- sapply(
#'   z, function(z) oeli::rmvnorm(n = 1, b[, z], matrix(Omega[, z], 2, 2))
#' )
#' update_b(
#'   beta = beta, Omega = Omega, z = z, m = m,
#'   Sigma_b_0_inv = diag(2), mu_b_0 = c(0, 0)
#' )
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_b <- function(beta, Omega, z, m, Sigma_b_0_inv, mu_b_0) {
    .Call(`_RprobitB_update_b`, beta, Omega, z, m, Sigma_b_0_inv, mu_b_0)
}

#' Update covariance of a single class
#'
#' @param S_c \[`matrix(P_r, P_r)`\]\cr
#' The scatter matrix of this class.
#'
#' @inheritParams update_b_c
#' @inheritParams check_prior
#'
#' @return
#' An update for \code{Omega_c}.
#'
#' @examples
#' update_Omega_c(S_c = diag(2), m_c = 10, n_Omega_0 = 4, V_Omega_0 = diag(2))
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_Omega_c <- function(S_c, m_c, n_Omega_0, V_Omega_0) {
    .Call(`_RprobitB_update_Omega_c`, S_c, m_c, n_Omega_0, V_Omega_0)
}

#' Update class covariances
#'
#' @inheritParams RprobitB_parameter
#' @inheritParams update_s
#' @inheritParams check_prior
#'
#' @return
#' A matrix of updated covariance matrices for each class in columns.
#'
#' @examples
#' N <- 100
#' b <- cbind(c(0, 0), c(1, 1))
#' Omega <- matrix(c(1, 0.3, 0.3, 0.5, 1, -0.3, -0.3, 0.8), ncol = 2)
#' z <- c(rep(1, N / 2), rep(2, N / 2))
#' m <- as.numeric(table(z))
#' beta <- sapply(
#'   z, function(z) oeli::rmvnorm(n = 1, b[, z], matrix(Omega[, z], 2, 2))
#' )
#' update_Omega(
#'   beta = beta, b = b, z = z, m = m,
#'   n_Omega_0 = 4, V_Omega_0 = diag(2)
#' )
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_Omega <- function(beta, b, z, m, n_Omega_0, V_Omega_0) {
    .Call(`_RprobitB_update_Omega`, beta, b, z, m, n_Omega_0, V_Omega_0)
}

#' Update coefficient vector of multiple linear regression
#'
#' @param mu0
#' The mean vector of the normal prior distribution for the coefficient vector.
#'
#' @param Tau0
#' The precision matrix (i.e. inverted covariance matrix) of the normal prior
#' distribution for the coefficient vector.
#'
#' @param XSigX
#' The matrix \eqn{\sum_{n=1}^N X_n'\Sigma^{-1}X_n}. See below for details.
#'
#' @param XSigU
#' The vector \eqn{\sum_{n=1}^N X_n'\Sigma^{-1}U_n}. See below for details.
#'
#' @details
#' This function draws from the posterior distribution of \eqn{\beta} in the linear utility
#' equation \deqn{U_n = X_n\beta + \epsilon_n,} where \eqn{U_n} is the
#' (latent, but here assumed to be known) utility vector of decider \eqn{n = 1,\dots,N}, \eqn{X_n}
#' is the design matrix build from the choice characteristics faced by \eqn{n},
#' \eqn{\beta} is the unknown coefficient vector (this can be either the fixed
#' coefficient vector \eqn{\alpha} or the decider-specific coefficient vector \eqn{\beta_n}),
#' and \eqn{\epsilon_n} is the error term assumed to be normally distributed with mean \eqn{0}
#' and (known) covariance matrix \eqn{\Sigma}.
#' A priori we assume the (conjugate) normal prior distribution \deqn{\beta \sim N(\mu_0,T_0)}
#' with mean vector \eqn{\mu_0} and precision matrix (i.e. inverted covariance matrix) \eqn{T_0}.
#' The posterior distribution for \eqn{\beta} is normal with
#' covariance matrix \deqn{\Sigma_1 = (T_0 + \sum_{n=1}^N X_n'\Sigma^{-1}X_n)^{-1}} and mean vector
#' \deqn{\mu_1 = \Sigma_1(T_0\mu_0 + \sum_{n=1}^N X_n'\Sigma^{-1}U_n)}.
#' Note the analogy of \eqn{\mu_1} to the generalized least squares estimator
#' \deqn{\hat{\beta}_{GLS} = (\sum_{n=1}^N X_n'\Sigma^{-1}X_n)^{-1} \sum_{n=1}^N X_n'\Sigma^{-1}U_n} which
#' becomes weighted by the prior parameters \eqn{\mu_0} and \eqn{T_0}.
#'
#' @return
#' A vector, a draw from the normal posterior distribution of the coefficient
#' vector in a multiple linear regression.
#'
#' @examples
#' ### true coefficient vector
#' beta_true <- matrix(c(-1,1), ncol=1)
#' ### error term covariance matrix
#' Sigma <- matrix(c(1,0.5,0.2,0.5,1,0.2,0.2,0.2,2), ncol=3)
#' ### draw data
#' N <- 100
#' X <- replicate(N, matrix(rnorm(6), ncol=2), simplify = FALSE)
#' eps <- replicate(N, oeli::rmvnorm(n = 1, mean = c(0,0,0), Sigma = Sigma), simplify = FALSE)
#' U <- mapply(function(X, eps) X %*% beta_true + eps, X, eps, SIMPLIFY = FALSE)
#' ### prior parameters for coefficient vector
#' mu0 <- c(0,0)
#' Tau0 <- diag(2)
#' ### draw from posterior of coefficient vector
#' XSigX <- Reduce(`+`, lapply(X, function(X) t(X) %*% solve(Sigma) %*% X))
#' XSigU <- Reduce(`+`, mapply(function(X, U) t(X) %*% solve(Sigma) %*% U, X, U, SIMPLIFY = FALSE))
#' beta_draws <- replicate(100, update_reg(mu0, Tau0, XSigX, XSigU), simplify = TRUE)
#' rowMeans(beta_draws)
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_reg <- function(mu0, Tau0, XSigX, XSigU) {
    .Call(`_RprobitB_update_reg`, mu0, Tau0, XSigX, XSigU)
}

#' Update error term covariance matrix of multiple linear regression
#'
#' @param N
#' The draw size.
#'
#' @param S
#' A matrix, the sum over the outer products of the residuals \eqn{(\epsilon_n)_{n=1,\dots,N}}.
#'
#' @inheritParams check_prior
#'
#' @details
#' This function draws from the posterior distribution of the covariance matrix \eqn{\Sigma} in the linear utility
#' equation \deqn{U_n = X_n\beta + \epsilon_n,} where \eqn{U_n} is the
#' (latent, but here assumed to be known) utility vector of decider \eqn{n = 1,\dots,N}, \eqn{X_n}
#' is the design matrix build from the choice characteristics faced by \eqn{n},
#' \eqn{\beta} is the coefficient vector, and \eqn{\epsilon_n} is the error term assumed to be
#' normally distributed with mean \eqn{0} and unknown covariance matrix \eqn{\Sigma}.
#' A priori we assume the (conjugate) Inverse Wishart distribution \deqn{\Sigma \sim W(\kappa,E)}
#' with \eqn{\kappa} degrees of freedom and scale matrix \eqn{E}.
#' The posterior for \eqn{\Sigma} is the Inverted Wishart distribution with \eqn{\kappa + N} degrees of freedom
#' and scale matrix \eqn{E^{-1}+S}, where \eqn{S = \sum_{n=1}^{N} \epsilon_n \epsilon_n'} is the sum over
#' the outer products of the residuals \eqn{(\epsilon_n = U_n - X_n\beta)_n}.
#'
#' @return
#' A matrix, a draw from the Inverse Wishart posterior distribution of the error term
#' covariance matrix in a multiple linear regression.
#'
#' @examples
#' ### true error term covariance matrix
#' (Sigma_true <- matrix(c(1,0.5,0.2,0.5,1,0.2,0.2,0.2,2), ncol=3))
#' ### coefficient vector
#' beta <- matrix(c(-1,1), ncol=1)
#' ### draw data
#' N <- 100
#' X <- replicate(N, matrix(rnorm(6), ncol=2), simplify = FALSE)
#' eps <- replicate(N, oeli::rmvnorm(n = 1, mean = c(0,0,0), Sigma = Sigma_true), simplify = FALSE)
#' U <- mapply(function(X, eps) X %*% beta + eps, X, eps, SIMPLIFY = FALSE)
#' ### prior parameters for covariance matrix
#' kappa <- 4
#' E <- diag(3)
#' ### draw from posterior of coefficient vector
#' outer_prod <- function(X, U) (U - X %*% beta) %*% t(U - X %*% beta)
#' S <- Reduce(`+`, mapply(outer_prod, X, U, SIMPLIFY = FALSE))
#' Sigma_draws <- replicate(100, update_Sigma(kappa, E, N, S))
#' apply(Sigma_draws, 1:2, mean)
#' apply(Sigma_draws, 1:2, stats::sd)
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_Sigma <- function(kappa, E, N, S) {
    .Call(`_RprobitB_update_Sigma`, kappa, E, N, S)
}

#' Update latent utility vector
#'
#' @param U
#' The current utility vector of length \code{J-1}.
#'
#' @param y
#' An integer from \code{1} to \code{J}, the index of the chosen alternative.
#'
#' @param sys
#' A vector of length \code{J-1}, the systematic utility part.
#'
#' @param Sigmainv
#' The inverted error term covariance matrix of dimension \code{J-1} x \code{J-1}.
#'
#' @details
#' The key ingredient to Gibbs sampling for probit models is considering the latent utilities
#' as parameters themselves which can be updated (data augmentation).
#' Independently for all deciders \eqn{n=1,\dots,N} and choice occasions \eqn{t=1,...,T_n},
#' the utility vectors \eqn{(U_{nt})_{n,t}} in the linear utility equation \eqn{U_{nt} = X_{nt} \beta + \epsilon_{nt}}
#' follow a \eqn{J-1}-dimensional truncated normal distribution, where \eqn{J} is the number of alternatives,
#' \eqn{X_{nt} \beta} the systematic (i.e. non-random) part of the utility and \eqn{\epsilon_{nt} \sim N(0,\Sigma)} the error term.
#' The truncation points are determined by the choices \eqn{y_{nt}}. To draw from a truncated multivariate
#' normal distribution, this function implemented the approach of Geweke (1998) to conditionally draw each component
#' separately from a univariate truncated normal distribution. See Oelschläger (2020) for the concrete formulas.
#'
#' @references
#' See Geweke (1998) \emph{Efficient Simulation from the Multivariate Normal and Student-t Distributions Subject
#' to Linear Constraints and the Evaluation of Constraint Probabilities} for Gibbs sampling
#' from a truncated multivariate normal distribution. See Oelschläger and Bauer (2020) \emph{Bayes Estimation
#' of Latent Class Mixed Multinomial Probit Models} for its application to probit utilities.
#'
#' @return
#' An updated utility vector of length \code{J-1}.
#'
#' @examples
#' U <- c(0,0,0)
#' y <- 3
#' sys <- c(0,0,0)
#' Sigmainv <- solve(diag(3))
#' update_U(U, y, sys, Sigmainv)
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_U <- function(U, y, sys, Sigmainv) {
    .Call(`_RprobitB_update_U`, U, y, sys, Sigmainv)
}

#' Update latent utility vector in the ranked probit case
#'
#' @param U
#' The current utility vector of length \code{J-1}, differenced such that
#' the vector is negative.
#'
#' @param sys
#' A vector of length \code{J-1}, the systematic utility part.
#'
#' @param Sigmainv
#' The inverted error term covariance matrix of dimension
#' \code{J-1} x \code{J-1}.
#'
#' @details
#' This update is basically the same as in the non-ranked case, despite that
#' the truncation point is zero.
#'
#' @return
#' An updated utility vector of length \code{J-1}.
#'
#' @examples
#' U <- c(0,0)
#' sys <- c(0,0)
#' Sigmainv <- diag(2)
#' update_U_ranked(U, sys, Sigmainv)
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_U_ranked <- function(U, sys, Sigmainv) {
    .Call(`_RprobitB_update_U_ranked`, U, sys, Sigmainv)
}

#' Transform threshold increments to thresholds
#'
#' @description
#' This helper function transforms the threshold increments \code{d} to the
#' thresholds \code{gamma}.
#'
#' @param d
#' A numeric vector of threshold increments.
#'
#' @details
#' The threshold vector \code{gamma} is computed from the threshold increments
#' \code{d} as \code{c(-100,0,cumsum(exp(d)),100)}, where the bounds
#' \code{-100} and \code{100} exist for numerical reasons and the first
#' threshold is fixed to \code{0} for identification.
#'
#' @return
#' A numeric vector of the thresholds.
#'
#' @examples
#' d_to_gamma(c(0,0,0))
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
d_to_gamma <- function(d) {
    .Call(`_RprobitB_d_to_gamma`, d)
}

#' Log-likelihood in the ordered probit model
#'
#' @param d
#' A numeric vector of threshold increments.
#'
#' @param y
#' A matrix of the choices.
#'
#' @param mu
#' A matrix of the systematic utilities.
#'
#' @param Tvec
#' The element \code{Tvec} in \code{\link{sufficient_statistics}}.
#'
#' @return
#' The log-likelihood value.
#'
#' @examples
#' ll_ordered(c(0,0,0), matrix(1), matrix(1), 1)
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
ll_ordered <- function(d, y, mu, Tvec) {
    .Call(`_RprobitB_ll_ordered`, d, y, mu, Tvec)
}

#' Update utility threshold increments
#'
#' @param d
#' The current vector of utility threshold increments.
#'
#' @param ll
#' Current log-likelihood value.
#'
#' @param zeta
#' The mean vector of the normal prior for \code{d}.
#'
#' @param Z
#' The covariance matrix of the normal prior for \code{d}.
#'
#' @inheritParams ll_ordered
#'
#' @return
#' The updated value for \code{d}.
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_d <- function(d, y, mu, ll, zeta, Z, Tvec) {
    .Call(`_RprobitB_update_d`, d, y, mu, ll, zeta, Z, Tvec)
}

#' Weight-based class updates
#'
#' @param Cmax \[`integer(1)`\]\cr
#' The maximum number of classes, used to allocate space.
#'
#' @param epsmin \[`numeric(1)`\]\cr
#' The threshold weight for removing a class.
#'
#' @param epsmax \[`numeric(1)`\]\cr
#' The threshold weight for splitting a class.
#'
#' @param deltamin \[`numeric(1)`\]\cr
#' The threshold difference in class means for joining two classes.
#'
#' @param deltashift \[`numeric(1)`\]\cr
#' The scale for shifting the class means after a split.
#'
#' @param identify_classes \[`logical(1)`\]\cr
#' Identify classes by decreasing class weights?
#'
#' @inheritParams RprobitB_parameter
#'
#' @details
#' The following updating rules apply:
#'
#' * Class \eqn{c} is removed if \eqn{s_c < \epsilon_{min}}.
#' * Class \eqn{c} is split into two classes, if \eqn{s_c > \epsilon_{max}}.
#' * Two classes \eqn{c_1} and \eqn{c_2} are merged to one class, if
#'   \eqn{||b_{c_1} - b_{c_2}|| < \delta_{min}}.
#'
#' @examples
#' s <- c(0.7, 0.3)
#' b <- matrix(c(1, 1, 1, -1), ncol = 2)
#' Omega <- matrix(c(0.5, 0.3, 0.3, 0.5, 1, -0.1, -0.1, 0.8), ncol = 2)
#'
#' ### no update
#' RprobitB::update_classes_wb(s = s, b = b, Omega = Omega)
#'
#' ### remove class 2
#' RprobitB::update_classes_wb(s = s, b = b, Omega = Omega, epsmin = 0.31)
#'
#' ### split class 1
#' RprobitB::update_classes_wb(s = s, b = b, Omega = Omega, epsmax = 0.69)
#'
#' ### merge classes 1 and 2
#' RprobitB::update_classes_wb(s = s, b = b, Omega = Omega, deltamin = 3)
#'
#' @return
#' A list of updated values for \code{s}, \code{b}, and \code{Omega} and
#' the indicator \code{update_type} which signals the type of class update:
#'
#' - `0`: no update
#' - `1`: removed class
#' - `2`: split class
#' - `3`: merged classes
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_classes_wb <- function(s, b, Omega, epsmin = 0.01, epsmax = 0.7, deltamin = 0.1, deltashift = 0.5, identify_classes = FALSE, Cmax = 10L) {
    .Call(`_RprobitB_update_classes_wb`, s, b, Omega, epsmin, epsmax, deltamin, deltashift, identify_classes, Cmax)
}

#' Dirichlet process class updates
#'
#' @inheritParams RprobitB_parameter
#' @inheritParams check_prior
#' @inheritParams update_classes_wb
#'
#' @examples
#' set.seed(1)
#' z <- c(rep(1,20),rep(2,30))
#' b <- matrix(c(1,1,1,-1), ncol=2)
#' Omega <- matrix(c(1,0.3,0.3,0.5,1,-0.3,-0.3,0.8), ncol=2)
#' beta <- sapply(z, function(z) oeli::rmvnorm(n = 1, b[,z], matrix(Omega[,z],2,2)))
#' delta <- 1
#' xi <- numeric(2)
#' D <- diag(2)
#' nu <- 4
#' Theta <- diag(2)
#' RprobitB:::update_classes_dp(
#'   Cmax = 10, beta = beta, z = z, b = b, Omega = Omega,
#'   delta = delta, xi = xi, D = D, nu = nu, Theta = Theta
#' )
#'
#' @return
#' A list of updated values for \code{z}, \code{b}, \code{Omega}, and \code{C}.
#'
#' @export
#'
#' @keywords gibbs_sampler
#'
update_classes_dp <- function(beta, z, b, Omega, delta, mu_b_0, Sigma_b_0, n_Omega_0, V_Omega_0, identify_classes = FALSE, Cmax = 10L) {
    .Call(`_RprobitB_update_classes_dp`, beta, z, b, Omega, delta, mu_b_0, Sigma_b_0, n_Omega_0, V_Omega_0, identify_classes, Cmax)
}

#' Gibbs sampler for probit models
#'
#' @details
#' This function is not supposed to be called directly, but rather via
#' \code{\link{fit_model}}.
#'
#' @param sufficient_statistics
#' The output of \code{\link{sufficient_statistics}}.
#'
#' @inheritParams fit_model
#'
#' @inheritParams RprobitB_data
#'
#' @param init
#' The output of \code{\link{set_initial_gibbs_values}}.
#'
#' @return
#' A list of Gibbs samples for
#' \itemize{
#'   \item \code{Sigma},
#'   \item \code{alpha} (if \code{P_f>0}),
#'   \item \code{s}, \code{z}, \code{b}, \code{Omega} (if \code{P_r>0}),
#'   \item \code{d} (if \code{ordered = TRUE}),
#' }
#' and a vector \code{class_sequence} of length \code{R}, where the \code{r}th
#' entry is the number of latent classes after iteration \code{r}.
#'
#' @keywords gibbs_sampler
#'
gibbs_sampler <- function(sufficient_statistics, prior, latent_classes, fixed_parameter, init, R, B, print_progress, ordered, ranked) {
    .Call(`_RprobitB_gibbs_sampler`, sufficient_statistics, prior, latent_classes, fixed_parameter, init, R, B, print_progress, ordered, ranked)
}

