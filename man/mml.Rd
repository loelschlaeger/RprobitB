% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bayes_factor.R
\name{mml}
\alias{mml}
\title{Approximation of the model's marginal likelihood}
\usage{
mml(
  x,
  S = 100,
  method = "pame",
  print_progress = TRUE,
  check_conv = TRUE,
  ncores = 1,
  seq = FALSE
)
}
\arguments{
\item{x}{An object of class \code{RprobitB_fit}.}

\item{S}{The sample size.}

\item{method}{The approximation method, one of
\itemize{
\item \code{"pame"} for the prior arithmetic mean estimate,
\item \code{"phme"} for the posterior harmonic mean estimate.
}}

\item{print_progress}{Set to \code{TRUE} to print computation progress.}

\item{check_conv}{Set to \code{TRUE} to plot the convergence behavior of the approximation.}

\item{ncores}{Computation is parallelized, set the number of cores.}

\item{seq}{Set to \code{TRUE} to add the attribute \code{"seq"} to the output
which is a vector containing the approximation sequence.}
}
\value{
The model's marginal likelihood value.
}
\description{
This function approximates the model's marginal likelihood.
}
\details{
The model's marginal likelihood \eqn{p(y\mid M)} for a model \eqn{M} and data
\eqn{y} is required for the computation of Bayes factors. In general, the term
has no closed form and must be approximated numerically. This function offers
the following approximation methods. The strong law of large numbers guarantees
(almost surely), that the following approximations converge to the model's
marginal likelihood as the sample size \code{S} goes to infinity.
\subsection{The prior arithmetic mean estimator}{

Set \code{method = "pame"} to compute the prior arithmetic mean estimate.
For this approach, \code{S} samples \eqn{\theta_1,\dots,\theta_S}
are drawn from the model's prior distribution. Then,
\deqn{p(y\mid M) = \mathbb{E}_\text{prior} p(y\mid \theta,M) \approx \frac{1}{S}
\sum_s p(y\mid \theta_s,M).}
}

\subsection{The posterior harmonic mean estimator}{

Set \code{method = "phme"} to compute the posterior harmonic mean estimate.
For this approach, \code{S} samples \eqn{\theta_1,\dots,\theta_S}
are drawn from the model's posterior distribution. Then,
\deqn{p(y\mid M) = \left(\mathbb{E}_\text{posterior} p(y\mid \theta,M)^{-1}
\right)^{-1} \approx \left( \frac{1}{S} \sum_s 1/p(y\mid \theta_s,M) \right) ^{-1}.}
}
}
\examples{
data <- simulate_choices(
  form = choice ~ cov | 0,
  N = 10,
  T = 10,
  J = 2,
  seed = 1
)
x <- mcmc(data, R = 1000, print_progress = FALSE)
### S = 10 is too small for a good approximation
RprobitB:::mml(x = x, S = 10, method = "pame", check_conv = TRUE)

}
\keyword{internal}
